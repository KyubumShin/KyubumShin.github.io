<!doctype html>
<html lang="ko"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>GhostNet: More Features from Cheap Operations - KyuBum&#039;s Dev Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="KyuBum Shin"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="KyuBum Shin"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="본 글은 CVPR 2020에서 발표한 GhostNet에 대한 코드와 함께 보는 논문 리뷰입니다 간단 요약 Ghostnet에서는 전통적인 CNN에서 나타나는 특징인 중복된 Feature(중요한 Feature)에 중점을 두고 이를 효율적으로 만들어 내는 방법에 대하여 작성된 논문입니다. 기존에 뽑아둔 Feature를 일반적인 Convolution 연산보다 적"><meta property="og:type" content="blog"><meta property="og:title" content="GhostNet: More Features from Cheap Operations"><meta property="og:url" content="https://kyubumshin.github.io/2022/07/16/paper/Ghostnet/"><meta property="og:site_name" content="KyuBum&#039;s Dev Blog"><meta property="og:description" content="본 글은 CVPR 2020에서 발표한 GhostNet에 대한 코드와 함께 보는 논문 리뷰입니다 간단 요약 Ghostnet에서는 전통적인 CNN에서 나타나는 특징인 중복된 Feature(중요한 Feature)에 중점을 두고 이를 효율적으로 만들어 내는 방법에 대하여 작성된 논문입니다. 기존에 뽑아둔 Feature를 일반적인 Convolution 연산보다 적"><meta property="og:locale" content="ko_KR"><meta property="og:image" content="https://kyubumshin.github.io/img/ghost1.PNG"><meta property="og:image" content="https://kyubumshin.github.io/img/ghost2.PNG"><meta property="article:published_time" content="2022-07-16T12:24:11.000Z"><meta property="article:modified_time" content="2022-07-16T15:25:02.127Z"><meta property="article:author" content="KyuBum Shin"><meta property="article:tag" content="DeepLearning"><meta property="article:tag" content="CV"><meta property="article:tag" content="CNN"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/ghost1.PNG"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://kyubumshin.github.io/2022/07/16/paper/Ghostnet/"},"headline":"GhostNet: More Features from Cheap Operations","image":[],"datePublished":"2022-07-16T12:24:11.000Z","dateModified":"2022-07-16T15:25:02.127Z","author":{"@type":"Person","name":"KyuBum Shin"},"publisher":{"@type":"Organization","name":"KyuBum's Dev Blog","logo":{"@type":"ImageObject","url":"https://kyubumshin.github.io/img/logo.svg"}},"description":"본 글은 CVPR 2020에서 발표한 GhostNet에 대한 코드와 함께 보는 논문 리뷰입니다 간단 요약 Ghostnet에서는 전통적인 CNN에서 나타나는 특징인 중복된 Feature(중요한 Feature)에 중점을 두고 이를 효율적으로 만들어 내는 방법에 대하여 작성된 논문입니다. 기존에 뽑아둔 Feature를 일반적인 Convolution 연산보다 적"}</script><link rel="canonical" href="https://kyubumshin.github.io/2022/07/16/paper/Ghostnet/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.0.2"></head><body class="is-1-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="KyuBum&#039;s Dev Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="검색" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-12"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-07-16T12:24:11.000Z" title="2022. 7. 16. 오후 9:24:11">2022-07-16</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-07-16T15:25:02.127Z" title="2022. 7. 17. 오전 12:25:02">2022-07-17</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Paper/">Paper</a><span> / </span><a class="link-muted" href="/categories/Paper/CV/">CV</a></span><span class="level-item">7분안에 읽기 (약 993 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile">GhostNet: More Features from Cheap Operations</h1><div class="content"><hr>
<p>본 글은 CVPR 2020에서 발표한 GhostNet에 대한 코드와 함께 보는 논문 리뷰입니다</p>
<h3 id="간단-요약"><a href="#간단-요약" class="headerlink" title="간단 요약"></a>간단 요약</h3><ul>
<li>Ghostnet에서는 전통적인 CNN에서 나타나는 특징인 중복된 Feature(중요한 Feature)에 중점을 두고 이를 효율적으로 만들어 내는 방법에 대하여 작성된 논문입니다.</li>
<li>기존에 뽑아둔 Feature를 일반적인 Convolution 연산보다 적은 resource를 가지는 Linear Transfer연산을 통하여 조금씩 변형하여 중복된 Feature를 만드는 것에 초점이 잡혀있습니다</li>
</ul>
<h3 id="GhostNet-Idea"><a href="#GhostNet-Idea" class="headerlink" title="GhostNet : Idea"></a>GhostNet : Idea</h3><p>아래의 그림은 Resnet 50의 일부 Feature 맵을 시각화 한 사진인데, 여기서 보면 일부 비슷한 모습을 가지는 Feature Map을 볼 수 있습니다. 이를 본 논문에서는 이러한 겹치는 Feature를 Ghost Feature라고 서술하였습니다.</p>
<center>

<img src="/img/ghost1.PNG" alt="" width="600px"/>

</center>

<p>Ghostnet에서는 이러한 Ghost Feature map을 convolution 연산을 통해 자연스럽게 나오는게 아닌 Linear Transfer를 이용하여 기존의 뽑아낸 Feature를 조금씩 변형하여 만든 Feature맵으로 유도하여 적은 Parameter와 Flops를 가진 모델을 만드는 것을 목표로 합니다.</p>
<h3 id="Ghost-Module"><a href="#Ghost-Module" class="headerlink" title="Ghost Module"></a>Ghost Module</h3><p>기존의 CNN Block Module은 아래의 첫번째 그림과 같이 연산이 됩니다. 이 경우 필요한 Parameter의 수는 다음과 같습니다.</p>
<blockquote>
<p>$c$ : channel수<br>$kernel$ : kernel size</p>
</blockquote>
<p>$$<br>parameters &#x3D; c_{in} \times c_{out} \times kernel<br>$$</p>
<p>두번째 그림에서 보여주는 Ghost Module은 다음과 같은 연산과정을 통하여 이루어집니다</p>
<ul>
<li>Input을 Convolution연산을 통하여 Feature를 추출</li>
<li>추출된 Feature에 Linear transformation을 통하여 기존의 Feature들과 유사한 Ghost Feature를 생성</li>
<li>Feature와 Ghost Feature를 Concat을 통하여 하나로 합침</li>
</ul>
<center>

<img src="/img/ghost2.PNG" alt="" width="600px"/>

</center>

<p>실제 구현에서는 Linear Transfer 연산으로 Mobilenet에서 사용되었던 Depthwise Convolution 연산을 사용하였습니다.<br>input이 80이고 output이 100인 연산을 convolution으로 만 진행할 경우 필요한 Parameters는 아래와 같지만<br>$$ 80 \times 100 \times kernel_{conv}$$<br>이를 Ghost Block으로 진행 할 경우 다음과 같이 Parameter가 줄게 됩니다.</p>
<ul>
<li>기존 Feature와 Ghost Feature의 1:1 인 경우<br>$$<br>40 \times 100 \times kernel_{conv}+ 100 \times kernel_{dwconv}<br>$$</li>
</ul>
<blockquote>
<ul>
<li>torch의 Conv2d Layer는 group을 이용하여 depthwise Convolution 연산을 진행 할 수 있습니다.</li>
<li>group이 output사이즈와 같을경우 depthwise 연산을 진행</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GhostModule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, inp, oup, kernel_size=<span class="number">1</span>, ratio=<span class="number">2</span>, dw_size=<span class="number">3</span>, stride=<span class="number">1</span>, relu=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(GhostModule, self).__init__()</span><br><span class="line">        self.oup = oup</span><br><span class="line">        init_channels = math.ceil(oup / ratio)</span><br><span class="line">        new_channels = init_channels*(ratio-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.primary_conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(inp, init_channels, kernel_size, stride, kernel_size//<span class="number">2</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(init_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>) <span class="keyword">if</span> relu <span class="keyword">else</span> nn.Sequential(),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.cheap_operation = nn.Sequential(</span><br><span class="line">            nn.Conv2d(init_channels, new_channels, dw_size, <span class="number">1</span>, dw_size//<span class="number">2</span>, groups=init_channels, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(new_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>) <span class="keyword">if</span> relu <span class="keyword">else</span> nn.Sequential(),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x1 = self.primary_conv(x)</span><br><span class="line">        x2 = self.cheap_operation(x1) <span class="comment"># depthwise convolution 연산</span></span><br><span class="line">        out = torch.cat([x1,x2], dim=<span class="number">1</span>) <span class="comment"># identity 결합</span></span><br><span class="line">        <span class="keyword">return</span> out[:,:self.oup,:,:]</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://github.com/huawei-noah/Efficient-AI-Backbones/blob/master/ghostnet_pytorch/ghostnet.py">코드 출처 : huawei-noah&#x2F;Efficient-AI-Backbones</a></p>
<p>Ghostnet은 CNN 중복된 Feature 특징 통하여 딥러닝 모델에서의 Feature가 서로 상관관계가 있고, 이를 기존 Feature를 통해 생성하면서 좋은 결과를 보여주었습니다. </p>
<h3 id="데모"><a href="#데모" class="headerlink" title="데모"></a>데모</h3><p><a target="_blank" rel="noopener" href="https://colab.research.google.com/github/pytorch/pytorch.github.io/blob/master/assets/hub/pytorch_vision_ghostnet.ipynb">Colab 데모 페이지</a></p>
<p>GhostNet은 pytorch hub를 통하여 손쉽게 Classification 모델로 사용할 수 있습니다.</p>
<ol>
<li>모델 Load</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">model = torch.hub.load(<span class="string">&#x27;huawei-noah/ghostnet&#x27;</span>, <span class="string">&#x27;ghostnet_1x&#x27;</span>, pretrained=<span class="literal">True</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>Classification</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line">input_image = Image.<span class="built_in">open</span>(filename)</span><br><span class="line">preprocess = transforms.Compose([</span><br><span class="line">    transforms.Resize(<span class="number">256</span>),</span><br><span class="line">    transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]),</span><br><span class="line">])</span><br><span class="line">input_tensor = preprocess(input_image)</span><br><span class="line">input_batch = input_tensor.unsqueeze(<span class="number">0</span>) <span class="comment"># create a mini-batch as expected by the model</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># move the input and model to GPU for speed if available</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    input_batch = input_batch.to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">    model.to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    output = model(input_batch)</span><br><span class="line"><span class="comment"># Tensor of shape 1000, with confidence scores over Imagenet&#x27;s 1000 classes</span></span><br><span class="line"><span class="built_in">print</span>(output[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># The output has unnormalized scores. To get probabilities, you can run a softmax on it.</span></span><br><span class="line">probabilities = torch.nn.functional.softmax(output[<span class="number">0</span>], dim=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(probabilities)</span><br></pre></td></tr></table></figure></div><div class="article-licensing box"><div class="licensing-title"><p>GhostNet: More Features from Cheap Operations</p><p><a href="https://kyubumshin.github.io/2022/07/16/paper/Ghostnet/">https://kyubumshin.github.io/2022/07/16/paper/Ghostnet/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>KyuBum Shin</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2022-07-16</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2022-07-17</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/DeepLearning/">DeepLearning</a><a class="link-muted mr-2" rel="tag" href="/tags/CV/">CV</a><a class="link-muted mr-2" rel="tag" href="/tags/CNN/">CNN</a></div><div class="sharethis-inline-share-buttons"></div><script src="&lt;script type=&quot;text/javascript&quot; src=&quot;https://platform-api.sharethis.com/js/sharethis.js#property=612ce5f747069100121128ed&amp;product=inline-share-buttons&quot; async=&quot;async&quot;&gt;&lt;/script&gt;" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2022/06/22/Few-Shot-Learning/"><span class="level-item">Meta Learning</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">댓글</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://kyubumshin.github.io/2022/07/16/paper/Ghostnet/';
            this.page.identifier = '2022/07/16/paper/Ghostnet/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'kyubumshin-github-io' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><!--!--><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="KyuBum&#039;s Dev Blog" height="28"></a><p class="is-size-7"><span>&copy; 2022 KyuBum Shin</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("ko");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="맨 위로" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "이 웹 사이트는 귀하의 경험을 향상시키기 위해 Cookie를 사용합니다.",
          dismiss: "무시",
          allow: "허용",
          deny: "거부",
          link: "더 알아보기",
          policy: "Cookie 정책",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="입력 하세요..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"입력 하세요...","untitled":"(제목 없음)","posts":"포스트","pages":"페이지","categories":"카테고리","tags":"태그"});
        });</script></body></html>