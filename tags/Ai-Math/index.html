<!doctype html>
<html lang="ko"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>태그: Ai Math - KyuBum&#039;s Dev Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="KyuBum Shin"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="KyuBum Shin"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="KyuBum&#039;s Dev Blog"><meta property="og:url" content="https://kyubumshin.github.io/"><meta property="og:site_name" content="KyuBum&#039;s Dev Blog"><meta property="og:locale" content="ko_KR"><meta property="og:image" content="https://kyubumshin.github.io/img/og_image.png"><meta property="article:author" content="KyuBum Shin"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://kyubumshin.github.io"},"headline":"KyuBum's Dev Blog","image":["https://kyubumshin.github.io/img/og_image.png"],"author":{"@type":"Person","name":"KyuBum Shin"},"publisher":{"@type":"Organization","name":"KyuBum's Dev Blog","logo":{"@type":"ImageObject","url":"https://kyubumshin.github.io/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.0.2"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="KyuBum&#039;s Dev Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="검색" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-9-tablet is-9-desktop is-9-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">태그</a></li><li class="is-active"><a href="#" aria-current="page">Ai Math</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-01-20T05:04:42.000Z" title="2022. 1. 20. 오후 2:04:42">2022-01-20</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-01-24T01:16:28.934Z" title="2022. 1. 24. 오전 10:16:28">2022-01-24</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/boostcamp/">boostcamp</a><span> / </span><a class="link-muted" href="/categories/boostcamp/week/">week</a></span><span class="level-item">5분안에 읽기 (약 788 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/01/20/boostcamp/week/week1/AIMath-8/">부스트 캠프 ai tech 1주 4일차 Ai Math (8)</a></h1><div class="content"><hr>
<h2 id="8-RNN"><a href="#8-RNN" class="headerlink" title="8. RNN"></a>8. RNN</h2><ul>
<li>연속적인 데이터(Sequence Data)를 주로 다루는 Nerual Network</li>
<li>소리, 문자열, 주가등의 데이터를 분석하는데 사용된다</li>
</ul>
<h3 id="8-1-시계열-데이터"><a href="#8-1-시계열-데이터" class="headerlink" title="8.1 시계열 데이터"></a>8.1 시계열 데이터</h3><ul>
<li><p>독립동등분포 가정을 잘 위배하기 때문에 순서를 바꾸거나 과거에 정보에 손실이 발생하면 데이터의 확률분포 자체가 변해버린다  </p>
</li>
<li><p>베이즈 법칙을 이용하여 다음과 같이 표현이 가능하다<br>$$<br>\begin{aligned}<br>P(X_1, … ,X_{t}) &amp; = P(X_t|X_1, …, X{t-1})P(X_1,…,X_{t-1})\\<br>&amp; = \prod_{s=1}^{t}P(X_s|X_{s-1},…,X_1)<br>\end{aligned}<br>$$</p>
</li>
<li><p>시퀸스 데이터를 다루기 위해서는 길이가 가변적인 데이터를 다룰수 있는 모델이 필요하다</p>
<ul>
<li>조건부에 들어가는 데이터의 길이는 시퀸스마다 가변적이다<br>$$<br>\begin{aligned}<br>X_t &amp;\sim P(X_t|X_{t-1}, … X_{1})\\<br>X_{t+1} &amp;\sim P(X_t|X_{t}, X_{t-1}, … X_{1})<br>\end{aligned}<br>$$</li>
</ul>
</li>
<li><p>고정된길이 $\tau$ 만큼의 시퀸스만 사용하는 모델의 경우 자기회귀모델(Autoregressive Model)이라고 한다</p>
<ul>
<li>매우 오래된 과거의 데이터는 실제 데이터에 큰 영향을 주기 힘들다는 가정하에 세워진 모델이다<br>$$<br>\begin{aligned}<br>X_t &amp;\sim P(X_t|X_{t-1}, … X_{t-\tau})\\<br>X_{t+1} &amp;\sim P(X_t|X_{t}, … X_{t-\tau+1})<br>\end{aligned}<br>$$</li>
</ul>
</li>
<li><p>이전정보를 제외한 나머지 정보들을 잠재변수로 활용하는 모델을 잠재자기회귀모델 이라고 한다</p>
<ul>
<li>앞으로 다룰 RNN도 이 모델에 해당한다<br>$$<br>\begin{aligned}<br>X_t &amp;\sim P(X_t|X_{t-1}, H_t)\\<br>X_{t+1}&amp;\sim P(X_t|X_{t}, H_{t+1})\\<br>H_t&amp;=\operatorname{Net}(H_{t-1}, X_{t-1})<br>\end{aligned}<br>$$</li>
</ul>
</li>
</ul>
<h3 id="8-2-RNN"><a href="#8-2-RNN" class="headerlink" title="8.2 RNN"></a>8.2 RNN</h3><ul>
<li>기본적인 RNN 모델은 아래와 같이 MLP와 유사한 형태를 가지고 있다</li>
<li>RNN은 이전순서의 잠재변수와 현재의 입렬을 활용하여 계산을 이어나간다</li>
<li>RNN의 역전파는 BPTT(Backpropagation Through Time)라고 불리며 연결그래프에 따라 순차적으로 계산한다<blockquote>
<ul>
<li>$S$ : 잠재변수</li>
<li>$X$ : input Data</li>
<li>$W_x$ : $X$의 가중치행렬</li>
<li>$W_{rec}$ : $S$의 가중치 행렬</li>
<li>$\sigma$ : Activate Function</li>
<li>$X$ : 시퀸스 데이터</li>
</ul>
</blockquote>
</li>
<li>RNN의 Network 연산  </li>
</ul>
<p>$$<br>\mathbf{S_{t}} = \sigma (\mathbf{O}_{t-1} + \mathbf{X}_{t}\mathbf{W}_{x})<br>$$<br>$$<br>\mathbf{O_{t}} = \mathbf{S}_{t}\mathbf{W}_{rec}<br>$$</p>
<center>

<p><img src="/img/RNN.PNG" alt="RNN"></p>
</center>

<ul>
<li>BPTT<ul>
<li>RNN의 Backpropagation 을 계산해보면 미분의 곱으로 이루어진 항이 계산된다</li>
<li>시퀸스의 길이만큼의 $W_{rec}$의 역전파가 이루어 질 때 마다 계속해서 미분을 하기 때문에 시퀸스의 길이가 길어질수록 gradient vanishing(기울기 소실)이 발생하여 계산이 불안정해 진다<blockquote>
<ul>
<li>$L$ : loss 함수</li>
<li>$y$ : target</li>
</ul>
</blockquote>
</li>
</ul>
</li>
</ul>
<p>$$<br>\frac{\partial S_{t}}{\partial W_{rec}} = \sum_{i=1}^{t-1} \left( \prod_{j=i+1}^{t} \frac{\partial S_{j}}{\partial S_{j-1}} \right)\frac{\partial S_{i}}{\partial W_{rec}} + \frac{\partial S_{t-1}}{\partial W_{rec}}<br>$$</p>
<ul>
<li>truncated BPTT<ul>
<li>RNN은 시퀸스의 길이가 길어지면 기울기 소실이 발생하여 계산이 불안정해지기 때문에 중간에 연산을 끊어주는 테크닉.</li>
</ul>
</li>
<li>이러한 기울기 소실을 해결하기 위해 등장한 네트워크<ul>
<li>LSTM, GRU</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-01-20T04:02:33.000Z" title="2022. 1. 20. 오후 1:02:33">2022-01-20</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-02-07T23:47:52.308Z" title="2022. 2. 8. 오전 8:47:52">2022-02-08</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/boostcamp/">boostcamp</a><span> / </span><a class="link-muted" href="/categories/boostcamp/week/">week</a></span><span class="level-item">2분안에 읽기 (약 337 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/01/20/boostcamp/week/week1/AIMath-7/">부스트 캠프 ai tech 1주 3일차 Ai Math (7)</a></h1><div class="content"><hr>
<h2 id="7-CNN"><a href="#7-CNN" class="headerlink" title="7. CNN"></a>7. CNN</h2><ul>
<li>합성곱을 이용한 신경망</li>
</ul>
<h3 id="7-1-Convolution-연산"><a href="#7-1-Convolution-연산" class="headerlink" title="7.1 Convolution 연산"></a>7.1 Convolution 연산</h3><ul>
<li><p>신호(signal)를 커널을 이용해서 국소적으로 증폭 또는 감소시키는 연산을 말한다</p>
</li>
<li><p>CNN 에서 하는 연산은 엄밀하게 말하면 Cross Correlation 연산이다</p>
<blockquote>
<ul>
<li>Cross Correlation<br>$$<br>[f*g](x)  = \int_{\mathbb{R}}f(z)g(x+z)\operatorname{d}z<br>$$</li>
<li>Convolution 연산<br>$$<br>[f*g](x)  = \int_{\mathbb{R}}f(z)g(x-z)\operatorname{d}z<br>$$</li>
</ul>
</blockquote>
</li>
<li><p>다양한 차원에서 연산이 가능하다<br>$$<br>\begin{aligned}<br>&amp;1D \quad [f*g](i) = \sum_{p=1}^{d}f(p)g(i+p)\\<br>&amp;2D \quad [f*g](i,j) = \sum_{p,q}f(p,q)g(i+p,j+q)\\<br>&amp;3D \quad [f*g](i,j,k) = \sum_{p,q,r}f(p)g(i+p,j+q,k+r)<br>\end{aligned}<br>$$</p>
</li>
</ul>
<h3 id="7-1-2D-Convolution-연산"><a href="#7-1-2D-Convolution-연산" class="headerlink" title="7.1 2D Convolution 연산"></a>7.1 2D Convolution 연산</h3><ul>
<li>2차원 convolution 연산은 커널을 input위에서 움직여가면서 선형모델과 합성함수가 적용되는 구조이다.</li>
</ul>
<center>

<p><img src="/img/Convolution_schematic.gif" alt="conv"></p>
</center>

<ul>
<li>출력크기는 아래와 같이 계산된다<blockquote>
<ul>
<li>$H, W$ : 입력크기</li>
<li>$K_{h}, K_{w}$ : 커널의 크기</li>
<li>$O_{h}, O_{w}$ : 출력의 크기<br>$$<br>O_{h} = H-K_{h}+1\\<br>O_{w} = W-K_{w}+1<br>$$</li>
</ul>
</blockquote>
</li>
</ul>
<h3 id="7-2-Convolution-연산의-Backpropagation"><a href="#7-2-Convolution-연산의-Backpropagation" class="headerlink" title="7.2 Convolution 연산의 Backpropagation"></a>7.2 Convolution 연산의 Backpropagation</h3><ul>
<li>Convolution 연산의 역전파도 결국에는 선형연산이 여러번 적용된 형태이기 때문에 계산할때 각 커널의 들어오는 모든 gradient를 더하면 된다  </li>
</ul>
<p>$$<br>\frac{\partial \mathcal{L}}{\partial w_{i}} = \sum_{j} \delta_{j} x_{i+j-1}<br>$$</p>
<center>

<p><img src="/img/conv_back.PNG" alt="conv_back"></p>
</center></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-01-20T02:31:56.000Z" title="2022. 1. 20. 오전 11:31:56">2022-01-20</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-01-24T01:16:24.688Z" title="2022. 1. 24. 오전 10:16:24">2022-01-24</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/boostcamp/">boostcamp</a><span> / </span><a class="link-muted" href="/categories/boostcamp/week/">week</a></span><span class="level-item">4분안에 읽기 (약 544 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/01/20/boostcamp/week/week1/AIMath-6/">부스트 캠프 ai tech 1주 3일차 Ai Math (6)</a></h1><div class="content"><hr>
<h2 id="6-베이즈-통계학"><a href="#6-베이즈-통계학" class="headerlink" title="6. 베이즈 통계학"></a>6. 베이즈 통계학</h2><ul>
<li>하나의 사건에서 믿음의 정도를 확률로 나타내는 베이즈 확률론에 기반한 통계학 이론</li>
<li>쉽게 말하면 아직 일어나지 않은 사건이 일어날 확률에 대한 계산을 하는 학문</li>
</ul>
<h3 id="6-0-조건부-확률"><a href="#6-0-조건부-확률" class="headerlink" title="6.0 조건부 확률"></a>6.0 조건부 확률</h3><ul>
<li><p>조건부확률 $P(A|B)$<br>특정사건 $B$가 일어난 상황에서 사건 $A$가 일어날 확률이다. 아래와 같이 나타낼 수 있다.  </p>
<p>$A$와 $B$가 동시에 일어날 확률 = $B$가 일어날 확률 * $B$일어난 상황에서 $A$가 일어날 확률<br>$$<br>P(A\cap B) = P(B), P(A|B) = P(A), P(B|A)<br>$$<br>$$<br>P(B|A) = \frac{P(A\cap B)}{P(A)} = P(B) \frac{P(A|B)}{P(A)}<br>$$</p>
</li>
</ul>
<h3 id="6-1-베이즈-정리"><a href="#6-1-베이즈-정리" class="headerlink" title="6.1 베이즈 정리"></a>6.1 베이즈 정리</h3><ul>
<li><p>$D$ : 데이터</p>
</li>
<li><p>$\theta$ : 측정하고싶은 파라미터</p>
</li>
<li><p>조건부 확률 $P(\theta|D)$는 사후확률이라고 부른다</p>
</li>
<li><p>조건부 확률 $P(D|\theta)$는 가능도(likehood, 우도)라고 부른다</p>
</li>
<li><p>$P(\theta)$ 는 사전확률이라고 부른다</p>
</li>
<li><p>베이즈 정리는 아래와 같이 나타내며 이식으로 부터 우리는 사후확률과 가능도는 비례하는 관계임을 알 수 있다<br>$$<br>P(\theta|D) = P(\theta) \frac{P(D|\theta)}{P(D)}<br>$$</p>
</li>
<li><p>조건부 확률의 시각화  </p>
<ul>
<li>정밀도(Precision) : 모델이 True라고 분류한 것들 중에서 실제 True인 것의 비율</li>
<li>재현율(Recall) : 실제 True인 것 중에서 모델이 True라고 예측한 것의 비율</li>
<li>정확도(Accuracy) : 올바르게 예측한 정도<br>$$<br>Precision = \frac{TP}{TP+FP}<br>$$<br>$$<br>Recall = \frac{TP}{TP+FN}<br>$$<br>$$<br>Accruacy = \frac{TP + TN}{TP+FN+FP+TN}<br>$$</li>
</ul>
</li>
</ul>
<center>

<p><img src="/img/BT.PNG" alt="조건부 확률"></p>
</center>

<ul>
<li><p>새로운 데이터가 들어왔을때 앞서 계산한 사후확률을 사전확률로 사용하여 새로운 사후확률로 갱신할 수 있다<br>$$<br>P^{\prime}(\theta|D) = P(\theta|D) \frac{P(D|\theta)}{P(D)}<br>$$</p>
</li>
<li><p><code>조건부 확률은 일어나지 않은 일에 대해 유용한 통계적 해석을 제공하지만 인과관계를 추론할때는 함부로 사용해서는 안된다</code></p>
</li>
<li><p>robust한 모델을 위해서는 <code>인과관계</code>를 생각할 필요가 있다</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-01-19T14:39:00.000Z" title="2022. 1. 19. 오후 11:39:00">2022-01-19</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-01-24T01:16:23.067Z" title="2022. 1. 24. 오전 10:16:23">2022-01-24</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/boostcamp/">boostcamp</a><span> / </span><a class="link-muted" href="/categories/boostcamp/week/">week</a></span><span class="level-item">5분안에 읽기 (약 784 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/01/19/boostcamp/week/week1/AIMath-5/">부스트 캠프 ai tech 1주 3일차 Ai Math (5)</a></h1><div class="content"><hr>
<h2 id="5-통계학"><a href="#5-통계학" class="headerlink" title="5. 통계학"></a>5. 통계학</h2><ul>
<li>다량의 데이터를 관찰하고 정리 분석하는 수학분야</li>
</ul>
<h3 id="5-0-용어정리"><a href="#5-0-용어정리" class="headerlink" title="5.0 용어정리"></a>5.0 용어정리</h3><ul>
<li>모집단 : 정보를 얻고자 하는 대상이 되는 집단의 전체</li>
<li>표본집단 : 모집단으로부터 추출한 데이터 집합</li>
<li>통계량 : 표본집단의 평균, 표준편차, 분산 등의 데이터를 말한다</li>
<li>표본분포 : 표본집단의 확률분포</li>
<li>표집분포 : 통계량의 확률분포</li>
</ul>
<h3 id="5-1-모수"><a href="#5-1-모수" class="headerlink" title="5.1 모수"></a>5.1 모수</h3><ul>
<li>모평균 모표준편차 모분산 등 모집단의 데이터를 말한다.</li>
<li>유한한 개수의 데이터를 관찰하는것으로 우리는 모집단의 분포를 <code>정확하게 파악하는것은 불가능</code>하기 때문에 근사적으로 확률분포를 추정해야한다</li>
<li>모수적 방법론<ul>
<li>데이터가 특정 확률분포를 따른다고 가정한 뒤 모수를 추정하는 방법</li>
<li>보통 충분히 많은 데이터가 확보 되었을때 사용한다</li>
</ul>
</li>
<li>비모수적 방법론<ul>
<li>확률분포를 가정하지 않고 데이터에 따라 모델의 구조 및 모수의 개수가 유연하게 바뀌는경우</li>
<li>모수의 특성을 이용하지 않는다</li>
</ul>
</li>
</ul>
<h3 id="5-2-확률분포를-가정하는-방법"><a href="#5-2-확률분포를-가정하는-방법" class="headerlink" title="5.2 확률분포를 가정하는 방법"></a>5.2 확률분포를 가정하는 방법</h3><ul>
<li>데이터가 2개의 값 (0 또는 1)만 가지는 경우 $\rightarrow$ 베르누이 분포</li>
<li>데이터가 n개의 이산적인 값을 가지는 경우 $\rightarrow$ 카테고리 분포</li>
<li>데이터가 $[0,1]$ 사이에서 값을 가지는 경우 $\rightarrow$ 베타분포</li>
<li>데이터가 0 이상의 값을 가지는 경우 $\rightarrow$ 감마분포, 로그정규분포 등</li>
<li>데이터가 $\mathbb{R}$ 전체에서 값을 가지는 경우 $\rightarrow$ 정규분포, 라플라스분포 등</li>
</ul>
<blockquote>
<h3 id="정규분포의-모수-평균과-분산"><a href="#정규분포의-모수-평균과-분산" class="headerlink" title="정규분포의 모수 평균과 분산"></a>정규분포의 모수 평균과 분산</h3><ul>
<li>표본집단의 데이터를 $X$ 라고할때 표본평균 $\bar{X}$ 와 표본분산 $S^2$은 다음과 같다<br>$$<br>\bar{X} = \frac{1}{N}\sum_{i=1}^{N}X_{i}\qquad S^2 = \frac{1}{N-1}\sum_{i=1}^{N}(X_{i}-\bar{X})^2<br>$$</li>
<li>이때 모집단의 모수인 평균 $\mu$ , 분산 $\sigma^2$ 표본평균과 표본분산의 기댓값으로 추정 할 수 있다<br>$$<br>{\displaystyle \operatorname {E}[\bar{X}]=\mu\quad\operatorname{E}[S^2] = \sigma^2}<br>$$</li>
<li>통계량의 확률분포를 표집분포라고 부르며 표본평균의 표집분포는 $N$이 커질수록 정규분포를 따른다</li>
</ul>
</blockquote>
<h3 id="5-3-최대-가능도-추정법-maximum-likelihood-estimation"><a href="#5-3-최대-가능도-추정법-maximum-likelihood-estimation" class="headerlink" title="5.3 최대 가능도 추정법 maximum likelihood estimation"></a>5.3 최대 가능도 추정법 maximum likelihood estimation</h3><ul>
<li>이론적으로 가장 가능성이 높은 모수를 추정하는 방법 중 하나</li>
<li>어떤 상태 $\mathbf{x}$ 를 관측할 가능성이 제일 높은 모수를 추정하는 방법<br>$$<br>\hat{\theta}_{MLE} = \underset{\theta}{argmax}L(\theta; \mathbf{x}) = \underset{\theta}{argmax} P(\mathbf{x}|\theta)<br>$$</li>
</ul>
<h3 id="5-4-KL-divergence-쿨백-라이블러-발산"><a href="#5-4-KL-divergence-쿨백-라이블러-발산" class="headerlink" title="5.4 KL divergence 쿨백-라이블러 발산"></a>5.4 KL divergence 쿨백-라이블러 발산</h3><ul>
<li>두 확률분포가 얼마나 떨어져 있는지를 나타낸다</li>
<li>거리로써 사용은 불가능하다<ul>
<li>역이 성립을 하지 않은다</li>
</ul>
</li>
<li>솔직하게 여기에 정리하기에는 많이 중요한 내용이고 양도 많다</li>
<li>많이 중요하다 따로할 예정이다 그때 링크를 추가할 예정</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-01-19T06:24:28.000Z" title="2022. 1. 19. 오후 3:24:28">2022-01-19</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-01-24T01:16:17.885Z" title="2022. 1. 24. 오전 10:16:17">2022-01-24</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/boostcamp/">boostcamp</a><span> / </span><a class="link-muted" href="/categories/boostcamp/week/">week</a></span><span class="level-item">2분안에 읽기 (약 320 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/01/19/boostcamp/week/week1/AIMath-3/">부스트 캠프 ai tech 1주 3일차 Ai Math (2)</a></h1><div class="content"><hr>
<h2 id="4-딥러닝-기본"><a href="#4-딥러닝-기본" class="headerlink" title="4. 딥러닝 기본"></a>4. 딥러닝 기본</h2><ul>
<li>딥러닝은 <code>비선형모델</code>인 신경망을 이용한 기계학습이다</li>
</ul>
<h3 id="4-1-softmax-함수"><a href="#4-1-softmax-함수" class="headerlink" title="4.1 softmax 함수"></a>4.1 softmax 함수</h3><ul>
<li>모델의 출력을 확률로 해석 할 수 있게 변환해주는 함수</li>
<li>인공신경망에서 확률분포를 얻기위한 마지막 활성함수로 많이 사용한다</li>
<li>출력값은 항상 0~1사이로 정규화된다<br>$$<br>f(x)_{k} = \frac{e^{x_i}}{\sum_{k=1}^{n}e^{x_{k}}}<br>$$</li>
</ul>
<h3 id="4-2-Activation-Function-활성함수"><a href="#4-2-Activation-Function-활성함수" class="headerlink" title="4.2 Activation Function (활성함수)"></a>4.2 Activation Function (활성함수)</h3><ul>
<li>실수범위에서 정의된 비선형 함수</li>
<li>딥러닝을 비선형 모델로 만들어주는 결정적인 함수이다</li>
<li>여러가지 종류가 있으며 ReLU계열이 제일 많이 사용되고 있다</li>
<li>포스팅을 통해 따로 다룰 예정이다  </li>
</ul>
<h3 id="4-3-신경망"><a href="#4-3-신경망" class="headerlink" title="4.3 신경망"></a>4.3 신경망</h3><ul>
<li>선형모델과 활성함수를 합성한 함수이다</li>
<li>우리가 흔히 부르는 MLP(Multi Layer Perceptron)는 여러 층의 합성신경망을 뜻한다  </li>
</ul>
<blockquote>
<ul>
<li>$x$ : input  </li>
<li>$\sigma$ : Activation Function</li>
<li>$h$ : Layer output</li>
<li>$z$ : linear output</li>
<li>$W$ : weight matrix</li>
<li>$b$ : bias<br>$$<br>h = \sigma(z)\\<br>z = Wx + b\\<br>$$</li>
</ul>
</blockquote>
<h3 id="4-4-Backpropagation"><a href="#4-4-Backpropagation" class="headerlink" title="4.4 Backpropagation"></a>4.4 Backpropagation</h3><ul>
<li>MLP의 weight들을 효율적으로 갱신하는 알고리즘</li>
<li>합성함수의 미분법인 Chain-rule 기반으로 output Layer부터 input Layer로 미분을 계산해 나간다</li>
</ul>
<blockquote>
</blockquote>
<p>$$<br>O = W_{2}h + b_{2}\\<br>h = \sigma(z)\\<br>z = W_{1}x + b_{1}\\<br>$$</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-01-19T06:24:23.000Z" title="2022. 1. 19. 오후 3:24:23">2022-01-19</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-01-24T01:16:20.966Z" title="2022. 1. 24. 오전 10:16:20">2022-01-24</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/boostcamp/">boostcamp</a><span> / </span><a class="link-muted" href="/categories/boostcamp/week/">week</a></span><span class="level-item">6분안에 읽기 (약 895 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/01/19/boostcamp/week/week1/AIMath-4/">부스트 캠프 ai tech 1주 3일차 Ai Math (4)</a></h1><div class="content"><hr>
<h2 id="5-확률론"><a href="#5-확률론" class="headerlink" title="5. 확률론"></a>5. 확률론</h2><ul>
<li>확률에 대해서 다루는 수학의 한 분야</li>
<li>딥러닝은 확률을 기반으로 한 머신러닝의 한 분야이기 때문에 그 기반에는 확률론이 깔려있다<br><del>그래서 통계학을 배워야 한다</del></li>
<li>이 정리글에서 확률론에 대해 자세하게 다루지는 않을 예정이며 좀 더 자세한 글을 원한다면 PRML을 검색해서 보길 바란다  </li>
</ul>
<h3 id="5-1-확률변수와-확률-분포"><a href="#5-1-확률변수와-확률-분포" class="headerlink" title="5.1 확률변수와 확률 분포"></a>5.1 확률변수와 확률 분포</h3><ul>
<li>확률변수<ul>
<li>시행의 결과에 따라 값이 결정되는 변수를 나타낸다</li>
<li>나타날 가능성이 있는 모든 경우의 수에 해당하는 값을 가질수 있다</li>
<li>ex) 주사위를 던질때 나올수 있는 눈</li>
<li>확률분포에 따라서 이산확률변수와 연속확률변수 중 하나로 구분 될 수 있다<ul>
<li>항상 둘중 하나로 구분되는것은 아니다</li>
</ul>
</li>
</ul>
</li>
<li>확률분포<ul>
<li>확률변수가 특정한 값을 가질 확률을 나타내는 함수를 의미한다</li>
</ul>
</li>
</ul>
<h3 id="5-2-이산확률와-연속확률"><a href="#5-2-이산확률와-연속확률" class="headerlink" title="5.2 이산확률와 연속확률"></a>5.2 이산확률와 연속확률</h3><ul>
<li>이산확률변수<ul>
<li>확률변수 X가 취할수 있는 모든값을 셀 수 있을때 이산확률변수라고 한다(가산변수)</li>
<li>확률변수가 가질수 있는 모든 경우의 수를 고려하여 확률을 더해서 구한다<br>$$<br>\mathbb{P}(X\in A) = \sum_{x \in A}P(X=x)<br>$$</li>
</ul>
</li>
<li>연속확률변수<ul>
<li>연속적인 범위의 값을 지니는 확률변수. 모든 경우를 정확하게 셀 수 없는 확률변수이다(불가산변수)</li>
<li>데이터 공간에 정의된 확률밀도함수의 적분을 통해 구한다<br>$$<br>\mathbb{P}(X\in A) = \int_{A}^{}P(\mathbf{x})d\mathbf{x}<br>$$</li>
</ul>
</li>
</ul>
<h3 id="5-3-결합확률-amp-조건부확률"><a href="#5-3-결합확률-amp-조건부확률" class="headerlink" title="5.3 결합확률 &amp; 조건부확률"></a>5.3 결합확률 &amp; 조건부확률</h3><ul>
<li>결합확률 $P(X, Y)$  <ul>
<li>$X=x$ 이고 $Y = y$ 일때의 확률을 나타내는 함수</li>
</ul>
</li>
<li>조건부확률 $P(X | Y)$  <ul>
<li>$Y = y$ 일 때 $X = x$ 일 확률을 나타내는 함수</li>
</ul>
</li>
<li>결합확률과 조건부확률은 다음과 같은 관계가 성립한다.<br>$$<br>P(x, y) = P(x|y)P(y) = P(y|x)P(x)<br>$$</li>
<li>우리는 앞으로 이 조건부확률을 구하기 위해 모델을 학습시킨다  </li>
</ul>
<h3 id="5-4-기댓값"><a href="#5-4-기댓값" class="headerlink" title="5.4 기댓값"></a>5.4 기댓값</h3><ul>
<li>각 사건이 벌어졌을때의 이득과 그 사건이 벌어질 확률의 곱을 전체 사건에대해 합한 값</li>
<li>이산확률일 경우</li>
</ul>
<p>$$<br>\operatorname{E}[X]=\sum_{i}x_{i}P(x_{i})<br>$$</p>
<ul>
<li>연속 확률일 경우</li>
</ul>
<p>$$<br>\operatorname{E}[X]=\int_{X}xP(x)\operatorname {d} x<br>$$</p>
<ul>
<li>또한 선형성을 가지고 있기 때문에 아래가 성립한다</li>
</ul>
<p>$$<br>\operatorname{E}[X+Y]=\operatorname{E}[X]+\operatorname{E}[Y]<br>$$</p>
<p>$$<br>\operatorname{E}[cX]=c\operatorname{E}[X]<br>$$</p>
<ul>
<li>조건부 기댓값<ul>
<li>조건부 확률에 대한 기댓값은 다음과 같이 계산한다</li>
</ul>
</li>
</ul>
<p>$$<br>\operatorname{E}[y|X]=\int_{Y}^{}yP(y|X)\operatorname{d}y<br>$$</p>
<h3 id="5-5-몬테카를로-Sampling"><a href="#5-5-몬테카를로-Sampling" class="headerlink" title="5.5 몬테카를로 Sampling"></a>5.5 몬테카를로 Sampling</h3><ul>
<li>반복된 무작위 추출을 이용하여 함수의 값을 근사하는 알고리즘<ul>
<li>표본공간의 확률분포에서 충분히 표본을 뽑으면 결국 확률분포에 근사한다</li>
</ul>
</li>
<li>기계학습, 딥러닝을 학습시킬때 우리는 확률분포를 알지 못하는 경우가 대부분이기 때문에 데이터를 이요하여 기대값을 계산하려면 몬테카를로 방법을 이용해야한다<br>$$<br>{\displaystyle \operatorname {E} [f(x)] \approx \frac{1}{N} \sum_{i=1}^{N}f(x^{(i)}),\quad x(i) \overset{\underset{\mathrm{}}{i.i.d}}{\sim} P(x) }<br>$$</li>
<li>독립추출만 보장되면 대수의법칙에 의해 항상 수렴성이 보장된다</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-01-19T03:37:16.000Z" title="2022. 1. 19. 오후 12:37:16">2022-01-19</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-01-24T01:16:18.308Z" title="2022. 1. 24. 오전 10:16:18">2022-01-24</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/boostcamp/">boostcamp</a><span> / </span><a class="link-muted" href="/categories/boostcamp/week/">week</a></span><span class="level-item">4분안에 읽기 (약 595 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/01/19/boostcamp/week/week1/AIMath-2/">부스트 캠프 ai tech 1주 3일차 Ai Math (2)</a></h1><div class="content"><hr>
<p>이 글에서 미분은 다루지 않습니다</p>
<h2 id="3-경사하강법"><a href="#3-경사하강법" class="headerlink" title="3. 경사하강법"></a>3. 경사하강법</h2><ul>
<li>함수의 극소값의 위치를 구할때 사용하는 방법</li>
<li>현재값의 기울기를 이용하여 점점 극소값에 접근한다</li>
<li>기울기가 너무 커서 발산할 경우를 방지하기 위해 lr(learning rate)를 곱해서 충분히 작은 값으로 계산을 해준다</li>
<li>컴퓨터로 계산할 경우 딱 떨어지는 정수를 만들어내기 힘들기 때문에 $\epsilon$ 값보다 작아질 경우를 수렴했다라고 가정한다  </li>
</ul>
<p>$$<br>x_{i+1} \leftarrow  x_{i} - \gamma \nabla f(x_{i})<br>$$</p>
<ul>
<li><p>python code</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">var = init <span class="comment"># 초기값</span></span><br><span class="line">grad = gradient(var) <span class="comment"># 현재 위치로부터 기울기를 구하는 함수</span></span><br><span class="line"><span class="keyword">while</span> (<span class="built_in">abs</span>(grad) &gt; eps):</span><br><span class="line">    var += - lr * grad</span><br><span class="line">    grad = gradient(var)</span><br></pre></td></tr></table></figure></li>
<li><p>벡터가 입력인 다변수 함수의 경우는 편미분을 이용하여 경사하강법을 진행한다</p>
</li>
</ul>
<h3 id="3-1-선형회귀에서의-경사하강법"><a href="#3-1-선형회귀에서의-경사하강법" class="headerlink" title="3.1 선형회귀에서의 경사하강법"></a>3.1 선형회귀에서의 경사하강법</h3><ul>
<li>선형회귀에서의 target은 $\left\|\mathbf{y-X\beta}\right\|_{2}$ 이고, 이를 최소화하는 $\beta$를 찾아야 하기 때문에 아래와 같은 gradient를 구해야 한다  </li>
</ul>
<p>$$<br>\nabla_{\beta}\left\|\mathbf{y-X\beta}\right\|_{2}=-\frac{\mathbf{X^{\top}(y-X\beta)}}{n\left\|\mathbf{y-X\beta}\right\|_{2}}<br>$$</p>
<ul>
<li>위의 식을 통하여 $\beta$를 구하는 경사하강법 알고리즘은 아래와 같다</li>
</ul>
<p>$$<br>\begin{eqnarray*}<br>\beta_{i+1}&amp;\leftarrow\beta_{i}-\gamma\nabla_{\beta}\left\|\mathbf{y-X\beta_{i}}\right\|_{2}\\<br>\beta_{i+1}&amp;\leftarrow\beta_{i} + \gamma \frac{\mathbf{X^{\top}(y-X\beta)}}{n\left\|\mathbf{y-X\beta}\right\|_{2}}<br>\end{eqnarray*}<br>$$</p>
<ul>
<li>간략하게 아래와 같이 표현도 가능하다 <ul>
<li>gradient를 최소화시키는것과 gradient의 제곱을 최소화 시키는것은 같은 의미</li>
</ul>
</li>
</ul>
<p>$$<br>\beta_{i+1} \leftarrow \beta_{i} + \frac{2\gamma}{n} \mathbf{X^{\top}(y-X\beta)}<br>$$</p>
<h3 id="3-2-경사하강법의-한계"><a href="#3-2-경사하강법의-한계" class="headerlink" title="3.2 경사하강법의 한계"></a>3.2 경사하강법의 한계</h3><ul>
<li>볼록한 함수에서는 적절한 학습률과 반복횟수를 선택했을 때 수렴이 보장되어있다</li>
<li>비선형회귀의 경우 목적식이 볼록하지 않기 때문에 수렴이 항상 보장되지는 않는다</li>
<li>특히 딥러닝의 경우 고차원의 자료를 다루기 때문에 경사하강법만으로는 학습하기가 힘들다</li>
</ul>
<center>

<p><img src="/img/nonlinear.PNG" alt="non_linear"></p>
</center>

<ul>
<li>이러한 이유로 SGD, Momentom, Adam 등의 여러가지 optimize 알고리즘이 등장했다</li>
<li>이 부분에 대해서는 추후에 따로 다룰 예정이다</li>
</ul>
</div></article></div></div><div class="column column-left is-3-tablet is-3-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="KyuBum Shin"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">KyuBum Shin</p><p class="is-size-6 is-block">Student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Incheon</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">포스트</p><a href="/archives"><p class="title">118</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">카테고리</p><a href="/categories"><p class="title">25</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">태그</p><a href="/tags"><p class="title">44</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/KyubumShin" target="_blank" rel="noopener">팔로우</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/KyubumShin"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">링크</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/KyubumShin" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">카테고리</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Computer-Science/"><span class="level-start"><span class="level-item">Computer Science</span></span><span class="level-end"><span class="level-item tag">8</span></span></a><ul><li><a class="level is-mobile" href="/categories/Computer-Science/Database/"><span class="level-start"><span class="level-item">Database</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Computer-Science/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Computer-Science/OS/"><span class="level-start"><span class="level-item">OS</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Computer-Science/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0/"><span class="level-start"><span class="level-item">자료구조</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/DeepLearning/"><span class="level-start"><span class="level-item">DeepLearning</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/DeepLearning/Basic/"><span class="level-start"><span class="level-item">Basic</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/DeepLearning/Pytorch-Lightning/"><span class="level-start"><span class="level-item">Pytorch Lightning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Paper/"><span class="level-start"><span class="level-item">Paper</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Paper/CV/"><span class="level-start"><span class="level-item">CV</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Paper/CV/OB/"><span class="level-start"><span class="level-item">OB</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Programming/Docker/"><span class="level-start"><span class="level-item">Docker</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/Programming/Python/tip/"><span class="level-start"><span class="level-item">tip</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/boostcamp/"><span class="level-start"><span class="level-item">boostcamp</span></span><span class="level-end"><span class="level-item tag">87</span></span></a><ul><li><a class="level is-mobile" href="/categories/boostcamp/Dairy/"><span class="level-start"><span class="level-item">Dairy</span></span><span class="level-end"><span class="level-item tag">29</span></span></a></li><li><a class="level is-mobile" href="/categories/boostcamp/Peer-Session/"><span class="level-start"><span class="level-item">Peer Session</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/boostcamp/Problems/"><span class="level-start"><span class="level-item">Problems</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/boostcamp/week/"><span class="level-start"><span class="level-item">week</span></span><span class="level-end"><span class="level-item tag">54</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%B0%B1%EC%97%94%EB%93%9C/"><span class="level-start"><span class="level-item">백엔드</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%B0%B1%EC%97%94%EB%93%9C/%EB%A9%94%EC%84%B8%EC%A7%80%ED%81%90/"><span class="level-start"><span class="level-item">메세지큐</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%9D%BC%EC%83%81/"><span class="level-start"><span class="level-item">일상</span></span><span class="level-end"><span class="level-item tag">43</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%9D%BC%EC%83%81/TIL/"><span class="level-start"><span class="level-item">TIL</span></span><span class="level-end"><span class="level-item tag">42</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9D%BC%EC%83%81/%EA%B3%84%ED%9A%8D/"><span class="level-start"><span class="level-item">계획</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">최근 글</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-01T12:19:58.000Z">2022-04-01</time></p><p class="title"><a href="/2022/04/01/boostcamp/Dairy/Week11-Day-5-Review/">Week11 - Day 5 Review</a></p><p class="categories"><a href="/categories/boostcamp/">boostcamp</a> / <a href="/categories/%EC%9D%BC%EC%83%81/">일상</a> / <a href="/categories/%EC%9D%BC%EC%83%81/TIL/">TIL</a> / <a href="/categories/boostcamp/Dairy/">Dairy</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-03-31T11:39:14.000Z">2022-03-31</time></p><p class="title"><a href="/2022/03/31/boostcamp/Dairy/Week11-Day-1-4-Review/">Week11 - Day 1~4 Review</a></p><p class="categories"><a href="/categories/boostcamp/">boostcamp</a> / <a href="/categories/%EC%9D%BC%EC%83%81/">일상</a> / <a href="/categories/%EC%9D%BC%EC%83%81/TIL/">TIL</a> / <a href="/categories/boostcamp/Dairy/">Dairy</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-03-24T15:06:09.000Z">2022-03-25</time></p><p class="title"><a href="/2022/03/25/boostcamp/Dairy/Week10-Day-3-4-Review/">Week10 - Day 3~4 Review</a></p><p class="categories"><a href="/categories/boostcamp/">boostcamp</a> / <a href="/categories/%EC%9D%BC%EC%83%81/">일상</a> / <a href="/categories/%EC%9D%BC%EC%83%81/TIL/">TIL</a> / <a href="/categories/boostcamp/Dairy/">Dairy</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-03-22T15:11:49.000Z">2022-03-23</time></p><p class="title"><a href="/2022/03/23/boostcamp/Dairy/Week10-Day-1-2-Review/">Week10 - Day 1~2 Review</a></p><p class="categories"><a href="/categories/boostcamp/">boostcamp</a> / <a href="/categories/%EC%9D%BC%EC%83%81/">일상</a> / <a href="/categories/%EC%9D%BC%EC%83%81/TIL/">TIL</a> / <a href="/categories/boostcamp/Dairy/">Dairy</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-03-20T03:45:11.000Z">2022-03-20</time></p><p class="title"><a href="/2022/03/20/paper/FCOS/">FCOS: Fully Convolutional One-Stage Object Detection</a></p><p class="categories"><a href="/categories/Paper/">Paper</a> / <a href="/categories/Paper/CV/">CV</a> / <a href="/categories/Paper/CV/OB/">OB</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">아카이브</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">4월 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">3월 2022</span></span><span class="level-end"><span class="level-item tag">21</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/02/"><span class="level-start"><span class="level-item">2월 2022</span></span><span class="level-end"><span class="level-item tag">34</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/01/"><span class="level-start"><span class="level-item">1월 2022</span></span><span class="level-end"><span class="level-item tag">39</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">10월 2021</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/09/"><span class="level-start"><span class="level-item">9월 2021</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/08/"><span class="level-start"><span class="level-item">8월 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">태그</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/3D/"><span class="tag">3D</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ai-Math/"><span class="tag">Ai Math</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ai-serving/"><span class="tag">Ai serving</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CNN-Viz/"><span class="tag">CNN Viz</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CV/"><span class="tag">CV</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-visualization/"><span class="tag">Data visualization</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DeepLearning/"><span class="tag">DeepLearning</span><span class="tag">23</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Function/"><span class="tag">Function</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN/"><span class="tag">GAN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Generative-Model/"><span class="tag">Generative Model</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Instance-Segmentation/"><span class="tag">Instance Segmentation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LandMark-Detection/"><span class="tag">LandMark Detection</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-modal/"><span class="tag">Multi-modal</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Object-Detection/"><span class="tag">Object Detection</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Project-product/"><span class="tag">Project product</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch-Lightning/"><span class="tag">Pytorch Lightning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Semantic-Segmentation/"><span class="tag">Semantic Segmentation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sequencial-Model/"><span class="tag">Sequencial Model</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VAE/"><span class="tag">VAE</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/backend/"><span class="tag">backend</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cs/"><span class="tag">cs</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/database/"><span class="tag">database</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/message/"><span class="tag">message</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/network/"><span class="tag">network</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/os/"><span class="tag">os</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pytorch/"><span class="tag">pytorch</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/week1/"><span class="tag">week1</span><span class="tag">19</span></a></div><div class="control"><a class="tags has-addons" href="/tags/week10/"><span class="tag">week10</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/week11/"><span class="tag">week11</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/week2/"><span class="tag">week2</span><span class="tag">15</span></a></div><div class="control"><a class="tags has-addons" href="/tags/week3/"><span class="tag">week3</span><span class="tag">11</span></a></div><div class="control"><a class="tags has-addons" href="/tags/week4/"><span class="tag">week4</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/week5/"><span class="tag">week5</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/week6/"><span class="tag">week6</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/week8/"><span class="tag">week8</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/week9/"><span class="tag">week9</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%9D%BC%EC%83%81/"><span class="tag">일상</span><span class="tag">42</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0/"><span class="tag">자료구조</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%95%A0%EC%9D%BC/"><span class="tag">할일</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">업데이트 소식 받기</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="구독"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="구독"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="KyuBum&#039;s Dev Blog" height="28"></a><p class="is-size-7"><span>&copy; 2022 KyuBum Shin</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("ko");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="맨 위로" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "이 웹 사이트는 귀하의 경험을 향상시키기 위해 Cookie를 사용합니다.",
          dismiss: "무시",
          allow: "허용",
          deny: "거부",
          link: "더 알아보기",
          policy: "Cookie 정책",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="입력 하세요..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"입력 하세요...","untitled":"(제목 없음)","posts":"포스트","pages":"페이지","categories":"카테고리","tags":"태그"});
        });</script></body></html>