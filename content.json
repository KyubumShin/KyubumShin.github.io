{"pages":[{"title":"about","text":"","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"rabbitmq","text":"KDT과정에서 만든 프로젝트의 실사용자가 여럿인 경우를 가정하고(그럴일은 거의 없겠지만) 백엔드를 구성하려고 팀원들과 계획을 해서 Rabbitmq를 사용하기로 결정하여 공부했었던 내용을 정리해 보았다. RabbitMQ는 오픈소스 메세지 브로커로써 메세지를 많은사람들에게 전달하거나, request에 대한 처리시간이 길 때 등 비동기적인 처리를 할 때 사용된다. ModelRabbitMQ는 아래와 같이 AMQP(Advanced Message Queuing Protocol)에 따른 구조로 되어있다. Producer(P) 메세지를 생성하고 Queue에 보내 저장하는 주체이다.Consumer(C) 메세지를 수신하는 주체이다.Exchange(X) Producer로 부터 수신한 메세지를 각각의 키에 따른 규칙(Binding)으로 Queue나 다른 Exchange로 보내주는 라우터의 기능을 가지고 있다. 모든 Queue는 반드시 Exchange를 통해 메세지를 Producer로 부터 전달받는다.Queue(Red Box) 자료구조에서 흔히 들어왔던 큐이다. 메모리에 메세지를 저장하고 Consumer로부터 큐에 요청이 들어오면 저장되었던 메세지를 Consumer에게 전달한다. Exchange Typeproducer로부터 생성된 모든 메세지들은 반드시 Exchange에서 Exchange Type과 Binding 규칙에 따라 규칙에 알맞은 Queue로 전달된다. Exchange Type은 다음과 같은 속성을 가진다. Direct Exchange 메세지에 포함된 routing Key를 기반으로 동일한 binding key를 가진 Queue에 연결된다. Fanout Exchange Exchange에 연결된 모든 Queue에 동일한 메세지를 전달한다. Topic Exchange routing Key와 binding Key가 부분적으로 일치하는 모든 Queue 로 메세지를 전달한다. 닷( . )으로 구분된 binding key를 사용하며 *와 #을 이용하여 binding Key를 구성할 수 있다. *은 한개의 단어를 나타내고 #은 0개 또는 1개의 단어를 나타낸다. Header Exchange key-value 로 정의된 헤더에 의해서 전달할 Queue를 결정한다. Queue를 바인딩 할 때 x-match라는 argument로 헤더를 하나만 충족켜도 되는지(any : OR의 기능), 모든 헤더를 충족시켜야 하는지(all : AND의 기능) 규칙을 정할 수 있다. reference AMQP Introduction RabbitMQ Tutorials RabbitMQ란? by Eric","link":"/2021/09/22/rabbitmq/"},{"title":"todolist","text":"9월 해야하는것 딥러닝관련 공부(하고싶은것 우선적으로) 강화학습관련 공부(policy 기반 학습관련해서 공부, MARL관련 논문보기) http://rail.eecs.berkeley.edu/deeprlcourse-fa19/resources/ GNN 관련 개요 알아보기 -&gt; 유사도 기반 추천시스템에서 사용하려고함 http://web.stanford.edu/class/cs224w/index.html#schedule python 메모리 관리(malloc, free 등), asyncio 공부 현재 하고있는것 DP관련 문제 풀기 백준 DP 문제집 푸는중 배운것 정리하기(너무 미루는거같아서 하루에 1포스트씩이라도 정리하자) Stargan-V2 논문 정독 카카오 블라인드 2022 자체 피드백: cs 공부 cs 공부(되세김질 기술면접대비) 코딩테스트 대비 알고리즘 공부 및 정리(점점 늘어날 예정) 힙, 큐, 스택 트리 DFS, BFS 플루이드 와샬 알고리즘 다익스트라 알고리즘 이진탐색 LIS A* 알고리즘 인터넷 찾다가 공부하고 싶은것 B+ Tree 백엔드 관련 공부(KDT 프로그램 최종 프로젝트 관련) rabbitmq, fastapi, celery 도커, 도커 컴포즈 공부 한것 코세라 딥러닝 강의 수료 : 복습하는 느낌이라 2일만에 끝내긴 했는데 좋았다 KDT 마지막 프로젝트 GAN 임시 테스트 데이터셋으로 학습시키기 : 결과가 나오는것을 보았는데 정말 행복했다. 일주일동안 라벨링만했는데 보상 받는 기분 KDT 과정 마지막 프로젝트 진행 : 어느정도 결과가 나오게 무사히 끝난거같다. 팀원들과 유지보수, 보완에 대해 토의해서 주기적으로 보안하는 코드를 작성할 예정 코딩테스트 대비 알고리즘 공부 및 정리(점점 늘어날 예정) 링크드 리스트 카카오 블라인드 2022 준비 : 1차 준비 : 4.5솔로 솔직히 잘본건 아니었는데 붙어서 다행이었다. 2차 준비 : 참신한 문제여서 재미는 있었는데 리더보드로 인한 압박감이 너무 컸다. 면접 볼수 있으면 좋겠다. 아직 내 cs상식이 좀 부족한거같았다. 열심히 면접대비cs지식을 보면서 공부했는데 모르는것만 나오더라…","link":"/2021/08/31/todolist/"},{"title":"10-03-TD","text":"10/03백신을 맞은 다음에 아직 컨디션이 완전히 돌아오지는 않아서 오늘은 간단하게 강화학습 책을 다시 한 번 읽었다. 아직 정리할 정도로 이해한것 같지는 않다. PRML책도 같이 읽어서 복습해야 할 것 같다. +정리한것 멀티프로세스와 멀티스레드","link":"/2021/10/03/Diary/10-03-TD/"},{"title":"10-02-TD","text":"10/02오늘은 팀원들과 함께 모의 코딩테스트를 시행하였다. 푼 문제 오큰수 : stack문제 탑 : stack 문제 (오큰수 반대) 강의실 배정 : Heap, 그리디 쇼핑몰 : Heap 부분합 : Two pointer 추후에 정리해서 깃허브에 업로드할 예정이다. 강화학습에 대해서 공부를 다시 시작하였다. 가치기반 학습에 대해서는 예전에 많이 공부를 해두어서 복습하는 느낌으로 공부를 하였고, 이번에는 저번에 공부할때 조금 부족했던 정책기반학습을 위한 Policy Gradient를 이해하기 위해 중점적으로 할 예정이다. 추후에 포스팅을 할 예정이다. 백신을 맞고 2일정도 누워있어서 오랜만에 CS - OS 에 관하여 포스팅을 하였다. 프로세스와 스레드","link":"/2021/10/02/Diary/10-02-TD/"},{"title":"10-04-TD","text":"10/14일오늘은 GAIL(Generative Adversarial Imitation Learning) 논문을 읽기 시작했다.이 논문을 읽기전에 여러 기초 지식들이 필요하다는것을 뼈저리게 느꼈지만 일단 헤딩하는 느낌으로 논문을 읽어나가면서 부족한 지식을 채워나가는 방식으로 글을 작성하려한다.지금까지 이해한 부분 간단하게 3줄 요약 GAIL은 imitation learning의 방법중 하나로써 기존의 Inverse Reinforce Learning(역강화학습 : 전문가의 행동데이터를 기반으로 Reward function을 복원하여 최적의 Policy를 얻어내는 학습)의 단점인 전문가의 행동데이터에서 간접적으로 학습을 하기때문에 소요시간이 크다는 점을 해결한 논문이다. imitation learning과 GAN의 유사점에서 착안하여 데이터로부터 직접적으로 Policy를 학습함 GAN과 비슷하게 Discriminator와 Generator(논문상에서는 TRPO)가 존재한다. Generator는 점점 더 샘플링된 전문가의 행동처럼 움직임을 결정하게 학습을 한다. 다른 역강화학습에 비해 상대적으로 적은양의 샘플로도 좋은 성능을 내었음 아직 수직적으로는 이해하지 못한부분이 많아서 여러번 정독을 해야할것 같다. 그리고 역강화학습 자체도 내가 대략적으로 개념정도만 공부한 상황이라 논문을 이해했다고 이야기 하기 위해서는 더 조사할 필요성을 느낀다.관련된 지식에 대하여 포스트를 작성할 계획이다. Paperhttps://arxiv.org/abs/1606.03476 +정리한 CS 지식 Array &amp; ArrayList &amp; LinkedList","link":"/2021/10/04/Diary/10-04-TD/"},{"title":"10-06-TD","text":"10/06일오늘도 어제에 이어서 gitlab에서 project의 CI/CD pipeline를 설정하는데 시간을 들였다.어제 하루동안 잘만 돌아가던 gitlab runner가 영문을 알수없게 갑작스럽게 터진데다가 몸상태가 좋지않아서bulid까지만 성공시키고 unittest는 성공하지 못하고 중간에 기절해서 자버렸다.dind 방식에서 unittest를 어떻게 사용해야할까 고민해 보았는데 1docker run --entrypoint 명령어를 이용하여 내부에 있는 unittest용 파일을 python을 통하여 활성화시켜주는 방향으로 할 생각이다.오늘은 docker 관하여 공부했었는데 아직 글을쓰기까지 조금 시간이 걸릴것 같다.","link":"/2021/10/06/Diary/10-06-TD/"},{"title":"10-05-TD","text":"10/05일KDT에서 만든 프로젝트를 Gitlab runners 를 이용하여 pipeline을 구축하는 연습을 하였다.모듈별로 각자 runner를 이용하여 pipeline을 구축하여 unittest를 해서 제대로 돌아가는지를 판단한 뒤추후에 runner를 하나로 묶어서 프로젝트를 배포할 예정이다.+강화학습 Policy Gradient에 대하여 정리중 오늘 발생했던 문제docker in docker 를 사용하는데 자꾸 host를 못잡는 현상이 벌어짐 원인Docker의 Container는 기본적으로 Host에서부터 독립된 namespace를 가지고 있어서 Host시스템에 주요자원에 접근할 수 없음우리는 Docker in Docker구조로 생성하였기 때문에 내부의 컨테이너가 아무리 애를 써도 docker host에 접근 할 수 있는 권한이 없다. 해결방법docker 의 privileged 옵션을 활성화 시켜서 host의 자원에 접근할수 있도록 해준다 추가로 찾아볼 것dind(docker in docker)","link":"/2021/10/05/Diary/10-05-TD/"},{"title":"10-07-TD","text":"10/07일오늘도 gitlab에서 CI/CD pipeline 구축 체험을 해보았다. (CI/CD에 대해 조금 알아보았는데 지금하는건 체험 수준)오늘 작업을 하면서 알게된점에 대해서 적어보려한다. gitlab에는 안전한 업데이트(?)를 위한 기능으로 protected branch, protected tags를 지원한다. protected branch마스터, 메인브랜치 같은 언제나 잘 작동하는 올바른 코드가 올라가 있어야 하는 브랜치를 특정 행동으로부터 보호하기 위한 조치이다.protected branch로 설정하면 항상 올바른 커밋을 push나 merge 하기 위해 룰을 지정할 수 있다.ex) Pull Request를 merge하기전에 항상 코드리뷰를 n명의 리뷰어에게 거쳐야 하거나, CI 테스트를 통과한 브랜치만이 merge가능하다. protected tagsprotected branch와 비슷하게 잘못해서 코드를 업데이트 하거나 삭제하는것을 예방할수 있다.gitlab 에서 Protected tags는 삭제하는것이 불가능하다.(강제로 할 수는 있는데 권장하지 않음)보통 CI/CD를 통과하고 release할 branch에 release version으로 tag를 단다.직접 protected tags로 지정하거나, wildcrads를 이용하여 특정 규칙을 만족하면 protected tags로 설정하는것이 가능하다. CI(Continuous Delivery)CI(지속적인 통합)이라고도 한다. CI를 통하여 개발자들은 협업을 하면서 코드의 변경 사항을 공유브랜치로 병합하는 작업을 더욱 수월하게 수행할 수 있다.개발자가 push한 변경사항이 병합될때 이 변경사항이 기존의 애플리케이션을 손상시키지 않도록 pipeline을 통한 테스트를 한다. CD(Continuous Delivery or Deployment)CD(지속적인 제공)는 유효한 코드를 repository에 자동으로 릴리즈한다.CD(지속적 배포)는 repository에 릴리즈된 유효한 코드를 자동으로 실행하는것을 말한다.애플리케이션을 배포할때 애플리케이션 전체를 한번에 실행하는것이 아닌 작은조각(모듈)으로 나누어 실행하면 좀더 리스크 관리를 하기 쉬워진다. 출처RedHat - what is ci/cd","link":"/2021/10/07/Diary/10-07-TD/"},{"title":"10-11-TD","text":"10/11일주말동안 stargan + Wasserstein GAN(WGAN) 논문을 정독해서 읽기 시작하였다.multi domain image to image Translation 을 실현시킨 Stargan과 GAN의 loss함수를 Earth Move distance(EMD)로 설정을 하여 Discriminator 와 Generator 간의 불균형 문제를 해결한 WGAN에 대하여 간략하게 정리하려고 한다.(요약이 아닌 리뷰포스트는 현재 WGAN을 보면서 작성중이다.) StarGAN논문 요약 여러 domain 간 변환을 1개의 Generator를 이용하여 변환할 수 있는것을 목표로 하는 논문이다. Discriminator는 Real/Fake를 판단하는 것 뿐만아니라 domain Classfication(이 이미지가 어떤 domain에 속해있는지)까지 학습 해야한다. 두개의 Generator를 사용하여 Cycle을 형성하여 학습하는 CycleGAN과 달리 하나의 Generator로 Fake image를 생성, Fake image와 기존 Source Image의 도메인 정보를 이용하여 다시 재구성을 하여 사이클 구조를 이룬다. 그래서 3개의 Loss function을 조합하여 Generator와 Discriminator를 학습시킨다. $\\mathcal{L}_{abv}$ 는 Adversarial Loss(minmax Loss) : 기본적인 GAN Loss, Cross Entropy에서 가져와 변형시켜서 만들었다. 실제로 학습시킬때는 WGAN의 EMD를 변형시켜서 Loss function 으로 사용했다. Domain Classification Loss : Classfication loss(Cross Entropy Loss) Reconstruction Loss : CycleGAN의 Cycle consistency loss를 사용(생성된 이미지를 다시 원래 source 이미지로 되돌렸을때 발생하는 차이에 대한 척도) starganhttps://arxiv.org/abs/1711.09020 WGAN은 좀 더 시간이 필요할듯 하다.막상 요약해서 쓰려고 하니까 수학적 베이스가 많이 필요한데 아직 내가 정리할 정도로 이해를 한것 같지 않다. +오늘 공부 하면서 조금 더 조사해봐야겠다 생각되었던 부분 OS 어떤구조를 가지고 있는지 (Linux, Windows에 관하여 이왕이면 차이도 조사하면 좋을것 같다) : 내부의 프로세스, 스케줄링, 페이징 교체 작업 같은 세부적인건 어느정도 설명이 가능한데 os가 전체적으로 어떤 구조인지 이야기 하라고 하면 못 할것 같다. 커널에 대해 지식이 부족함을 느꼈다. 대략적으로는 아는데 자세하게는 못말하는 느낌이다. 한번 자세히 조사할 필요가 있다고 생각한다. 각종 Loss 함수에 대한 공부(이 함수가 어디에서 비롯되었는지 궁금해졌다.) Duality 등의 WGAN에 대한 수학적 베이스에 대한 공부(Lipschitz조건, Kantorovich-Rubinstein duality)","link":"/2021/10/11/Diary/10-11-TD/"},{"title":"10-12-TD","text":"10/12일WGAN을 읽으면서 아직 이해못한 부분들을 이해하기 위하여 GAN 논문의 Loss 함수부분을 중점적으로 읽어보았다. GAN 논문 요약 GAN 논문은 Discriminative model $D$ 와 Generative model $G$로 이루어져서 $D$는 생성된 이미지와 원본 이미지를 구별해 내는 방향으로 학습, $G$는 $D$가 생성한 이미지와 원본 이미지를 구별하지 못하도록 학습시키는 것을 목표로 한다. -&gt; 두 모델이 적대적으로 학습하는 방식이기 때문에 Generative Adversarial Nets(생성적 적대 신경망)이라고 이름이 붙었다. 최종적으로 생성한 데이터의 분포를 실제 데이터의 분포에 가깝게 만드는것을 목표로 한다. Kullback-Leibler divergence(KL divergence)를 기반으로한 Jensen Shannon Divergence(JS divergence)를 사용한다. (KL divergence는 비대칭적이기 때문에 metric으로 사용하기 부적절하다) WGAN 논문 요약 기존 GAN Loss function을 개선하여 GAN의 성능을 끌어올린 논문이다. JS divergence는 두 확률분포(생성한 데이터, 실제 데이터의 확률분포)가 겹치지 않을때 상수값 $log2$를 가진다. 이것은 데이터분포간의 거리가 아무리 멀거나 가깝거나 상관없이 겹치지 않으면 상수값을 가지기 때문에 학습이 제대로 이루어지지 않을 가능성이 높다. 기존의 GAN 모델에서는 겹치는 부분을 만들어주기 위해 노이즈를 추가하여 데이터의 분포를 강제적으로 늘려주었다. -&gt; 생성된 이미지가 흐려지거나 하는 문제들이 발생함 그래서 WGAN에서는 Earth Mover distance 라는 거리 mertics를 제시하였다. 자세한 부분은 따로 포스트를 할 예정이다.","link":"/2021/10/12/Diary/10-12-TD/"},{"title":"9&#x2F;25-일기","text":"9/25일카카오 2차 시험을 보았다.문제는 밝힐수 없지만 흥미로운 주제였다. 하루종일 시험을 보면서 더 공부해야할게 많다라는 점과 정말 잘하는사람은 엄청 잘하더라 알고리즘 어케 짰을지 궁금하다 라는 생각이 들었다.그리고 리더보드는 정말 압박감이 심하더라… 필기시험과 api코딩테스트를 같이 봤는데생각보다 내 cs 지식이 빈약한것을 느낄 수 있었다.그래서 오늘 이런것들을 찾아서 정리해 보았다.조금더 있는데 시험본다고 너무 피곤해서 내일 남길 예정이다. 데이터베이스 Key Post not found: database-key 데이터베이스 Key 부분 키(Partial Key) 또는 식별자(Discriminator) 상위 개체 타입이 결정되지 않으면 개별 개체를 식별할 수 없는 종속적인 개체 타입 독립적인 키로는 존재할수 없지만, 상위 개체의 타입의 키와 결합하여 약한개체 타입의 개별개체를 고유하게 식별하는 속성 약한 개체 타입 상위개체타입이 결정되지 않으면 개별 개체를 식별할 수 없는 종속적인 개체타입 ex) 프로리그 축구단의 소속된 선수의 등번호 등번호만 놓고 보면 다른축구단에도 같은 번호가 존재 할 수 있지만, 특정 축구단의 소속된 선수의 등번호는 단 하나만 존재한다. -&gt; 개별개체를 식별가능 Http status code 100 : 조건부 응답 200 : 성공 300 : 리다이렉션 완료 400 : 클라이언트 에러 500 : 서버 에러추후에 Fastapi 정리하면서 한번더 정리할 예정","link":"/2021/09/25/Diary/9-25-TD/"},{"title":"9&#x2F;26-일기","text":"9/26일다 지나가서 27일 오전 1시에 쓰는 일기 카카오 준비한다고 몇 일 동안 하지 못했던 KDT 프로젝트 유지보수를 다시 시작하였다.카카오 준비 직전에 바쁘다고 정신이 없었는데 그 때 ssh키를 모르고 커밋을 해버려서 팀내에서 새로 규칙을 정해서 브랜치를 정리했다. (미안….)(private key 파일을 다행(?)히도 push 까지는 하지 않았고, 사용하는 repository가 private라 큰일은 없어서 다행이었다.)가볍게 git을 공부했었는데 제대로 공부할 필요성을 느낀다.무엇보다 git add . 이거 쓰면 안될거같다. 오늘 공부한것1. Hash Table (추후에 자세히 정리예정) python dictionay structure 파이썬 내부에서 dictionary는 어떻게 돌아가나? dictionary와 hashtable 차이 Boxing/UnBoxing을 하나 안하나 충돌 처리기법 Open Hashging Chaining : linked list 이용 Close hashing(Open Addressing) Linear probing Quadratic probing Double hashing 1. 깃 브런치 복습(https://learngitbranching.js.org/?locale=ko)","link":"/2021/09/27/Diary/9-26-TD/"},{"title":"9-27-TD","text":"9/27일오늘은 최종프로젝트를 자동빌딩 시키기 위해 CI/CD 의 하나인 Bitbucket runners에 대해서 조사했다. 하지만 Bitbucker Image에 Docker가 안깔려있어서 빌드되는것을 확인하는데에는 실패 하였다. KDT과정이 끝나고 아마존이 아닌 싼 VPS에서 모델을 돌리려 하다보니 이런저런 제약사항이 뒤따르고있다. 모델이 많이 무거워서 모델 경량화에 대해서 한번 공부할 필요성을 느꼈다.그리고 Git 명령어에 대해서 공부했다.(저번에 저지른 사건을 잘 처리하기 위해서) 오늘 한것 Hash Table 정리 해쉬 테이블","link":"/2021/09/27/Diary/9-27-TD/"},{"title":"9-28-TD","text":"9/28일오늘은 어제의 연속으로 bitbuckit runners와 pipeline을 다루었다.아직 다룬지 얼마 안된것과 도커에 대해 자세히 모르기 때문에 runner를 실행시킬때마다 빌드실패의 늪에 빠지게 되었다. SSH private key를 도커컨테이너 내부로 전달을 했어야 했는데 미숙하여 환경값으로 저장까지는 했으나 제대로 보내지 못하였고, 여러 커뮤티니에 비슷한것들을 찾아 다니던 끝에 ssh private key는 넘겨 줄 수 있었지만, 이제는 컨테이너끼리 메세지큐를 보내는곳에서 에러가 발생했다. 해결한 문제bitbucket-pipelines.yml12345678910pipelines: branches: name: -step: script: - docker build --tag tag:1.5 --build-arg ssh_prv_key=&quot;$(echo $SSH_PRV_KEY | base64 --decode)&quot; . services: - docker - redis - rabbitmq 1234567FROM pytorch/pytorch:1.7.0-cuda11.0-cudnn8-runtimeARG ssh_prv_key # 여길 빼먹음RUN mkdir -p -m 0600 /root/.ssh \\ &amp;&amp; ssh-keyscan bitbucket.org &gt;&gt; /root/.ssh/known_hosts \\ &amp;&amp; echo &quot;$ssh_prv_key&quot; &gt; /root/.ssh/id_ed25519 \\ &amp;&amp; chmod 0600 /root/.ssh/id_ed25519 도커파일을 빌드하는 과정에서 argument 를 받아오긴 했는데 도커파일 안에서 선언은 하지 않아서 계속 에러가 발생했다. ARG and ENV의 차이ARG와 ENV의 가장 큰 차이점은 빌드를 하고난 다음에도 사용이 가능한가? 의 차이이다. ARG는 빌드시에만 쓰이는 argument이며 ENV는 빌드가 끝나고도 사용 가능한 환경변수라고 생각할 수 있다. Dockerfile이 아닌 명령어로 빌드를 할때는 arg만 가능하고, run을 할때는 env의 선언만 가능하다. ARG Dockerfile에서만 사용되는 변수 선언 docker build 시에 –build-arg 옵션을 활용하여 오버라이딩 할 수 있다. ENV Dockerfile뿐만 아니라 컨테이너 내에서 사용가능한 변수 선언 docker run 시에 –e 옵션을 활용하여 오버라이딩 할 수 있다.","link":"/2021/09/28/Diary/9-28-TD/"},{"title":"9-29-TD","text":"9/29일오늘은 백준 알고리즘 문제 2개정도 풀고 예전에 KDT에서 한번 해보고싶었는데 시간 난이도 등의 문제로 포기한 multi labeling 관련 논문들을 검색해 보았다. 조만간 시간을 내서 읽어보고 한번 포스팅을 할 예정이다. 그리고 음(mm)에서 이벤트로 카카오 Brain 대표 Curtis [Unthinkable Question] 나는 왜 ai개발자로 전향했을까를 들었다. Curtis에 관한 여러가지 개인적인 이야기도 있었고, Brain에서 어떤 일을 하는가, 질문시간을 통한 ai의 방향, 학부생의 공부 방향 등등의 이야기가 있었는데, 무엇보다 기억에 남았던것은 자기자신을 특별하게 만들기 위해서 해야할 일이었다. 남들이 만들어놓은 길에서 조금만 벗어나도 유니크해진다.+ The Hacker way이 말을 듣고 나의 경쟁력은 무엇이 될 수 있을까에 대해 시간을 내서 한번 고민을 해봐야겠다고 다짐했다. 또 그동안 하면 좋겠다 라고 생각해놓고 아직 내 실력이 부족한거같으니까 좀더 공부하고 하자 라고생각했던 기술관련 공부등을 다시 시작해야겠다. Multi Agent RL Multi label Classfication GAN 과 RL의 결합 인공지능에 대해서 본격적으로 공부하기로 마음먹은지 1년이 조금 넘은 시간이 흘렀는데 하면 할수록 인공지능이라는 탑이 너무나도 높아보이고, 탑을 올려보는동안에도 조금씩 높아지는것이 눈에 보여서 한동안 슬럼프에 빠졌었던 때도 있었다. 내가 잘하고있는걸까 생각도 많이했었고, 거의 혼자서만 공부를 해오다보니 내 실력은 어느정도일까 의구심도 많이 들었다. 오늘 이 라디오(?)를 들으면서 걱정은 줄고 고민할 거리가 많이 늘어난 느낌이다.","link":"/2021/09/29/Diary/9-29-TD/"},{"title":"Garbage collection","text":"서론이 글에서는 Python의 Garbage Collector에 대해서 다룬다. Garbage collectionGarbage Collector(이하 GC)는 메모리 관리 기법중 하나로 동적으로 할당했던 메모리 영역 중에 필요없게 된 부분을 해제하는 기능이다. C, C++등의 언어들은 수동메모리 관리를 전재로 설계되어 malloc, free등의 함수로 직접 메모리를 관리 해주어야 하지만, Python, Java, C# 같은 고급 언어들은 GC가 내장되어 있어 자동으로 메모리 관리를 해준다. Python GC의 작동방식Python의 GC는 reference count + Generational GC 방식으로 메모리를 관리한다. reference count 12345typedef struct _object { _PyObject_HEAD_EXTRA Py_ssize_t ob_refcnt; /* reference count */ struct _typeobject *ob_type;} PyObject; python의 객체들은 모두 reference count를 가지고 있으며 이것을 통해서 GC가 언제 메모리에서 제거할지를 판단한다. 참조가 이루어지면 reference count가 1증가하고, 참조가 끝나면 1감소한다. 최종적으로 0이 되면 GC에서 더이상 필요없는 오브젝트로 판단하고 메모리에서 삭제한다. 이러한 방식은 프로그래머가 어느정도 오브젝트의 메모리 할당 해제 시점을 유추 할 수 있고, 대부분 사용된 직후 해제되기 때문에 캐시에 저장되어 있을 확률이 높아 빠르게 할당 해제가 이루어지는 장점이 존재한다. 하지만 아래와 같은 단점 또한 존재한다. 두개 이상의 객체가 서로 가리키고 있을 경우(순환 참조) reference count가 0까지 내려가지 않는 상황이 발생 할 수 있다. 또한 Multi Thread 환경에서는 공유자원에 대한 참조가 되기 때문에 추가적인 Lock 등이 필요하거나, 지속해서 GC에서 판단하는 프로세스를 거쳐야 하기 때문에 수행 성능의 저하 등의 문제가 발생 할 수 있다. 이러한 단점들을 해결하기 위해 Python에서는 순환 참조를 탐지하는 알고리즘과, 보조적인 Generational GC를 두었고, GIL로 Multi Threading에 제한을 걸어 버렸다. Generational GC 새롭게 할당된 오브젝트일수록 금방 메모리에서 해제될 확률이 높다는 통계에서 기반한 메모리 관리방법이다. 각각의 오브젝트가 GC가 실행하고나서 메모리에서 해제되지 않으면 다음 세대로 넘어가게 되는 방식인데 더 젊은 세대(금방 생성)일수록 자주 GC의 프로세스에서 할당 해제할 오브젝트인지 판단이 내려지게 된다. 이 과정을 보조적으로 추가하면서 python에서는 조금더 효율적으로 메모리를 관리 하고 있다. reference Garbage Collection in Python Garbage collection (computer science)","link":"/2022/02/02/python/GC/"},{"title":"Global Interpritor Lock","text":"GIL. Global Interpritor Lock.Global Interpritor Lock(GIL)이란 Python에서 오직 하나의 Thread만 동작하도록 컨트롤하는 Lock(또는 Mutex)이다.이 말은 타임라인상에 오직 하나의 Thread만 실행될 수 있다는 것을 말한다. Single Thread를 사용하는 코드에서는 그렇게 큰 영향을 주지 않지만, Multi-Thread를 사용하는 코드에서는 병목현상을 일으킬 수 있다. GIL이 어떻게 동작하는지 한번 살펴보자위에서 이야기 한 것처럼, GIL에서는 오직 하나의 Thread만 활성화되어서 코드를 실행하는데 이는 아래의 그림처럼 그려낼 수 있다. Thread가 전환 될 경우에는 기존의 Thread의 작동이 멈추고 동작을 시작하게 된다.기존의 하던 작업들을 멈추고 다른 Thread로 넘겨야 하기 때문에 context switch가 일어나게 된다. 그러면 왜 GIL을 사용할까?먼저 왜 GIL을 사용하는지 알기 위해서는 Python의 Garbege Collector(GC)에 대해 알고 있어야 한다. (GC에 대한 자세한 내용은 추후에 다룰 예정이다) 고급언어인 python에서는 C언어와 다르게 자동으로 메모리 관리를 해주는 GC라는 것을 사용한다. 이 GC는 오브젝트가 얼마나 많이 참조(실행)가 되었는지를 카운팅하는 reference count 라는 것으로 메모리에서 삭제할지 유지할지를 결정한다. 하지만 동시에 여러군데에서 참조가 이루어 질 경우 Race Condition 등의 문제들이 발생 할 수 있기 때문에 이를 방지하기위해 Mutex나 Semaphore등의 Lock이 필요했는데 이것을 Python에 존재하는 수많은 Object에 전부 적용하는것은 성능상으로도 좋지 않을 뿐만 아니라, Deadlock 같은 매우 치명적인 위험상황이 발생 할 수 있었다 그래서 선택한것이 따로 Object에 Lock을 두지 않고, 타임라인에서 실행되는 Thread를 딱 하나만 두도록 Interpritor를 Mutex로 잠궈버렸다. 이렇게 되면 여러곳에서 동시 참조가 되지않으니 성능의 하락 없이 위의 동시참조의 문제를 해결하게 된것이다 그러면 python에서는 병렬화된 코드는 어떻게 써야하나 Multi Process를 사용한다Thread를 막아버린것 이기 때문에 Multi Processing을 사용하면 잘 돌아간다. 물론 Process간에 공유자원을 가지기 위해서는 많은 작업들이 필요로 하기 때문에 context switching이 발생하여 Thread에 비해 속도가 늦을 것이다. 하지만 Windows는 OS 보안상 이유로 이걸 막아버렸다. Multi Threading을 사용한다아까 Multi Threading을 막아놨다고 했는데 뭔 소리냐 할 수 있지만, CPU에서 대부분의 연산이 돌아가는 코드를 제외한 I/O Bound 계열의 문제들은 file system과 Network의 하위 컴포넌트에서 돌아가기 때문에 Single보다 더 빠르게 진행 할 수 있다. 굳이 사용하고 싶다면 PyPi나 Jython 같은 다른 Python implementation으로 사용하는 방법도 존재하지만, 그 코드가 python에서와 똑같이 동작할 보장은 없다 그리고 numpy나 Scipy등의 ML에서 많이 사용하는 Module들은 C기반으로 만들어져서 GIL의 굴레에서 자유롭게 연산이 된다고 한다. reference 왜 Python에는 GIL이 있는가 What Is the Python Global Interpreter Lock (GIL)?","link":"/2022/01/28/python/GIL/"},{"title":"Functools.Partial","text":"과제를 하다가 functools의 partial을 쓸 기회가 있었는데 오류를 뱉어서 나름대로 해결을 하고 정답지를 보니 작성한 코드가 달라서 한번 조사해보고 쓰는 글입니다. Functools의 Partial에 대해 알아보자 functools Module의 내장 함수인 Partial은 기존에 존재하는 함수에 추가적인 인수를 지정하여 새로운 버전의 함수로 만들어주는 기능을 가지고 있다. Partial의 예시말로만 설명하면 이해하기 힘드니 코드와 같이 보자 다음과 같이 n진수를 10진수의 형태로 바꾸어 주는 함수가 있다고 하자 12def to_int(num, base): return int(num, base=base) 이때 특정한 수 2와 3을 Base로 하는 함수를 원한다고 할 때 다음과 같이 사용할 수 있다. 12345def two_to_int(num): return to_int(num, base=2)def three_to_int(num): return to_int(num, base=3) 하지만 매번 특정한 수를 Base로 하는 함수를 이렇게 여러줄로 정의하면 코드의 줄도 길어지고 귀찮을수 있는데 이때 Partial을 사용하면 다음과 같이 함수를 새로 정의할 수 있다. 1234567two_to_int = partial(to_int, base=2)three_to_int = partial(to_int, base=3)two_to_int(&quot;10&quot;)2three_to_int(&quot;120&quot;)15 내부 구조Partial 함수는 아래 코드와 같이 정의되어있다 여기서 2가지 방법으로 함수의 인자를 미리 설정할 수 있다. partial(함수이름, 변수) newfunc.args에 변수를 저장한다 partial(함수이름, 변수명=변수) newfunc.keywords에 변수명이 Key, 변수가 value로 저장된다 기존에 있는 변수를 변수명을 통해서 다시 지정할 때 그 변수의 입력위치가 중간에 존재할 경우 Error가 발생한다 12345678def partial(func, /, *args, **keywords): def newfunc(*fargs, **fkeywords): newkeywords = {**keywords, **fkeywords} return func(*args, *fargs, **newkeywords) newfunc.func = func newfunc.args = args newfunc.keywords = keywords return newfunc 함수가 실행될때는 newfunc.args에 저장된 args, 함수에 입력되는 parameter, newfunc.keywords 순으로 순차적으로 입력된다 123456789101112def tempfunc(one, two, three, four): print(one, two, three, four)a = partial(tempfunc, 1, 2)a(5, 3)output1 2 5 3a = partial(tempfunc, two=1)a(5, 3, 2)outputTypeError: tempfunc() got multiple values for argument 'two' reference Functools 의 Partial 이란? functools — Higher-order functions and operations on callable objects","link":"/2022/03/10/tip/partial/"},{"title":"Activation Function","text":"활성화 함수 Activation Function 실수범위에서 정의된 비선형 함수 딥러닝을 비선형 모델로 만들어주는 결정적인 함수이다 1. softmax 분류 모델에서 많이 사용하는 함수 출력값은 항상 0~1사이로 정규화된다 보통 활성화 함수로는 사용되지 않고 마지막 단계에서 출력을 정규화할때 사용한다.$$f(x)_{k} = \\frac{e^{x_i}}{\\sum_{k=1}^{n}e^{x_{k}}}$$ 2. sigmoid 출력값을 0~1 사이로 변경한다 위의 softmax 함수의 원형 함수의 단점 중심이 0이 아니기 때문에 모든차원이 같은방향으로 이동한다 값이 커질수록 기울기 값이 감소한다$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$ 3. Tanh sigmoid함수의 개량형 중심을 0으로 맞춰서 sigmoid 함수의 단점을 줄였다. 하지만 여전히 기울기 값의 감소에 따른 Gradient vanishing 문제가 존재한다 $$tanh = 2\\times \\sigma(2x) -1$$ 4. ReLU 0보다 크면 그대로 넘기고 작으면 0으로 만드는 매우 간단한 함수 sigmoid 계열에 비해 연산속도가 매우 빠르다 큰값이 와도 기울기 값이 유지되기 때문에 gradient vanishing이 해소되었다. 단점 큰 값이 연속될 수 있는RNN 계열에서는 Gradient exploring이 발생한다. 0 이하의 값이 무시되기 때문에 음수값만 존재하면 weight가 죽어버리는 Dying ReLU현상이 일어난다 $$\\operatorname{ReLU} = max(0, x)$$ 5. Leaky ReLU Dying ReLU 현상을 해결하기위해 고안된 활성화 함수 0보다 작은값에는 $\\alpha$값을 곱한다 GAN 계열의 Generator에서 많이 사용된다 단점 여전한 Gradient exploring $$\\operatorname{Leaky ReLU} = max(\\alpha x, x)$$","link":"/2022/01/22/DL/Basic/activate-function/"},{"title":"pytorch-lightning","text":"","link":"/2022/03/07/DL/PL/pytorch-lightning/"},{"title":"database-key","text":"KEYKey는 데이터베이스에서 조건에 만족하는 튜플을 찾거나 순서대로 정렬할 때 다른 튜플들과 구별할 수 있는 유일한 기준이 되는 Attribute(속성) 1. 슈퍼키(Super Key) 데이터 베이스에서 테이블의 행을 고유하게 식별할 수 있는 속성 또는 속성의 집합 고유하게 식별하는 모든 조합을 나타냄 2. 후보 키(candidate key) 슈퍼 키 중에 더이상 줄일 수 없는 형태를 가진 것 슈퍼 키를 구성하는 속성 중 하나라도 빠지면 유일성을 잃어버리는 조합 기본 키로 선정될 수 있는 후보이기 때문에 후보키라고 이름이 붙여짐 Null 값을 허용할지 안할지는 여러가지 설이 존재함(된다 하는 사람도 있고 안된다 하는 사람도 있음) 3. 기본 키(Primary Key, 주 키) 식별자로 이용하기에 가장 적합한 것을 설계자가 선택 정의한 후보키 후보키중 하나를 설계자가 선택해서 기본키로 삼을수 있음 항상 고유한 값을 가짐 Null 값이 존재하지 않아야함 4. 대리 키(alternate key) 후보 키들중 기본키로 선택받지 못한 나머지 키들 기본키의 조건도 만족하기때문에 언제든지 기본키로 대체될 수 있다. 대체 키(surrogate key)라고도 함 5. 외래 키(외부 키, Foreign Key) 테이블과 테이블을 연결시켜주는 키 여러 테이블을 동시에 분석할때 유용하다 하나의 테이블로 저장할때 발생하는 중복된 데이터 발생을 방지하면서 데이터를 이어줄 수 있다.","link":"/2021/09/25/cs/Database/database-key/"},{"title":"Hash Table","text":"Hash Table1. Hash Table이란해시 테이블은 (Key,value)를 기반으로 데이터를 저장하는 자료구조중 하나이다.해시테이블은 아래의 그림과 같이 Key값을 Hash 함수를 이용하여 고유한 index값으로 변환하고, 이 index에 해당되는 배열(bucket)의 위치에 저장한다. 이런한 구조로 인해 Key값에 Hash 함수를 수행하기만 하면 value값이 저장되어있는 Index를 얻는것이 가능하기 때문에 탐색에 O(1)의 시간복잡도가 소요된다. 2. Hash FunctionsHash 함수는 임의의 길이의 데이터를 고정된 길이의 데이터로 매핑하는 함수이다.Hash Table에서는 Hash 함수를 이용하여 Key에서 부터 고유한 index를 얻는다. 아래에는 간단한 Hash 함수들을 나열해 보았다. Division Method : 가장 간단한 Hash함수중 하나로 Key값을 Bucket의 사이즈로 나누어서 계산한다. Digit Folding : Key의 문자를 ASCII 코드로 바꿔 합한 데이터를 테이블 주소로 사용한다. Multiplication Method : 3. Hash CollapseHash 함수에 서로 다른 입력값을 넣었지만 같은 출력값이 나올경우 발생할 수 있는 상황을 말한다. 이러한 상황이 발생할때 해결방법으로 아래와같은 충돌 처리기법이 존재한다. 3.1 충돌 처리 기법 Open Hashging : 주소 밖의 메모리에 저장 Chaining : 충돌이 발생하면 해당 주소에 linked list 이용해서 연결해 저장하는 방법 데이터를 찾을시에 순차탐색을 해야하는 단점이 생김 Close hashing(Open Addressing) : 테이블 내의 새로운 주소를 탐색하여 데이터를 입력하는 방식 Linear probing : 충돌이 발생할때마다 고정값만큼 이동한 주소에 저장하는 방법 Quadratic probing : 충돌이 발생한 만큼의 제곱값을 폭으로 주소에 저장하는 방법 Double hashing : 해시된 값을 한번더 해싱하여 새로운 주소를 할당하는 방법 referencehttp://www.laurentluce.com/posts/python-dictionary-implementation/","link":"/2021/09/27/cs/datastructure/hash/"},{"title":"Array &amp; ArrayList &amp; LinkedList","text":"Array &amp; ArrayList &amp; LinkedList 의 특징Array(배열) Array는 선언함과 동시에 크기를 함께 적어줘야하는 자료구조이다. Array를 선언하면서 특정 자료형과 배열의 크기를 함께 적어주면 특정 자료형이 들어갈 메모리공간을 미리 할당한다. 데이터를 삭제해도 공간이 남아있다. 장점 미리 주소값(Index)을 할당하다보니 데이터검색이 빠르다. 단점 선언한 크기 이상의 데이터를 가지는것은 불가능하기 때문에 데이터가 늘어나거나 하는 최대사이즈를 알수없는 상황에서 사용하기 부적합하다. ex) c, c++의 배열 ArrayList ArrayList는 크기가 정해져 있지 않다. 데이터에 순서가 Index형식으로 존재한다. 데이터를 중간에 추가하면 기존에 데이터는 Index의 변화가 일어난다. (뒤로 하나씩 밀리거나 당겨지거나) 장점 배열과 같이 Index가 존재하기 때문에 데이터검색이 빠르다. 데이터 검색에 $O(1)$의 시간복잡도 단점 중간에 추가하면 기존 데이터의 Index에 변화가 일어나기 때문에 추가적인 연산이 필요하다. 데이터 추가와 삭제에 $O(n)$의 시간복잡도 LinkedList 각 노드가 데이터와 포인터를 가지고 연결되어 있는 방식으로 데이터를 저장 한방향으로만 연결되거나, 양방향으로 연결, 순환구조로 연결 등의 여러가지 방식이 존재한다. 장점 노드의 연결만 끊어주면 되기때문에 데이터의 추가 삭제가 간단함 시간복잡도 $O(1)$ 단점 특정위치의 데이터를 알기 위해서 처음부터 탐색을 해야하기 때문에 시간이 소요됨 시간복잡도 $O(n)$ 추가 정보","link":"/2021/09/22/cs/datastructure/list-Array/"},{"title":"링크드 리스트","text":"링크드리스트링크드 리스트는 각 노드가 데이터와 포인터를 가지고 연결되어 있는 방식으로 데이터를 저장하는 자료구조이다 장점 원소 추가와 제거가 쉬움 : 시간복잡도 $O(1)$ list의 크기를 가변적으로 사용가능 단점 탐색에는 효율이 좋지 않음 : 특정위치 탐색에 걸리는 시간복잡도 $O(n)$ 결론 가변적으로 자주 변하는 데이터에 사용하면 좋다 종류 단일 연결 리스트 : 단방향으로 포인터가 연결된 리스트 이중 연결 리스트 : 양방향으로 포인터가 연결된 리스트 순환 연결 리스트 : Head와 Tail의 노드가 연결되어 순환구조를 가지는 리스트 구현양방향 리스트로 구현해 보았다. 노드 데이터를 담을 노드를 구현12345class Node: def __init__(self, Data): self.Data = Data self.prev = None self.next = None 리스트 head와 tail은 더미데이터를 넣어주어서 고려할 사항을 줄여줌12345678910111213141516171819202122232425262728293031class linked_list: def __init__(self): dummy = Node(None) self.head = dummy self.tail = dummy self.current = dummy def add(self, data): # 새로운 노드를 추가 newNode = Node(data) self.tail.next = newNode newNode.prev = self.tail self.tail = newNode self.current = newNode def delete(self): # 현재 활성화 노드를 삭제하고 리턴 next_node, prev_node = self.current.next, self.current.prev if next_node != None: next_node.prev = prev_node prev_node.next = next_node return self.current def delete_n(self, n): # n번째 노드를 삭제하고 리턴 current = self.head.next for _ in range(n-1): current = current.next def prev(self): # 활성화 노드를 prev로 이동 self.current = self.current.prev def next(self): # 활성화 노드를 next로 이동 self.current = self.current.next","link":"/2021/08/28/cs/datastructure/linked-list/"},{"title":"OSI 모델","text":"1. OSI 모델이란?컴퓨터 네트워크 프로토콜 디자인과 통신을 계층으로 나누어 설명한 것이다. 각 계층은 하위 계층의 기능만을 이용하고, 상위 계층에게 기능을 제공한다. 일반적으로 하위 계층들은 하드웨어로, 상위 계층들은 소프트웨어로 구현된다. 1.1 7계층으로 나눈 이유통신이 일어나는 과정을 단계별로 파악할수 있고, 특정한 곳에 이상이 생기면 이상을 탐지하기 쉽고, 이상이 생긴 단계만 고칠수 있기 때문이다 1.2. 계층단계 물리 계층 네트워크의 기본 하드웨어 전송기술로 구성 높은 수준의 기능의 논리데이터 구조를 기초로 한다 하드웨어 기술이 접목되어있어 OSI 아키텍쳐중 가장 복잡한 계층이며 필수적이다 전송단위는 Bit이다 리피터, 케이블, 허브 데이터 링크 계층 Point to Point 간 신뢰성 있는 전송을 보장하기 위한 계층 네트워크 위의 개체들 간 데이터를 전달한다. 물리계층에서 발생할 수 있는 오류를 찾아내고 수정하는데 필요한 기능적, 절차적 수단을 제공한다. 주소값은 물리적으로 할당받는다.(MAC address) 네트워크 브릿지나 스위치 등이 이계층에서 동작한다. (Ethernet) 전송단위는 Frame 네트 워크 계층 여러개의 노드를 거칠때마다 경로를 찾아주는 역할을 하는 계층으로 다양한 길이의 데이터를 네트워크들을 통해 전달하고, 그 과정에서 전송 계층이 요구하는 서비스 품질(QoS)을 제공하기 위한 기능적, 절차적 수단을 제공 라우팅, 흐름 제어, 세그멘테이션(segmentation/desegmentation), 오류 제어, 인터네트워킹(Internetworking) 등을 수행한다 IP부여, 경로설정(Route) 전송단위는 Datagram(Packet) 전송 계층 양 끝단(End to end)의 사용자들이 신뢰성있는 데이터를 주고 받을 수 있도록 해 주어, 상위 계층들이 데이터 전달의 유효성이나 효율성을 생각하지 않도록 해준다. TCP/UDP프로토콜을 사용한다. 전송 단위는 Segment이다. 여기까지가 물리 계층이라고 한다. 세션 계층 양 끝단의 응용 프로세스가 통신을 관리하기 위한 방법을 제공한다. TCP/IP 세션을 만들고 없애는 책임을 진다. 통신을 하기 위한 세션을 확립/유지/중단 표현 계층 코드 간의 번역을 담당하여 사용자 시스템에서 데이터의 형식상 차이를 다루는 부담을 응용 계층으로부터 덜어 준다. 인코딩이나 암호화등의 동작이 이루어진다. 송신층과 수신측 사이에서 데이터의 형식(png, jpg, webp 등등) 을 정해준다. 응용 계층 응용 계층(Application layer)은 응용 프로세스와 직접 관계하여 일반적인 응용 서비스를 수행한다. DHCP, DNS, FTP, HTTP","link":"/2021/09/24/cs/network/Network/"},{"title":"TCP&#x2F;UDP","text":"2. TCP/UDP2.1 TCP 전송 제어 프로토콜2.1.1 TCP개요 인터넷 상에서 데이터를 메세지의 형태(TCP 세그먼트)로 보내기 위해 IP와 함께 사용하는 프로토콜 IP와 함께 TCP/IP라는 명칭으로 불린다. IP가 주소를 통해 데이터의 배달을 한다면 TCP는 패킷을 추적 및 관리하는 역할을 한다. 2.1.2 TCP특징 연결형 서비스로 연결이 성공해야지만 통신 가능(3 &amp; 4 way Handshaking : 연결설정, 연결해제) 데이터의 경계를 구분하지 않음 신뢰성이 있다 패킷손실, 중복 순서바뀜을 보장 -&gt; 정확한 데이터 전달 가능 흐름제어 및 혼잡제어를 제공 흐름제어 : 송신처와 수신처의 데이터 처리속도를 조절하여 수신자의 버퍼 오버플로우를 방지 수신측의 처리속도보다 송신속도가 빠를경우 도착한 데이터가 손상될 가능성이 존재 수신자가 송신자에게 자신의 상태를 feedback 해서 속도를 조절한다. 혼잡제어 : 네트워크 내의 패킷수가 넘치지 않도록 방지 낮은속도로 전송하기 시작해서 속도를 올림 Full-Duplex(전송이 양방향으로 동시에 일어날 수 있음), Point to Point(연결이 정확히 2개의 종단점을 가지고 있음) ex) 파일전송 2.2 UDP 사용자 데이터그램 프로토콜2.2.1 UDP개요 데이터를 데이터그램 단위로 처리하는 프로토콜 -&gt; 전송계층 비연결형, 신뢰성 없는 전송 프로토콜이다. 2.2.2 UDP특징 전송방식이 매우 단순해서 빠르다 -&gt; 최소한의 오류만 검출한다. 신뢰성이 낮다 -&gt; 전송하는 데이터의 순번이 바뀌거나 누락될 가능성이 존재한다. 비연결형 서비스이다 논리적인 경로가 없기 때문에 각각의 패킷은 다른 경로로 전송되고 독립적인 관계를 가진다. ex) 실시간 서비스 : 영상통화 등등 2.3 TCP UDP 차이출처 : soosungp33.log [CS] 📕 Network","link":"/2021/09/24/cs/network/TCP-UDP/"},{"title":"multiprocess and multiThread","text":"Multi Process(멀티 프로세스)멀티 프로세스란? 다수의 프로세스로 하나의 Task를 처리하는것 프로세스간 메모리 구분이나 독립된 공간이 필요할때 사용특징 독립된 구조로 다른프로세스에게 서로 영향을 주지않아서 문제가 발생해도 해당 프로세스 이외에는 영향이 없다. -&gt; 안정적이다.단점 서로 독립된 영역에서 작업을 진행하기 때문에 작업량이 많아질수록 Context Switching에 의한 오버헤드가 발생하여 성능의 저하가 일어날 수 있다 서로 독립되어있기 때문에 통신을 위해 별도의 통신설비를 이용해야함(IPC, Inter Process Communication) 프로세스간 변수등의 자료 교환을 할 수 없다. Multi Thread(멀티 스레드)멀티 스레드란? 하나의 프로세스에 여러개의 스레드로 자원을 공유하여 다수의 작업을 동시에 처리하는것특징 프로세스 안에서 공유 메모리를 가지고 있기때문에 시간, 자원의 손실이 프로세스대비 적다 스레드간 자료, 변수의 공유가 가능하다.단점 공유메모리를 가지기 때문에 공유메모리의 공간의 손상이 발생하면 다른 스레드또한 작업이 불가능한 상태가 되어버린다. 위의 문제를 가지기 때문에 주의깊은 설계가 필요하다. -&gt; Critical Section # Context Switching 하나의 프로세스나 쓰레드가 CPU를 사용중인 상태에서 다른 프로세스나 쓰레드가 CPU를 사용하기위해 현재 프로세스의 상태정보를 저장하고 다른 프로세스의 상태값을 불러오는 과정 -&gt; PCB에 저장 상태값을 저장하고 불러오는 동안에는 작업을 수행할 수 없다 -&gt; 오버헤드","link":"/2021/10/03/cs/os/multi/"},{"title":"프로세스와 쓰레드","text":"프로세스와 스레드Process(프로세스)프로세스란? 컴퓨터에서 연속적으로 실행되는 컴퓨터 프로그램 프로그램을 구동하여 메모리상에서 실행되는 작업단위 OS로 부터 독립된 메모리 영역을 할당받는다. 프로세스의 구조프로세스는 아래와 같은 구조를 가진다. Code : 코드 자체를 구성하는 메모리 영역 Data : 전역변수, 정적변수, 배열등을 저장 Heap : 동적 할당시 사용(new(), malloc() 등) Stack : 지역변수, 매개변수, 리턴값 등을 임시적으로 저장하는 영역 왜 이렇게 나눈걸까?12공유 할 수 있는 데이터는 공유하여 메모리의 사용량을 줄이기 위해서Stack과 Data를 나눈 이유는 스택의 특성과 전역변수를 활용하기 위해서 Process Control Block(PCB, 프로세스 제어 블록)특정 프로세스에 대한 정보(Process MetaData)를 저장하고 있는 자료구조(Linked List)아래와 같은 데이터가 저장되어 있다. Process MetaData Process ID : 프로세스의 식별번호 Process State : 프로세스의 상태(new, ready, running, waiting, terminated) Program Counter : 이 프로세스 다음에 실행할 명령어의 주소 CPU Registers CPU 스케줄링 정보: 우선 순위, 최종 실행시각, CPU 점유시간 등 메모리 관리 정보: 해당 프로세스의 주소 공간 등 프로세스 계정 정보: 페이지 테이블, 스케줄링 큐 포인터, 소유자, 부모 등 입출력 상태 정보: 프로세스에 할당된 입출력장치 목록, 열린 파일 목록 등 PBC는 CPU에서 프로세스의 상태에 따라 교체작업(Context Switching)이 이루어질때 PBC에서 저장되어있는 내용들을 불러와 이전 종료시점부터 다시 작업을 재실행한다. Thread(스레드)Thread란? 프로세스 내부에 존재하는 실행 단위 하나의 프로세스가 생성될때 내부에 적어도 하나의 스레드가 같이 생성된다. 스레드는 Stack만 따로 할당받고, 나머지 Code, Data, Heap은 공유 프로세스와 스레드의 차이 프로세스는 고유한 공간과 자원을 할당받아서 사용하지만(프로세스간 공유하지 않음) 스레드는 고유한 메모리(Stack)를 프로세스로 부터 할당받긴 하지만, 서로 공유하는 메모리(Code, Data, Heap)가 존재함 Stack를 스레드마다 독립적으로 할당 받는 이유 독립적인 실행 단위로써 스레드를 사용하기 위해서는 독립적인 메모리 공간이 필요하고, 이를 만족시키는 최소조건이 Stack을 제공하는것 이기 때문이다.","link":"/2021/10/02/cs/os/process-Thread/"},{"title":"Week1 - Day 1&amp;2 Review","text":"오늘 하루 한 것 Day1 팀원들과 아이스 브레이킹 강의 듣기 (python 2-4까지) 노션 회고록 Template 만들기 과제 Basic Math Text Processing 1 Text Processing 2 Day2 강의듣기 python 강의 완료 Ai Math 경사하강법까지 완료 과제 Gradient Descent 하는 중 기본퀴즈 1~5강 python 3-2강 까지 정리 피어세션에서 한것 Day1 피어세션 그라운드 룰 만들기 Day2 python 메모리 관리에 대한 질문 구조체 메모리 점유에 대한 질문 내일 할것 심화과제 끝내기 과제과정, 결과 + 정규식에 대해서 정리해보자 느낀점 어떻게 해야 남이보기 쉽게 설명할수 있을까? 정리하는데 시간이 오래걸린다. 1일차 한 내용이 많아서 하루만에 정리하기 쉽지 않았다. 예전에도 한번 시도했지만 꾸준히 정리해야 할맛나는것 같다. 쌓이면 쌓일수록 답이없다….. 매일 적당한 양을 공부하고, 정리할것 알아도 정리하자!","link":"/2022/01/18/boostcamp/Dairy/Day2/"},{"title":"Week1 - Day 4 Review","text":"오늘 하루 한 것 강의 모든강의 다 끝냄 과제 심화과제 완료 정리 통계학 베이즈 통계학 피어세션에서 한 것 선형회귀 경사하강법에 대한 질문 내일 할것 정리 마무리! 과제회고 피어세션 질문 정리 주말에 할 것 추가 정리 정규식 pickles __init__.py, __main__.py numpy, pandas 정리 KL diverence 하루 느낀점 생각보다 많이 정리하지는 못했다 제출은 안하지만 답지 받기전까지 끝내고 싶어서 심화과제에 시간을 많이 투자했다","link":"/2022/01/20/boostcamp/Dairy/Day4/"},{"title":"Week1 - Day 3 Review","text":"오늘 하루 한 것 강의듣기 Ai Math 5강까지 과제 Gradient Descent 완료 정리 경사하강법 완료 python 5-1까지 정리 완료 피어세션 numpy dtype float32 최대 최소값에 관해서 int형은 단순 비트계산이지만 float형은 부동소수점형으로 지수비트와 유효자리비트로 나뉘어있기 때문에 int형 -&gt; 정확함 float형 -&gt; 자세히보면 잘라먹음 내일 할것 역전파, 통계, CNN, RNN 정리 심화과제 2, 3 주말에 할 것 추가 정리 정규식 pickles __init__.py, __main__.py numpy, pandas 정리 느낀점 아직도 할게 많다… 정리 빨리 끝내고싶다","link":"/2022/01/19/boostcamp/Dairy/Day3/"},{"title":"Week1 - Day 5 Review","text":"오늘 하루 한 것 정리 RNN 딥러닝 기초 피어세션에서 한 것 무어 펜로즈 역행렬 간단하게 설명하기 일주일 회고 주말에 할 것 추가 정리 정규식 pickles __init__.py, __main__.py numpy, pandas 정리 KL diverence 여러가지 활성함수 하루 느낀점 마지막 날이지만 주말에 정리할게 많다.","link":"/2022/01/21/boostcamp/Dairy/Day5/"},{"title":"Week2 - Day 4 Review","text":"1. 오늘 하루 한 것 강의 pytorch 8강, 9강, 10강 정리 pytorch 8강, 9강, 10강 2. 피어세션에서 한 것 GIL 관한 이야기 FQ 3. 내일 할것 5, 6, 7강 정리 마무리 4. 추가 정리 필요한것 추가 정리 정규식 pickles __init__.py, __main__.py numpy, pandas 정리 KL diverence 여러가지 활성함수 GIL GC datdata augmentation Module 5. 하루 느낀점 조금 피곤하다…. 정리할 것은 많다","link":"/2022/01/27/boostcamp/Dairy/Week2-Day-4-Review/"},{"title":"Week2 - Day 2 Review","text":"1. 오늘 하루 한 것 강의 pytorch 4, 5강 과제 pytorch 기본과제1 끝내기, 기본과제2 중간까지 정리 pytorch 기본과제1, 4강, 5강 2. 피어세션에서 한 것 4강 코드가 안돌아가요 코테 문제 코드 리뷰 3. 내일 할것 기본과제2 끝내기 4. 하루 느낀점 오늘은 좀 할만하…지??","link":"/2022/01/25/boostcamp/Dairy/Week2-Day-Review-2/"},{"title":"Week2 - Day 3 Review","text":"1. 오늘 하루 한 것 강의 pytorch 6강, 7강 과제 pytorch 기본과제2, 퀴즈2 완료, 심화과제 완료 정리 2. 피어세션에서 한 것 NLP Dataset -&gt; build_vocab_from_iterator 관해서 이야기 FQ epoch에서 이뤄지는 모델 학습 과정을 정리해보고 성능을 올리기 위해서 어떤 부분을 먼저 고려하면 좋을지 같이 논의해보세요 loss optimizer.zero_grad()를 안하면 어떤 일이 일어날지 그리고 매 batch step마다 항상 필요한지 같이 논의해보세요 3. 내일 할것 심화과제 정리, 나머지 정리 마무리 pytorch 8~10강 듣고 정리 4. 하루 느낀점 과제한다고 시간을 많이 소모했다 이제 정리할시간!","link":"/2022/01/26/boostcamp/Dairy/Week2-Day3-Review/"},{"title":"Week3 - Day 1 Review","text":"1. 오늘 하루 한 것 강의 1, 2강 완료 정리 1강 완료, 2강 Barplot 2. 피어세션에서 한 것 피어슨 상관계수 3. 내일 할 것 정리 마무리 3, 4 강의 4. 하루 느낀점 설연휴 좀 쉬었더니 빠르게 정리가 잘 되지 않는다 쉰다고 많이 못했어….","link":"/2022/02/03/boostcamp/Dairy/Week3-Day1-Review/"},{"title":"Week4 - Day1 Review","text":"1. 오늘 하루 한 것 강의 MLP, Optimization 정리 MLP, Optimization 과제 MLP, Optimization 2. 피어세션에서 한 것 FQ Regression Task, Classification Task, Probabilistic Task의 Loss 함수(or 클래스)는 Pytorch에서 어떻게 구현이 되어있을까요?* 올바르게(?) cross-validation을 하기 위해서는 어떻 방법들이 존재할까요? sklearn.model_selection.StratifiedKFold Time series의 경우 일반적인 k-fold cv를 사용해도 될까요? nested CV 3. 내일 할 것 CNN, RNN 강의 4. 하루 느낀점 오늘은 열심히 한것같다","link":"/2022/02/07/boostcamp/Dairy/Week4-Day1-Review/"},{"title":"Week4 - Day2 Review","text":"1. 오늘 하루 한 것 강의 CNN 4~6강, RNN 7강 정리 CNN 4~6강, RNN 7강 과제 CNN, RNN LSTM 2. 피어세션에서 한 것 Batch norm weight 초기화에 관해서 3. 내일 할 것 RNN 마무리, 논문리뷰 정리 4. 하루 느낀점 프로젝트 아이디어에 대해서 생각을 하는중이다 괜찮은게 있으려나?","link":"/2022/02/08/boostcamp/Dairy/Week4-Day2-Review/"},{"title":"Week4 - Day3 Review","text":"1. 오늘 하루 한 것 강의 Generative Model 과제 심화과제 SSD 논문리딩 2. 피어세션에서 한 것 각종 Attention에 관한 이야기 3. 내일 할 것 강의 정리, 논문 정리, 스몰톡 주제 정리 4. 하루 느낀점 모더레이터….","link":"/2022/02/10/boostcamp/Dairy/Week4-Day3-Review/"},{"title":"Week4 - Day4 Review","text":"1. 오늘 하루 한 것 정리 LSTM 마무리 과제 심화과제 GAN에 관한 추가 내용 공부 2. 피어세션에서 한 것 pixelRNN 관련한 글 3. 내일 할 것 VAE 추가공부, Data 시각화 마무리 4. 하루 느낀점 예전에 간단하게 정리해 두었던 GAN을 보니 기억이 새록새록 떠오른다","link":"/2022/02/11/boostcamp/Dairy/Week4-Day4-Review/"},{"title":"Week6 - Day1 Review","text":"1. 오늘 한 것 강의 1~6강 P-Stage EDA Dataset 코드 작성 Solution에 필요한 논문탐색 2. 피어세션에서 한 것 P-Stage가 시작해서 팀원들과 어떤방식으로 진행해야할지 대해서 의논하였다 3. 내일 할 일 Pytorch Lightning base코드 작성 일부 모델 구성 생각 4. 하루 느낀점 드디어 P-Stage가 시작하였다. 열심히 진행해서 좋은 결과를 내면 좋겠다.","link":"/2022/02/21/boostcamp/Dairy/Week6-Day1-Review/"},{"title":"Week5 - Day 1~4 Review","text":"1. 이번주동안 한 것 강의 Data viz 6~7강 Ai serving 관련해서 정리 Project Serving docker 추가공부 fastai, mlflow, feature 2. 피어세션에서 한 것 tmux 3. 내일 할 것 다음주 대회 미리 baseline code 준비 4. 하루 느낀점 이번주 내용이 매우 가볍다보니 정리를 조금 소홀히 한듯하다 다시 다잡고 마저 정리해야겠다","link":"/2022/02/17/boostcamp/Dairy/Week5-Day4-Review/"},{"title":"Week6 - Day3 Review","text":"1. 오늘 한 것 P-Stage 기존의 CV score와 LB score간의 차이가 큰점을 해결하기 위해 베이스라인 코드를 수정하였다 Kaggle Study House Price Dataset에 관한 EDA 발표 화장실에 대한 고찰 Data Descript.txt를 읽고 데이터에 대한 고찰 2. 피어세션에서 한 것 P-Stage 팀원들과 여러가지 가설을 세워보았다 Data Agument를 위한 Transform 선택 Face Crop Model Design 3. 내일 할 일 가설 검증을 위한 코드 제작 4. 하루 느낀점 House price 데이터가 column이 많아서 다시 봐도 헛갈린다 스터디를 마치고 김태진 마스터님이 좋은 말씀을 많이 해주셨다 역시 즐겁게 해야 오래 할 수 있다","link":"/2022/02/23/boostcamp/Dairy/Week6-Day3-Review/"},{"title":"Week6 - Day4 Review","text":"1. 오늘 한 것 P-Stage Baseline code 추가수정 Grad cam 코드 구현 2. 피어세션에서 한 것 P-Stage 팀원들에게 Baseline코드 설명 3. 내일 할 일 ipynb 파일을 Python IDE로 변환 4. 하루 느낀점 하루종일 코드만 보고있어서 조금 지친 하루가 된것 같다 level2에서 같이 팀을 하자고 연락이 온 캠퍼들과 이야기를 나누었는데 긴장되어 보였다","link":"/2022/02/24/boostcamp/Dairy/Week6-Day4-Review/"},{"title":"Week6 - Day5 Review","text":"1. 오늘 한 것 P-Stage ipynb파일로 구현한 Baseline Code를 분리 및 모듈화 GradCam이 코드에 적용되도록 구현 2. 피어세션에서 한 것 mask RCNN 논문 리뷰 3. 주말 할 일 베이스라인 코드를 가지고 가설검증(주말내에 끝내기) 실험 정리 4. 하루 느낀점 하루종일 코드만 보고있어서 조금 지친 하루가 된것 같다 level2에서 같이 팀을 하자고 연락이 온 캠퍼들과 이야기를 나누었는데 긴장되어 보였다 5. 미세한 팁 pyyaml로 yaml파일을 불러올때 1e5같은 형식의 수치는 str형으로 받아온다 이때 float형으로 받고 싶으면 1.0e5같이 쓰면 된다 Linear scaling role 배치사이즈와 비례해서 lr을 움직여야 한다","link":"/2022/02/25/boostcamp/Dairy/Week6-Day5-Review/"},{"title":"Week7 Review","text":"P-Stage 회고1. P Stage 동안 진행 한 일 Pytorch Lightning을 이용한 베이스 라인 코드를 작성하였다. Yaml파일을 이용하여 빠르게 Hyperparameter와 모델을 수정 할 수 있도록 코드를 설계했고, 이 코드를 바탕으로 팀에서 많은 실험을 할 수 있었다. 하나의 Task를 분리하는 가설을 세우고 검증하였다. 마스크, 성별, 나이 3가지를 한 모델로 판단하는 것보다 3개의 모델로 3가지를 따로 판단하는 것이 더 학습시키기 용이하다고 생각하였다. 동일 모델 동일 Hyperparameter를 가지고 Target Label만 바꿔서 학습을 시켰을 때 약 0.01의 스코어 상승이 있었다. Soft Voting 구현을 하였다. 최종 제출을 앞두고 Soft Voting 을 구현하여 0.015정도의 스코어 상승을 실현했다. Gradient Cam Module을 코드에 사용할 수 있게 적용하였다. 이를 통하여 일부 모델이 예측할 때 강한 옷의 무늬나 배경이 영향을 준다는것을 확인하였다. 베이스라인 코드에 Layer Freeze 기능 추가. 학습이 진행되면서 Loss값이 증가하는것을 확인하고 이를 방지하기 위해 특정 Epoch가 지나면 자동으로 Layer를 Freeze 하도록 코드를 수정하였다. 2. 한계 및 아쉬웠던 점 시간상의 제약으로 여러가지 실험을 진행하지 못한 가설들이 여러가지 있어서 많이 아쉬웠다 mean variance loss를 이용한 Regression Model로 나이 예측 추가적인 데이터 전처리 (배경 제거, 학습시킨 모델을 이용한 이상치 제거) SOLID 원칙을 일부 지키지 않아 코드의 재사용성이 조금 떨어져서 기능을 추가할 때 고쳐야할 코드가 많아지고 이때문에 시간이 더 소요되었다 협업 툴을 사용하긴 했으나 제대로 활용되지 않아서 아쉬웠다. 3. 다음 프로젝트 위해 해보고 싶은 것 여유를 가지고 프로젝트에 임하기 위해서 자신만의 유연한 베이스라인 코드를 완성시키고 싶다 협업 툴 사용이 미숙하여 체계적으로 협업을 진행하지 못한것에 대해서 아쉬움이 남아 미리 팀 룰을 정하고 체계적으로 역할을 분담하여 진행해보자 한다 4. 느낀점 2주동안 진행되었던 P-Stage가 끝나고 기존 팀원들과 흩어지고 새로운 팀으로 이동하게 되었는데 아쉽기도 하면서 기대되기도 한다. 급하게 하다보니 시간이 많이 부족했었다. 아직 Pythonic하지 못한 듯 하다. 더 노력해야지","link":"/2022/03/07/boostcamp/Dairy/Week7-Review/"},{"title":"Week9 - Day 1 Review","text":"오늘 한 일 Instance Segmentaion 강의 및 퀴즈 완료 Conditional GAN 강의 및 퀴즈 완료 기본과제 4번 CGAN 완료 2. 피어세션에서 한 것 질문 정리 링크 receptive field 에 관한 추가 정리 Pooling Layer는 receptive field를 키워준다? Atrous convolution와 비슷한 개념 한번에 더 큰 영역을 볼 수 있다고 생각할 수 있음 3. 하루 느낀점 P-Stage가 1주일 남은 시점에서 정리를 빠르게 끝내고 싶은데 할게 너무 많다 나의 삶의 지도 작성을 하면서 오랜만에 다시 나에 대해서 생각해본 날 이었다","link":"/2022/03/15/boostcamp/Dairy/Week9-Day1/"},{"title":"Week8 - Day 1~4 Review","text":"1. 1~4일간 한 것 CV 트랙 강의 수강 완료 과제 완료 추천 시스템 청강 준비 2. 피어세션에서 한 것 receptive field 에 관한 정리 Convolution Layer에서 한번에 받을 수 있는 영역의 크기 이 영역이 클수록 한번에 볼 수 있는 정보의 크기 또한 커진다 성능의 향상 과제 리뷰 1번과제 Resnet 34 scratch 구현에서의 의문점에 관하여 토론 ReLU의 적용 시점에 따라서 성능이 갈리지 않나? 가이드라인 코드에서는 ReLU를 Skip Connection과 합치기 전에 각각 적용함 직접 만든 코드에서는 ReLU를 합친 output에 적용하였다 성능은 직접만든 코드쪽이 월등하게 높은것으로 나타났다 3. 주말 할 일 다다음주 P-Stage를 대비하여 필요한 지식을 미리 찾아두고 공부해두기 Kaggle 스터디 발표준비 4. 하루 느낀점 팀원이 바뀌고 새로 그라운드 룰부터 많은것을 정하기위해 정말 많이 이야기했다 아직 바뀐지 얼마 지나지 않아서 조금은 어색한 느낌이 있다 금방 좋아지겠지 5. 미세한 팁 functools.partial에서 keyword값으로 넣어주려면 변수를 맨 뒤로 빼야한다 functools.partial에 관한 정리","link":"/2022/03/11/boostcamp/Dairy/Week8-Review/"},{"title":"Week2 - Day 1 Review","text":"오늘 하루 한 것 강의 pytorch 1, 2, 3 강의 과제 pytorch 기본과제1 중간정도 정리 pytorch 1, 2, 3 강의, 기본과제1 피어세션에서 한 것 backward 함수의 파라미터로 gradient를 넘기는것에 대한 의미 reshape, view 차이점 내일 할것 기본과제 정리 끝내기 하루 느낀점 부덕아… 눈이 너무 아파","link":"/2022/01/24/boostcamp/Dairy/week2-Day1/"},{"title":"Week8 - Day 5 Review","text":"1. 오늘 한것 정리 마무리 2. 피어세션에서 한 것 팀 공통 정리 문서 만들기! 3. 주말 할 일 CNN Viz 정리 마무리 다다음주 P-Stage를 대비하여 필요한 지식을 미리 찾아두고 공부해두기 Kaggle 스터디 발표준비 4. 하루 느낀점 CV wiki를 작성하기로 했는데 잘 되었으면 좋겠다 그리고 꼭 CV에 국한된 것이 아니라 부캠 전체 공유하는 위키 만드는것도 한번 고려를 해보려고 한다 같이 위키만들 사람 구하려면 기초부터 조금 잘 만들어두어야 겠다 5. 미세 팁 오늘은 없습니다 reference Naver Connect Boostcamp - ai tech","link":"/2022/03/11/boostcamp/Dairy/week8-day5/"},{"title":"Week9 - Day 2 Review","text":"1. 오늘 한 일 이고잉님 Github 특강 CV Wiki AlexNet 작성 Kaggle 스터디 발표 준비 2. 하루 느낀점 CLI가 친숙해서 GUI를 이용한 Git관리는 오히려 낯설었다 하루종일 Git만 한다고 정리는 생각보다 많이 하지 못했다 3. 미세한 꿀팁 git checkout 명령어는 branch가 우선순위를 가진다 같은 이름의 commit과 branch가 존재 할 때 branch에 head가 간다","link":"/2022/03/16/boostcamp/Dairy/week9-day2-review/"},{"title":"Week1 Peer Session","text":"Peer Session 정리 일주일동안 피어세션에서 주고받았던 질문에 대해서 추려서 정리한 글이다 1. python 메모리 관리는 어떤 방식으로 이루어지나? 영상참조하면 좋을것 같다 https://www.youtube.com/watch?v=arxWaw-E8QQ 2. list 구조체의 메모리는 어떤방식으로 할당 될까 python의 list는 다른 언어의 array와 다르게 list 내부에 여러가지 데이터 형식이 들어가는 것이 가능하다 linked list 형태로 data가 추가 될 때마다 그 형식에 맞는 메모리를 할당해서 연결하기 때문에 가능하다 3. python float의 할당 방식은 어떻게 이루어 질까? + int 형과의 비교 python의 float 형은 64bit의 부동소수점으로 표현을 한다 기억 범위 : $4.9×10^{-324}\\sim1.8×10^{308}$ 부동소수점 표현 부호, 지수비트, 가수비트로 나눠서 수를 표현하는 방식을 말한다 자세한 설명은 따로 포스팅 할 예정이다 3.1 python에서 int형의 범위는 어떻게 될까 python3 버전으로 넘어오면서 int형의 overflow가 사라졌다 그래서 int형으로 표현할 수 있는 범위는 메모리가 허용하는 한도내에서 무제한이다 조금더 자세하게 설명하자면 python2 버전에서는 int와 long 타입을 같이 사용하는 구조였는데 int의 범위가 넘어가면 자동으로 long 타입으로 넘어가는 형식이었다. python3에서는 아에 long 타입이 int와 결합해서 수의 크기에 따라 탄력적으로 가용메모리를 추가적으로 할당하는 Arbitrary presicion을 사용한다","link":"/2022/01/19/boostcamp/Peer%20Session/Peer1/"},{"title":"Week2 Peer Session","text":"1. tensor가 벡터형태 일 때 Backward를 진행하면 왜 아래와 같이 표기해야하나?1234a = tensor([3, 2])b = tensor([4, 1])Q = a*2 + b**2Q.backward(gradient = tensor([1, 1])) Pytorch에서는 scalar 값이 아닌 tensor에서는 backward의 시작점으로 보지 않기 때문에 벡터에 따로 gradient를 지정해 줘야한다. 2. optimizer.zero_grad() Gradient를 초기화 해주는 함수를 말한다 만약 초기화 해주지 않는다면 tensor가 backward 연산될때마다 grad에 더해져서 제대로 학습되지 않게 될 것이다 3. GIL Global Interpreter Lock Global Interpritor Lock","link":"/2022/01/24/boostcamp/Peer%20Session/Peer2/"},{"title":"Week1 Homework","text":"1. 기초과제 과제 내용 간단한 python의 built-in function 과 문자열 처리를 위한 과제 결과 정규식 라이브러리 re를 사용하여 문자열을 처리해주었다 회고 기초과제 + 첫주라 그런지 난이도는 어렵지 않았다 문제표현상 애매한 점이있었지만, 조교님과의 소통으로 해결함 2. 심화과제 여기서부터 진정한 과제 1. 경사하강법 구현 말 그대로 경사하강법의 구현 차근차근 수식을 코드로 바꾸면 되기때문에 어려운부분은 없었다 2. BPTT 구현 과정 RNN의 Backpropagation은 처음 구현하는거라 시행착오가 많았다 numpy를 거의 사용 안하고 문제를 풀었는데 조금 연습을 할 필요가 있어보인다 3. 최대가능도 계산 증명 및 구현 가우시안 분포를 통한 최대가능도 계산 로그우도함수$$\\begin{aligned}L(\\theta|x) &amp;= \\sum_{i=1}^{n}\\left( -\\frac{1}{2}\\log2\\pi\\sigma^2 +\\log \\exp\\left(-\\frac{(x_i-\\mu)^2}{2\\sigma^2}\\right) \\right)\\\\&amp;= -\\frac{n}{2}\\log2\\pi\\sigma^2 - \\sum_{i=1}^{n}\\frac{(x_i-\\mu)^2}{2\\sigma^2}\\\\&amp;= -\\frac{n}{2}\\log2\\pi\\sigma^2 - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(x_i-\\mu)^2\\end{aligned}$$ 모평균의 추정량$$\\begin{aligned}\\frac{\\partial L(\\theta|x)}{\\partial \\mu}&amp;= -\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}\\frac{\\partial}{\\partial \\mu}\\left(x_i^2-2x_i\\mu+\\mu^2\\right)\\\\&amp;= -\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(-2x_i + 2\\mu)\\\\&amp;= \\frac{X-n\\mu}{\\sigma^2}\\\\\\hat{\\mu} &amp;= \\frac{1}{n}X\\\\&amp;= \\frac{1}{n}\\sum_{i=1}^{n}x_i\\end{aligned}$$ 모분산의 추정량$$\\frac{\\partial L(\\theta|x)}{\\partial \\sigma} = -\\frac{n}{\\sigma} + \\frac{1}{\\sigma^3}\\sum_{i=1}^{n}(x_i-\\mu)^2$$$$\\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^{n}(x_i-\\mu)^2$$ 후기 우린 앞으로 편미분과 평생을 같이 살아야한다고 역시 스스로 힘으로 문제를 해결하면 기분이 좋다 다음 심화과제는 어떨지 궁금하다","link":"/2022/01/21/boostcamp/Problems/work1/"},{"title":"Week2 Homework","text":"1. 기초과제 과제 내용 Pytorch의 Custom Model 제작에 필요한 nn.Module 함수들에 대한 공부 Dataset과 Dataloader의 구현 결과 및 회고 평소 자주 쓰지 않았던 torch 함수들을 찾아보고 알게되는 기회가 되었다 특히 hook과 apply같은 거의 보지 못했던 기능들이 나와 정리해 보았다 Pytorch nn.Module 관련 정리 Pytorch Dataset &amp; DataLoader 관련 정리 2. 심화과제 과제내용 Transfer Learning과 weight 초기화 + Ray사용 해보기 결과 및 회고 Transfer Learning은 익히 알던 내용이여서 어렵지 않았다 weight 초기화를 할때 랜덤으로 초기화 해주는것보다 특정 initialization 을 진행하는것이 더 성능이 잘 나오는것에 대해 알게 되었다 이미 pytorch에서는 layer별로 내부 Method에 적용되어있다고 한다 자세한 내용은 kaiming_uniform_에 대해 찾아보는것을 추천한다 Ray는 코드 실행은 해보았지만 colab GPU 사용량 초과로 인해서 강제 종료 당했다 추후에 Linux 환경의 컴퓨터에서 다시한번 실행을 해 볼 예정이다","link":"/2022/01/28/boostcamp/Problems/work2/"},{"title":"부스트 캠프 ai tech 1주 3일차 Ai Math (2)","text":"이 글에서 미분은 다루지 않습니다 3. 경사하강법 함수의 극소값의 위치를 구할때 사용하는 방법 현재값의 기울기를 이용하여 점점 극소값에 접근한다 기울기가 너무 커서 발산할 경우를 방지하기 위해 lr(learning rate)를 곱해서 충분히 작은 값으로 계산을 해준다 컴퓨터로 계산할 경우 딱 떨어지는 정수를 만들어내기 힘들기 때문에 $\\epsilon$ 값보다 작아질 경우를 수렴했다라고 가정한다 $$x_{i+1} \\leftarrow x_{i} - \\gamma \\nabla f(x_{i})$$ python code 12345var = init # 초기값grad = gradient(var) # 현재 위치로부터 기울기를 구하는 함수while (abs(grad) &gt; eps): var += - lr * grad grad = gradient(var) 벡터가 입력인 다변수 함수의 경우는 편미분을 이용하여 경사하강법을 진행한다 3.1 선형회귀에서의 경사하강법 선형회귀에서의 target은 $\\left\\|\\mathbf{y-X\\beta}\\right\\|_{2}$ 이고, 이를 최소화하는 $\\beta$를 찾아야 하기 때문에 아래와 같은 gradient를 구해야 한다 $$\\nabla_{\\beta}\\left\\|\\mathbf{y-X\\beta}\\right\\|_{2}=-\\frac{\\mathbf{X^{\\top}(y-X\\beta)}}{n\\left\\|\\mathbf{y-X\\beta}\\right\\|_{2}}$$ 위의 식을 통하여 $\\beta$를 구하는 경사하강법 알고리즘은 아래와 같다 $$\\begin{eqnarray*}\\beta_{i+1}&amp;\\leftarrow\\beta_{i}-\\gamma\\nabla_{\\beta}\\left\\|\\mathbf{y-X\\beta_{i}}\\right\\|_{2}\\\\\\beta_{i+1}&amp;\\leftarrow\\beta_{i} + \\gamma \\frac{\\mathbf{X^{\\top}(y-X\\beta)}}{n\\left\\|\\mathbf{y-X\\beta}\\right\\|_{2}}\\end{eqnarray*}$$ 간략하게 아래와 같이 표현도 가능하다 gradient를 최소화시키는것과 gradient의 제곱을 최소화 시키는것은 같은 의미 $$\\beta_{i+1} \\leftarrow \\beta_{i} + \\frac{2\\gamma}{n} \\mathbf{X^{\\top}(y-X\\beta)}$$ 3.2 경사하강법의 한계 볼록한 함수에서는 적절한 학습률과 반복횟수를 선택했을 때 수렴이 보장되어있다 비선형회귀의 경우 목적식이 볼록하지 않기 때문에 수렴이 항상 보장되지는 않는다 특히 딥러닝의 경우 고차원의 자료를 다루기 때문에 경사하강법만으로는 학습하기가 힘들다 이러한 이유로 SGD, Momentom, Adam 등의 여러가지 optimize 알고리즘이 등장했다 이 부분에 대해서는 추후에 따로 다룰 예정이다","link":"/2022/01/19/boostcamp/week/week1/AIMath-2/"},{"title":"부스트 캠프 ai tech 1주 3일차 Ai Math (2)","text":"4. 딥러닝 기본 딥러닝은 비선형모델인 신경망을 이용한 기계학습이다 4.1 softmax 함수 모델의 출력을 확률로 해석 할 수 있게 변환해주는 함수 인공신경망에서 확률분포를 얻기위한 마지막 활성함수로 많이 사용한다 출력값은 항상 0~1사이로 정규화된다$$f(x)_{k} = \\frac{e^{x_i}}{\\sum_{k=1}^{n}e^{x_{k}}}$$ 4.2 Activation Function (활성함수) 실수범위에서 정의된 비선형 함수 딥러닝을 비선형 모델로 만들어주는 결정적인 함수이다 여러가지 종류가 있으며 ReLU계열이 제일 많이 사용되고 있다 포스팅을 통해 따로 다룰 예정이다 4.3 신경망 선형모델과 활성함수를 합성한 함수이다 우리가 흔히 부르는 MLP(Multi Layer Perceptron)는 여러 층의 합성신경망을 뜻한다 $x$ : input $\\sigma$ : Activation Function $h$ : Layer output $z$ : linear output $W$ : weight matrix $b$ : bias$$h = \\sigma(z)\\\\z = Wx + b\\\\$$ 4.4 Backpropagation MLP의 weight들을 효율적으로 갱신하는 알고리즘 합성함수의 미분법인 Chain-rule 기반으로 output Layer부터 input Layer로 미분을 계산해 나간다 $$O = W_{2}h + b_{2}\\\\h = \\sigma(z)\\\\z = W_{1}x + b_{1}\\\\$$","link":"/2022/01/19/boostcamp/week/week1/AIMath-3/"},{"title":"부스트 캠프 ai tech 1주 3일차 Ai Math (4)","text":"5. 확률론 확률에 대해서 다루는 수학의 한 분야 딥러닝은 확률을 기반으로 한 머신러닝의 한 분야이기 때문에 그 기반에는 확률론이 깔려있다그래서 통계학을 배워야 한다 이 정리글에서 확률론에 대해 자세하게 다루지는 않을 예정이며 좀 더 자세한 글을 원한다면 PRML을 검색해서 보길 바란다 5.1 확률변수와 확률 분포 확률변수 시행의 결과에 따라 값이 결정되는 변수를 나타낸다 나타날 가능성이 있는 모든 경우의 수에 해당하는 값을 가질수 있다 ex) 주사위를 던질때 나올수 있는 눈 확률분포에 따라서 이산확률변수와 연속확률변수 중 하나로 구분 될 수 있다 항상 둘중 하나로 구분되는것은 아니다 확률분포 확률변수가 특정한 값을 가질 확률을 나타내는 함수를 의미한다 5.2 이산확률와 연속확률 이산확률변수 확률변수 X가 취할수 있는 모든값을 셀 수 있을때 이산확률변수라고 한다(가산변수) 확률변수가 가질수 있는 모든 경우의 수를 고려하여 확률을 더해서 구한다$$\\mathbb{P}(X\\in A) = \\sum_{x \\in A}P(X=x)$$ 연속확률변수 연속적인 범위의 값을 지니는 확률변수. 모든 경우를 정확하게 셀 수 없는 확률변수이다(불가산변수) 데이터 공간에 정의된 확률밀도함수의 적분을 통해 구한다$$\\mathbb{P}(X\\in A) = \\int_{A}^{}P(\\mathbf{x})d\\mathbf{x}$$ 5.3 결합확률 &amp; 조건부확률 결합확률 $P(X, Y)$ $X=x$ 이고 $Y = y$ 일때의 확률을 나타내는 함수 조건부확률 $P(X | Y)$ $Y = y$ 일 때 $X = x$ 일 확률을 나타내는 함수 결합확률과 조건부확률은 다음과 같은 관계가 성립한다.$$P(x, y) = P(x|y)P(y) = P(y|x)P(x)$$ 우리는 앞으로 이 조건부확률을 구하기 위해 모델을 학습시킨다 5.4 기댓값 각 사건이 벌어졌을때의 이득과 그 사건이 벌어질 확률의 곱을 전체 사건에대해 합한 값 이산확률일 경우 $$\\operatorname{E}[X]=\\sum_{i}x_{i}P(x_{i})$$ 연속 확률일 경우 $$\\operatorname{E}[X]=\\int_{X}xP(x)\\operatorname {d} x$$ 또한 선형성을 가지고 있기 때문에 아래가 성립한다 $$\\operatorname{E}[X+Y]=\\operatorname{E}[X]+\\operatorname{E}[Y]$$ $$\\operatorname{E}[cX]=c\\operatorname{E}[X]$$ 조건부 기댓값 조건부 확률에 대한 기댓값은 다음과 같이 계산한다 $$\\operatorname{E}[y|X]=\\int_{Y}^{}yP(y|X)\\operatorname{d}y$$ 5.5 몬테카를로 Sampling 반복된 무작위 추출을 이용하여 함수의 값을 근사하는 알고리즘 표본공간의 확률분포에서 충분히 표본을 뽑으면 결국 확률분포에 근사한다 기계학습, 딥러닝을 학습시킬때 우리는 확률분포를 알지 못하는 경우가 대부분이기 때문에 데이터를 이요하여 기대값을 계산하려면 몬테카를로 방법을 이용해야한다$${\\displaystyle \\operatorname {E} [f(x)] \\approx \\frac{1}{N} \\sum_{i=1}^{N}f(x^{(i)}),\\quad x(i) \\overset{\\underset{\\mathrm{}}{i.i.d}}{\\sim} P(x) }$$ 독립추출만 보장되면 대수의법칙에 의해 항상 수렴성이 보장된다","link":"/2022/01/19/boostcamp/week/week1/AIMath-4/"},{"title":"부스트 캠프 ai tech 1주 3일차 Ai Math (5)","text":"5. 통계학 다량의 데이터를 관찰하고 정리 분석하는 수학분야 5.0 용어정리 모집단 : 정보를 얻고자 하는 대상이 되는 집단의 전체 표본집단 : 모집단으로부터 추출한 데이터 집합 통계량 : 표본집단의 평균, 표준편차, 분산 등의 데이터를 말한다 표본분포 : 표본집단의 확률분포 표집분포 : 통계량의 확률분포 5.1 모수 모평균 모표준편차 모분산 등 모집단의 데이터를 말한다. 유한한 개수의 데이터를 관찰하는것으로 우리는 모집단의 분포를 정확하게 파악하는것은 불가능하기 때문에 근사적으로 확률분포를 추정해야한다 모수적 방법론 데이터가 특정 확률분포를 따른다고 가정한 뒤 모수를 추정하는 방법 보통 충분히 많은 데이터가 확보 되었을때 사용한다 비모수적 방법론 확률분포를 가정하지 않고 데이터에 따라 모델의 구조 및 모수의 개수가 유연하게 바뀌는경우 모수의 특성을 이용하지 않는다 5.2 확률분포를 가정하는 방법 데이터가 2개의 값 (0 또는 1)만 가지는 경우 $\\rightarrow$ 베르누이 분포 데이터가 n개의 이산적인 값을 가지는 경우 $\\rightarrow$ 카테고리 분포 데이터가 $[0,1]$ 사이에서 값을 가지는 경우 $\\rightarrow$ 베타분포 데이터가 0 이상의 값을 가지는 경우 $\\rightarrow$ 감마분포, 로그정규분포 등 데이터가 $\\mathbb{R}$ 전체에서 값을 가지는 경우 $\\rightarrow$ 정규분포, 라플라스분포 등 정규분포의 모수 평균과 분산 표본집단의 데이터를 $X$ 라고할때 표본평균 $\\bar{X}$ 와 표본분산 $S^2$은 다음과 같다$$\\bar{X} = \\frac{1}{N}\\sum_{i=1}^{N}X_{i}\\qquad S^2 = \\frac{1}{N-1}\\sum_{i=1}^{N}(X_{i}-\\bar{X})^2$$ 이때 모집단의 모수인 평균 $\\mu$ , 분산 $\\sigma^2$ 표본평균과 표본분산의 기댓값으로 추정 할 수 있다$${\\displaystyle \\operatorname {E}[\\bar{X}]=\\mu\\quad\\operatorname{E}[S^2] = \\sigma^2}$$ 통계량의 확률분포를 표집분포라고 부르며 표본평균의 표집분포는 $N$이 커질수록 정규분포를 따른다 5.3 최대 가능도 추정법 maximum likelihood estimation 이론적으로 가장 가능성이 높은 모수를 추정하는 방법 중 하나 어떤 상태 $\\mathbf{x}$ 를 관측할 가능성이 제일 높은 모수를 추정하는 방법$$\\hat{\\theta}_{MLE} = \\underset{\\theta}{argmax}L(\\theta; \\mathbf{x}) = \\underset{\\theta}{argmax} P(\\mathbf{x}|\\theta)$$ 5.4 KL divergence 쿨백-라이블러 발산 두 확률분포가 얼마나 떨어져 있는지를 나타낸다 거리로써 사용은 불가능하다 역이 성립을 하지 않은다 솔직하게 여기에 정리하기에는 많이 중요한 내용이고 양도 많다 많이 중요하다 따로할 예정이다 그때 링크를 추가할 예정","link":"/2022/01/19/boostcamp/week/week1/AIMath-5/"},{"title":"부스트 캠프 ai tech 1주 3일차 Ai Math (6)","text":"6. 베이즈 통계학 하나의 사건에서 믿음의 정도를 확률로 나타내는 베이즈 확률론에 기반한 통계학 이론 쉽게 말하면 아직 일어나지 않은 사건이 일어날 확률에 대한 계산을 하는 학문 6.0 조건부 확률 조건부확률 $P(A|B)$특정사건 $B$가 일어난 상황에서 사건 $A$가 일어날 확률이다. 아래와 같이 나타낼 수 있다. $A$와 $B$가 동시에 일어날 확률 = $B$가 일어날 확률 * $B$일어난 상황에서 $A$가 일어날 확률$$P(A\\cap B) = P(B), P(A|B) = P(A), P(B|A)$$$$P(B|A) = \\frac{P(A\\cap B)}{P(A)} = P(B) \\frac{P(A|B)}{P(A)}$$ 6.1 베이즈 정리 $D$ : 데이터 $\\theta$ : 측정하고싶은 파라미터 조건부 확률 $P(\\theta|D)$는 사후확률이라고 부른다 조건부 확률 $P(D|\\theta)$는 가능도(likehood, 우도)라고 부른다 $P(\\theta)$ 는 사전확률이라고 부른다 베이즈 정리는 아래와 같이 나타내며 이식으로 부터 우리는 사후확률과 가능도는 비례하는 관계임을 알 수 있다$$P(\\theta|D) = P(\\theta) \\frac{P(D|\\theta)}{P(D)}$$ 조건부 확률의 시각화 정밀도(Precision) : 모델이 True라고 분류한 것들 중에서 실제 True인 것의 비율 재현율(Recall) : 실제 True인 것 중에서 모델이 True라고 예측한 것의 비율 정확도(Accuracy) : 올바르게 예측한 정도$$Precision = \\frac{TP}{TP+FP}$$$$Recall = \\frac{TP}{TP+FN}$$$$Accruacy = \\frac{TP + TN}{TP+FN+FP+TN}$$ 새로운 데이터가 들어왔을때 앞서 계산한 사후확률을 사전확률로 사용하여 새로운 사후확률로 갱신할 수 있다$$P^{\\prime}(\\theta|D) = P(\\theta|D) \\frac{P(D|\\theta)}{P(D)}$$ 조건부 확률은 일어나지 않은 일에 대해 유용한 통계적 해석을 제공하지만 인과관계를 추론할때는 함부로 사용해서는 안된다 robust한 모델을 위해서는 인과관계를 생각할 필요가 있다","link":"/2022/01/20/boostcamp/week/week1/AIMath-6/"},{"title":"부스트 캠프 ai tech 1주 3일차 Ai Math (7)","text":"7. CNN 합성곱을 이용한 신경망 7.1 Convolution 연산 신호(signal)를 커널을 이용해서 국소적으로 증폭 또는 감소시키는 연산을 말한다 CNN 에서 하는 연산은 엄밀하게 말하면 Cross Correlation 연산이다 Cross Correlation$$[f*g](x) = \\int_{\\mathbb{R}}f(z)g(x+z)\\operatorname{d}z$$ Convolution 연산$$[f*g](x) = \\int_{\\mathbb{R}}f(z)g(x-z)\\operatorname{d}z$$ 다양한 차원에서 연산이 가능하다$$\\begin{aligned}&amp;1D \\quad [f*g](i) = \\sum_{p=1}^{d}f(p)g(i+p)\\\\&amp;2D \\quad [f*g](i,j) = \\sum_{p,q}f(p,q)g(i+p,j+q)\\\\&amp;3D \\quad [f*g](i,j,k) = \\sum_{p,q,r}f(p)g(i+p,j+q,k+r)\\end{aligned}$$ 7.1 2D Convolution 연산 2차원 convolution 연산은 커널을 input위에서 움직여가면서 선형모델과 합성함수가 적용되는 구조이다. 출력크기는 아래와 같이 계산된다 $H, W$ : 입력크기 $K_{h}, K_{w}$ : 커널의 크기 $O_{h}, O_{w}$ : 출력의 크기$$O_{h} = H-K_{h}+1\\\\O_{w} = W-K_{w}+1$$ 7.2 Convolution 연산의 Backpropagation Convolution 연산의 역전파도 결국에는 선형연산이 여러번 적용된 형태이기 때문에 계산할때 각 커널의 들어오는 모든 gradient를 더하면 된다 $$\\frac{\\partial \\mathcal{L}}{\\partial w_{i}} = \\sum_{j} \\delta_{j} x_{i+j-1}$$","link":"/2022/01/20/boostcamp/week/week1/AIMath-7/"},{"title":"부스트 캠프 ai tech 1주 4일차 Ai Math (8)","text":"8. RNN 연속적인 데이터(Sequence Data)를 주로 다루는 Nerual Network 소리, 문자열, 주가등의 데이터를 분석하는데 사용된다 8.1 시계열 데이터 독립동등분포 가정을 잘 위배하기 때문에 순서를 바꾸거나 과거에 정보에 손실이 발생하면 데이터의 확률분포 자체가 변해버린다 베이즈 법칙을 이용하여 다음과 같이 표현이 가능하다$$\\begin{aligned}P(X_1, … ,X_{t}) &amp; = P(X_t|X_1, …, X{t-1})P(X_1,…,X_{t-1})\\\\&amp; = \\prod_{s=1}^{t}P(X_s|X_{s-1},…,X_1)\\end{aligned}$$ 시퀸스 데이터를 다루기 위해서는 길이가 가변적인 데이터를 다룰수 있는 모델이 필요하다 조건부에 들어가는 데이터의 길이는 시퀸스마다 가변적이다$$\\begin{aligned}X_t &amp;\\sim P(X_t|X_{t-1}, … X_{1})\\\\X_{t+1} &amp;\\sim P(X_t|X_{t}, X_{t-1}, … X_{1})\\end{aligned}$$ 고정된길이 $\\tau$ 만큼의 시퀸스만 사용하는 모델의 경우 자기회귀모델(Autoregressive Model)이라고 한다 매우 오래된 과거의 데이터는 실제 데이터에 큰 영향을 주기 힘들다는 가정하에 세워진 모델이다$$\\begin{aligned}X_t &amp;\\sim P(X_t|X_{t-1}, … X_{t-\\tau})\\\\X_{t+1} &amp;\\sim P(X_t|X_{t}, … X_{t-\\tau+1})\\end{aligned}$$ 이전정보를 제외한 나머지 정보들을 잠재변수로 활용하는 모델을 잠재자기회귀모델 이라고 한다 앞으로 다룰 RNN도 이 모델에 해당한다$$\\begin{aligned}X_t &amp;\\sim P(X_t|X_{t-1}, H_t)\\\\X_{t+1}&amp;\\sim P(X_t|X_{t}, H_{t+1})\\\\H_t&amp;=\\operatorname{Net}(H_{t-1}, X_{t-1})\\end{aligned}$$ 8.2 RNN 기본적인 RNN 모델은 아래와 같이 MLP와 유사한 형태를 가지고 있다 RNN은 이전순서의 잠재변수와 현재의 입렬을 활용하여 계산을 이어나간다 RNN의 역전파는 BPTT(Backpropagation Through Time)라고 불리며 연결그래프에 따라 순차적으로 계산한다 $S$ : 잠재변수 $X$ : input Data $W_x$ : $X$의 가중치행렬 $W_{rec}$ : $S$의 가중치 행렬 $\\sigma$ : Activate Function $X$ : 시퀸스 데이터 RNN의 Network 연산 $$\\mathbf{S_{t}} = \\sigma (\\mathbf{O}_{t-1} + \\mathbf{X}_{t}\\mathbf{W}_{x})$$$$\\mathbf{O_{t}} = \\mathbf{S}_{t}\\mathbf{W}_{rec}$$ BPTT RNN의 Backpropagation 을 계산해보면 미분의 곱으로 이루어진 항이 계산된다 시퀸스의 길이만큼의 $W_{rec}$의 역전파가 이루어 질 때 마다 계속해서 미분을 하기 때문에 시퀸스의 길이가 길어질수록 gradient vanishing(기울기 소실)이 발생하여 계산이 불안정해 진다 $L$ : loss 함수 $y$ : target $$\\frac{\\partial S_{t}}{\\partial W_{rec}} = \\sum_{i=1}^{t-1} \\left( \\prod_{j=i+1}^{t} \\frac{\\partial S_{j}}{\\partial S_{j-1}} \\right)\\frac{\\partial S_{i}}{\\partial W_{rec}} + \\frac{\\partial S_{t-1}}{\\partial W_{rec}}$$ truncated BPTT RNN은 시퀸스의 길이가 길어지면 기울기 소실이 발생하여 계산이 불안정해지기 때문에 중간에 연산을 끊어주는 테크닉. 이러한 기울기 소실을 해결하기 위해 등장한 네트워크 LSTM, GRU","link":"/2022/01/20/boostcamp/week/week1/AIMath-8/"},{"title":"부스트 캠프 ai tech 1주 1일차 Basic","text":"1. OS(Operating System) 운영체제 Application이 동작 할 수 있는 환경을 말한다. 컴퓨터의 하드웨어와 App이 소통하는 창구 역할을 한다. ex) 윈도우즈, MacOS, Ubuntu(Linux) 자세한 내용은 CS에서 따로 정리를 하고있다. 2. File System File system 이란? 파일을 저장하는 트리구조의 데이터 저장체제 Directory 이란? 아래에 정의하는 File이나 다른 Directory를 저장할수 있는 것 폴더 또는 디렉토리라고 할 수 있다. File 이란? 의미있는 정보를 저장하는 논리적인 단위 run, write, read 등을 할 수 있다. 파일 명과 확장자로 종류나 쓰임새를 식별 가능하다. 경로란? 절대경로 : root부터 현재 파일 위치까지의 경로 상대경로 : 현재 활성화된 디렉토리부터 타겟 파일까지의 경로 3. Terminal 키보드를 통하여 명령을 하고, 프로그램을 실행시키는 인터페이스 windows의 CMD, PowerShell 과 Mac, Linux의 Terminal 등이 해당한다.","link":"/2022/01/17/boostcamp/week/week1/basic/"},{"title":"부스트 캠프 ai tech 1주 2일차 Python Basic for AI (2)","text":"1일차 배운내용 2일차에 정리하는중… 4. Function(함수) 어떤 일을 수행하는 논리적인 코드 단위 parameter, indentation(들여쓰기), return 등으로 구성된다 argument : 함수를 호출할 때 입력되는 파라미터들을 말한다 12345def im_function(im_parameter): #함수의 정의와 파라미터 im_return = im_parameter # 수행 내용 return im_return # 리턴값result = im_function(im_argument) 함수에 return 값이 존재하지 않을경우 함수는 None을 리턴한다 4.1 지역변수 &amp; 전역변수 지역변수(local variable) : 함수 내에서만 사용되는 변수 전역변수(global variable) : 프로그램 전체에서 사용하는 변수 global을 사용하여 함수내에서 정의 할 수 있다. 123456def function(x): global y return x + yy = 5print(function(6)) # 11 4.2 재귀함수(recursive Function) 자기자신을 호출하는 함수 종료조건이 존재하여 종료조건을 만족시킬때 까지 스스로를 호출한다 python에서는 recursivelimit가 걸려있어서 따로 sys 모듈을 통해 한도를 늘려놓아야 한다. 개인적으로 별로 안이용하고 싶음 4.3 Function type hints &amp; Docstring Function type hintspython에서는 dynamic typinig 형식으로 작성하기 때문에 별도로 자료형을 적어두지 않기 때문에 처음 함수를 사용하는 사용자가 interface를 알기 어렵다는 단점이 있다.이를 해결하기 위해 type hints 기능을 제공한다. parameter와 return의 type을 알려주는 type hints 12def this_is_function(var_name: var_type) -&gt; return_type: pass Docstring함수에 대한 상세 스펙(필요한 parameter, return, 수행하는 일 등등)을 사전에 작성한다.세개의 따옴표로 함수명 아래에 표시한다123456789def function(x): &quot;&quot;&quot; this is docstring return parameter x : int ======= return int &quot;&quot;&quot; return x 4.4 python 가이드 라인 함수는 가능하면 짧게 작성한다 함수이름에 역할, 의도를 명확하게 나타낼 수 있도록 한다 하나의 함수에는 유사한 역할을 하는 코드만 포함한다 parameter로 받은 값 자체를 바꾸지 않는다 공통 코드나 복잡한 수식은 함수로 나타낸다 PEP8 참고해보자 5. input &amp; print &amp; fommatting input 함수는 콘솔창에서 문자열을 입력받는 함수이다(string 형태로 받아옴) print 함수는 입력받은 값을 문자열으로 출력한다 , 를 사용할 경우 print문이 공백을 사이에 두고 연결된다123print(&quot;name :&quot;)name = input() # input -&gt; 규범print(&quot;Hello&quot;, name) # Hello 규범 formatting을 통해서 출력양식의 형식을 지정할 수 있다. type 설명 %s 문자열(string) %c 문자 1개(character) %d 정수 (int 형) %f 부동소수(float 형) %o 8진수 %x 16진수 %% % 문자 자체 %n.m(datatype) string : n개의 문자로 맞춘다(공백으로 채운다). m 자리수까지만 나타낸다(혼용 불가) int : n개의 문자로 맞춘다(공백으로 채운다). m 은 사용불가 float : n개의 문자로 맞춘다(공백으로 채운다). 소숫점 m자리까지 나타낸다 Python 3.6 이후의 PEP8에 근거한 formatting 123name = Joneage = 20print(f'Hello, {name}. I am {age}.') # Hello, Jone. I am 20. 예전방식 12print('%s %s' % ('one', 'two')) # one twoprint('%d %d'.format(1, 1)) # one two","link":"/2022/01/18/boostcamp/week/week1/python-2/"},{"title":"부스트 캠프 ai tech 1주 2일차 Python Basic for AI (3)","text":"6. Condition (조건문) 조건에 따라 특정한 동작을 하게 하는 명령어 python 에서는 if, elif, else의 예약어를 사용한다 조건을 나타내는 기준과 실행해야하는 명령으로 구성된다 조건이 참일때만 실행한다12345678if age &lt;= 13: print('초등학생')elif age &lt;= 16: print('중학생')elif age &lt;= 19: print('고등학생')else: print('성인') 비교연산자 설명 x &lt; y x가 y보다 작은지 검사 x &gt; y x가 y보다 큰지 검사 x == y x와 y가 같은값인지 검사 x is y x와 y의 메모리 주소가 같은지 검사 x != y x와 y가 같은값인지 검사 x is not y x와 y의 메모리 주소가 같은지 검사 x &gt;= y x가 y이상인지 검사 x &lt;= y x가 y이하인지 검사 c언어에서는 0은 False, 1은 True를 나타내지만, python에서는 성립하지 않는다 존재하면 참, 없으면 거짓으로 판단한다 and, or, not 논리키워드와도 같이 사용한다123if 1 # Trueif 0 # Trueif None # False 6.1 삼항연산자(Ternary operators) 참과 거짓만 존재하는 결과를 한줄에 표현 할 수 있다.12a = 1print('number' if isinstance(a, int) else 'not number') isinstance(var, datatype) -&gt; boolean데이터의 타입을 판단하는 함수 7. 반복문 정해진 동작을 반복적으로 수행하게 하는 명령문 for, while 명령 키워드가 존재한다 7.1 for 문 iterable 한 object의 원소의 갯수 만큼 반복시켜주는 반복문 range, enumerate등과 연계하여 사용이 가능하다123456for i in range(1, 10, 2): print(i) # 1, 3 ... 7 ,9for i in range(10, 1, -1): print(i) # 10, 9, ... , 2, 1for i, x in enumerate('apple'): print(i, x) # 0 a, 1 p, ... , 4 e 7.2 while 문 조건을 만족하는 동안 반복적으로 명령을 수행한다12345i = 0while i &lt; 5: print(i) i += 1# output 0, 1, 2, 3, 4 7.3 반복문 제어 break : 특정 조건에서 가장 가까운 반복문을 종료한다 continue : 특정 조건에서 남은 명령을 skip 하고 다음 루프로 넘어간다 else : 반복조건이 만족하지 않은경우 반복 종료시 1회 수행한다. break로 반복문에서 탈출할 경우에는 수행하지 않음","link":"/2022/01/18/boostcamp/week/week1/python-3/"},{"title":"부스트 캠프 ai tech 1주 2일차 Python Basic for AI (4)","text":"8. 문자열(string) char들이 저장되어있는 시퀸스 자료형 기본적으로 list와 같은 형태로 데이터를 처리한다 Indexing, Slicing, +, * 연산은 리스트와 동일하게 수행한다 8.1 자주 사용하는 문자열 함수 함수명 기능 len(a) 문자열의 문자 개수를 반환 a.upper() 대문자로 변환 a.lower() 소문자로 변환 a.capitalize() 첫 문자를 대문자로 변환 a.strip(input) a.rstrip(input) a.lstrip(input) 좌우/우/좌 input을 없앰 a.split(input) input 기준으로 문자열을 나눠서 리스트로 반환 a.isdigit() a.islower() a.isupper() 문자열이 숫자/소문자/대문자인지 여부 반환 a.startswith(input) a.endswith(input) 문자열이 input으로 시작/끝 나는 문자열 여부 반환 str.join(list) list의 원소들을 str로 연결해서 하나의 문자열로 나타낸다 단 list의 원소는 모두 문자열 type 이어야 한다 8.2 다양한표현 \\ (백슬래쉬) : 특수하게 사용하는 문자열을 표현하기위해서 사용한다 백슬래쉬를 표현하기 위해서는 \\\\ 두번 사용하면 된다. \\n : 줄바꿈을 의미하는 특수문자 \\t : TAB “””문자열””” : 줄바꿈도 자유롭게 입력 가능한 문자열 표현 r”문자열” : 특수문자를 무시하고 그대로 출력함12print(r'이건 줄바꿈 기호입니다 \\n')# output : 이건 줄바꿈 기호입니다 \\n","link":"/2022/01/18/boostcamp/week/week1/python-4/"},{"title":"부스트 캠프 ai tech 1주 2일차 Python Basic for AI (5)","text":"9. 데이터 구조 Stack &amp; Queue Tuple &amp; Set Dictionary Collection 9.1 Stack &amp; Queue Stack 나중에 넣은 데이터를 먼저 반환하도록 설계된 데이터 구조 LIFO (Last in First Out) 입력을 Push, 출력을 Pop이라고 한다 python의 list는 기본적으로 Stack의 구조를 가진다 Queue 먼저 넣은 데이터가 먼저 반환하도록 설계된 데이터 구조 FIFO (First in First Out) 입력은 Push, 출력은 get 이라고 한다 보통 python의 Dequeue를 사용한다. 정해진 크기를 넘어갈 경우 overflow, element가 없는데 반환을 시킬경우 underflow라고 한다. 9.2 Tuple &amp; Set Tuple 값의 변경이 불가능한 리스트 index로 접근해서 값을 수정하는것을 막는다 정의 할 때 ( )를 사용한다 리스트와 동일하게 (+, *)연산, Indexing, Slicing을 사용한다 사용자의 실수에 의한 에러를 사전에 방지하기 위해 변경할 필요가 없는 데이터를 저장할 때 사용한다 123t = (1, ) # 값이 1개인 Tuple은 반드시 ,를 붙여야 함t + t # (1, 1)t[0] = 2 # Error 발생함 Set 값을 순서없이 저장, 중복을 허용하지 않는 자료형(확인필요) set( )을 통하여 객체를 생성한다 set을 이용하여 다양한 집합연산이 가능하다12345678s1 = set([1, 2, 3, 4, 5])s2 = set([1, 3, 5, 7, 9])s1.union(s2) # (1, 2, 3, 4, 5, 7, 9) 합집합s1 | s2 # (1, 2, 3, 4, 5, 7, 9) 합집합s1.intersection(s2) # (1, 3, 5) 교집합s1 &amp; s2 # (1, 3, 5) 교집합s1.difference(s2) # (2, 4) 차집합s1 - s2 # (2, 4) 차집합 9.3 Dictionary 데이터를 저장 할 때 구분지을수 있는 값(Key)를 함께 저장 Hash 구조 Key값을 활용하여 Value를 관리한다. dict( )나 { }로 객체를 생성한다 12345678910number_dic = {'one': 1, 'two': 2, 'three': 3}number_dic['one'] # 1, Key 값으로 value 출력 가능country_code.items() # 데이터 출력# dict_items([('one', 1), ('two', 2), ('three', 3)])number_dic.keys() # key만 출력# dict_keys(['one', 'two', 'three'])number_dic.values() # value만 출력# dict_values([1, 2, 3])number_dic.get(1) # None, 아닐경우 Nonenumber_dic.get('one') # 1, key가 존재할 경우 values 값을 return 9.4 Collections Python Built-in 확장 모듈 편의성, 실행 효율 등을 사용자에게 제공함 자주 사용되는 deque, difaultdict, Counter에 대해서만 다룰것이다 deque Stack과 Queue의 기능을 모두 지원하는 데이터 구조 List에 비해 효율적인 저장방식을 지원한다 popleft()등 삽입 삭제에 매우 효율적임 Linked List의 특성(rotate, reverse)을 지원한다 기존 list 형태의 함수를 모두 지원함12345from collections import dequeq = deque()q.append(a) # [a]q.appendleft(b) # [b, a]q.popleft() # [a] defaultdict Dict type값에 기본값을 지정해서 key가 존재하지 않아도 기본값으로 찾아지는 기능을 가지고 있다 defaultdict(datatype) 으로 기본값의 자료형을 정하면서 dict객체를 생성할 수 있다1234from collections import defaultdictdic = defaultdict(int)dic['a'] += 1 # {'a': 1}dic['b'] -= 1 # {'a': 1, 'b': -1} Counter 시퀸스 type의 data element들의 갯수를 dict형태로 변환123from collections import Counterc = Counter([1, 3, 5, 3, 2, 4, 3])# Counter({1: 1, 3: 3, 5: 1, 2: 1, 4: 1})","link":"/2022/01/18/boostcamp/week/week1/python-5/"},{"title":"부스트 캠프 ai tech 1주 3일차 Python Basic for AI (7)","text":"11. Object Oriented Programming (객체 지향적 프로그래밍, OOP) 객체(Object)란?프로그램에서 사용되는 데이터 또는 식별자에 의해 참조되는 공간, 독립된 단위를 의미한다 OOP는 여러개의 독립된 객체들의 모임으로 프로그램을 구성하는것을 이야기한다 11.1 Object in Python Python에서의 객체는 class로 선언이 가능하다 class는 속성(Attribute)와 명령어(Method)을 가지고 있다 Attribute해당 class가 가지고 있는 특별한 변수를 말한다. 이 변수는 다른 객체가 될 수도 있다. __init__(self) 메서드로 속성을 미리 설계할 수 있다 Method해당 class가 내장하고 있는 함수들을 지칭한다. 메서드는 class 안에 기존 함수와 같은 방식으로 정의가 가능하나, 반드시 self를 추가해야 메서드로 인정된다. 또한 python에는 특별한 메서드 들이 존재한다 class의 이름 선언과 함께 __init__메서드에 parameter 값들을 입력하면 객체를 생성 할 수 있다 class_name.method_name()과 같은 형식으로 객체의 메서드를 호출 할 수 있다 예시 축구선수 12345678910111213141516171819202122232425262728class SoccerPlayer(object): def __init__(self, name, position, back_number): self.name = name self.position = position self.back_number = back_number def change_back_number(self, new_number): print(&quot;선수의 등번호를 변경합니다 : From %d to %d&quot; % (self.back_number, new_number)) self.back_number = new_number def kick(self): pass def heading(self): pass def moving(self): passjinhyun = SoccerPlayer(&quot;Jinhyun&quot;, &quot;MF&quot;, 10)print(&quot;현재 선수의 등번호는 :&quot;, jinhyun.back_number)jinhyun.change_back_number(5)print(&quot;현재 선수의 등번호는 :&quot;, jinhyun.back_number)==================================================output:현재 선수의 등번호는 : 10선수의 등번호를 변경합니다 : From 10 to 5현재 선수의 등번호는 : 5 11.1.1 Special method class에는 __init__ 과 같이 특정한 일을 전담하는 정해진 메서드들이 존재하고 이것들을 Special method라고 부른다 class 내부에 Special method를 정의하면 객체간의 operator 연산 등 여러가지를 할 수 있다. 자세한 내용은 링크로 남기고 생략한다. 여러가지 스페셜 메서드 11.2 OOP의 특징 Visibility 가시성 객체의 정보를 볼수 있는 레벨을 조절한다 유저에게 필요한 부분은 보여주고(추상화), 노출할 필요가 없는 정보들은 숨긴다(캡슐화) __ 를 속성이나 메서드 앞에 붙여서 객체 외부에서 접근할 수 없게 한다 결론 : docstring 잘 쓰는게 중요하다 Inheritance 상속 부모클래스로부터 속성과 Method를 물려받은 자식클래스를 생성 하는 것을 말한다 super를 통해 부모클래스의 메서드를 호출 할 수 있다 코드의 재사용이 목적이다 polymorphism 다형성 같은 이름의 메서드의 내부로직을 다르게 사용할 수 있다. 자식클래스에서 메서드를 재정의(overiding)하여 새로 맞춰서 사용이 가능하다 123456789101112131415161718192021class TeamAPlayer(SoccerPlayer): def __init__(self, regular): super().__init__(name, position, back_number) self.regular = regular def is_regular(self): print(self.name, '선수는 주전', '입니다' if self.regular else '이 아닙니다') def change_back_number(self, new_number): print(f&quot;팀 A {self.name}선수의 등번호를 변경합니다&quot;) super().change_back_number() self.back_number = new_numberjinhyun = TeamAPlayer(&quot;Jinhyun&quot;, &quot;MF&quot;, 10, False)jinhyun.is_regular()jinhyun.change_back_number(5)=============================output:Jinhyun 선수는 주전 이 아닙니다팀 A Jinhyun선수의 등번호를 변경합니다선수의 등번호를 변경합니다 : From 10 to 5 참고 자료객체 지향 프로그래밍 - wikipedia","link":"/2022/01/19/boostcamp/week/week1/python-7/"},{"title":"부스트 캠프 ai tech 1주 3일차 Python Basic for AI (8)","text":"12. Module 모듈 작은 프로그램 조각이 조각들을 모아서 하나의 큰 프로그램을 만든다 사용하는 이유 : 다른 프로그램에서 사용하기가 편하다편하면 무조건 해야지 module == .py 파일 import 문을 사용하여 같은폴더 내의 module 이나 package를 호출한다 module을 호출하는 방법 별칭으로 호출 특정 함수 또는 클래스만 호출 모듈에 모든 함수또는 클래스를 호출 123import numpy as np # 1from numpy import ndarray # 2from numpy import * # 3 python에는 수많은 Built-in Modules이 존재한다 random, tqdm, time, collection, heap, Math … 13. package 다양한 모듈이 모여서 이루어진 코드 묶음 오픈소스들이 모두 패키지로 관리된다 각 폴더별로 필요한 모듈을 구현하고, __init__.py를 구성한다 추후에 __init__.py 와 __main__.py 작성법에 관련되어 포스팅을 할 예정이다","link":"/2022/01/19/boostcamp/week/week1/python-8/"},{"title":"부스트 캠프 ai tech 1주 3일차 Python Basic for AI (9)","text":"14. Exception Handing 사전에 인지했거나 예측 하지못한 각종의 예외들을 대처하기위한 방법 개발자가 반드시 명시적으로 정의해야한다 try ~ except 1234try: 예외 발생 가능 코드except (exception 종류): 예외 발생시 대응하는 코드 try ~ except ~ else else : 예외가 발생하지 않을때 진행하는 부분 123456try: 예외 발생 가능 코드except (exception 종류): 예외 발생시 대응하는 코드else: 예외가 발생하지 않을 때 동작하는 코드 try ~ except ~ finally finally : 예외가 발생해도 진행하는 부분 123456try: 예외 발생 가능 코드except (exception 종류): 예외 발생시 대응하는 코드finally: 예외에 상관없이 동작하는 코드 기본적으로 제공하는 exception 종류 : 링크 raise 함수를 사용하여 강제로 Error나 Exception을 발생시킬 수 있다. 15. File Handing 코드로 파일을 처리하기 위한 방법 파일 처리를 위해서 open 을 사용한다1234f = open('파일이름', '접근모드')......f.close() 모드 설명 r 읽기모드 - 파일 내용을 읽어올 때 사용 w 쓰기모드 - 파일 내용을 수정할 때 사용 a 추가모드 - 파일에 내용을 추가할 때 사용 b 바이너리 모드 - 바이너리형식으로 파일을 읽기/수정/추가할 때 사용 + 파일을 읽고 쓰기용으로 열기 (앞의 모드에 따라서 파일 포인터의 위치차이가 존재한다) x 쓰기모드로 생성하는데 이미 파일이 존재할 경우 예외를 발생시킨다 16. Logging Handling Log프로그램이 실행되는 동안 일어 나는 정보를 말한다. 이런 기록들을 모아 분석하여 의미있는 결과를 도출 할 수 있기 때문에 Log를 따로 관리하는 모듈을 사용한다 Python의 기본 Log 관리모듈 logging이 존재한다 logging level에 관련한 표 : 아래로 내려갈수록 높은 레벨의 log이다","link":"/2022/01/19/boostcamp/week/week1/python-9/"},{"title":"부스트 캠프 ai tech 1주 2일차 Python Basic for AI (6)","text":"10. Pythonic Code Python 스타일의 효율적인 코딩기법 사용하면 코드를 간결하고 이쁘게 작성할 수 있다. 그리고 잘하는 사람처럼 보인다 그러니 모두 잘 익히고 사용하자 10.1 List comprehension 기존의 list를 사용하여 간단한 list를 만드는 기법 for 문 + list.append 보다 속도가 빠르다 조건문과 함께 더 다양한 list를 표현 가능하다123456# 기존 방법a = []for i in range(10): a.append(i)# list comprehensiona = [i for i in range(10)] 10.2 enumerate &amp; zip enumerate for 문에서 iterable object의 element를 추출할 때 인덱스 번호와 함께 추출12345for i, x in enumerate('apple'): print(i, x) # 0 a, 1 p, ... , 4 elist(enumerate('apple'))output = [(0, 'a'), (1, 'p'), (2, 'p'), (3, 'l'), (4, 'e')] zip 여러개의 list값을 병렬적으로 추출해서 하나의 list로 재결합 시킨다.12345a = (1, 2, 3)b = (4, 5, 6)print(list(zip(a, b)))######################[(1, 4), (2, 5), (3, 6)] 10.3 map &amp; lambda &amp; reduce map iterable object의 element에 각각 특정한 함수를 적용할 수 있는 함수 아래의 lambda와 병행하여 자주, 많이 쓰인다 실행시점의 값을 생성해서 메모리를 효율적으로 사용한다1234567def function(x): return x**2a = [1, 2, 3, 4, 5]print(list(map(function, a)))#############################output =&gt; [1, 4, 9, 16, 25] lambda 함수를 따로 정의할 필요 없이 사용할 수 있는 익명 함수 PEP8에서 권장하지는 않지만 아직도 많이쓰고 스스로도 많이 쓰고있다 어려운 문법, 테스트하기 힘듬, docstring 지원안함, 코드해석이 어려움 등등의 문제가 있다 간단한 명령문인 경우 따로 정의하지 않고 lambda를 사용하는 편이다1234a = [1, 2, 3, 4, 5]print(list(map(lambda x: x**2, a)))#############################output =&gt; [1, 4, 9, 16, 25] reduce map과 비슷한 동작으로 list에 똑같은 함수를 적용해서 합쳐나간다 2년 넘게 공부하면서 한번도 쓴적이 없다 python3 버전에서 lambda와 같이 사용을 권장하지 않는다12from functools import reduceprint(reduce(lambda x, y: x+y, [1, 2, 3, 4, 5])) 10.4 iterable object 시퀸스형 자료형에서 데이터를 순서대로 추출하는 object object 내부적으로 __iter__와 __next__라는 함수(메서드)가 존재한다 .iter() 와 .next() 함수로 iterable 객체를 iterator object로 사용이 가능하다 아래의 generator와 같이 사용하면 정말 강력한 성능을 보이게 된다123456789101112cities = [&quot;Seoul&quot;, &quot;Busan&quot;, &quot;Jeju&quot;] iter_obj = iter(cities) print(next(iter_obj))print(next(iter_obj)) print(next(iter_obj)) next(iter_obj)==============output:SeoulBusanJejuError 발생 더이상 출력할 수 있는 원소가 없음 10.5 generator iterable object를 특수한 형태로 사용해주는 함수 object 내부의 element가 호출되는 시점에 값을 메모리에 반환한다 yield를 사용해서 한번에 하나의 element만 반환함 이 것이 궁금하다면 python 코루틴 관련해서 찾아보는것이 좋다 일반적인 iterator 보다 generator가 훨씬더 적은 메모리를 사용한다 먼 훗날에 나올 Dataset이 generator를 이용한 object이다 123456789101112131415161718192021222324252627def my_gen(): n = 1 print('This is printed first') # Generator function contains yield statements yield n n += 1 print('This is printed second') yield n n += 1 print('This is printed at last') yield n# Using for loopfor item in my_gen(): print(item)=====================output:This is printed first1This is printed second2This is printed at last3 예제출처 generator도 list comprehension과 유사한 형태로 표현이 가능하다 [] 대신 ()로 표현한다. 123456789101112131415161718gen_ex = (n*n for n in range(500)) print(next(gen_ex)) # 0 1 4 ....``` ### 10.6 function passing arguments* 함수에 입력되는 Argument는 아래와 같이 다양한 형태를 가진다 * Keyword arguments * 함수에 입력되는 parameter의 변수명을 같이 입력하여 순서에 상관없이 parameter를 지정 해 줄 수 있다```pythondef function(a, b): return a*2 + bprint(function(3, 5))print(function(b=5, a=3))=========================output:1111 Default arguments parameter의 기본값을 사용한다 따로 argument가 입력되지 않을 경우 기본값으로 출력한다12345678910111213141516171819202122232425262728def function(a, b=0): return a*2 + bprint(function(3, 1))print(function(3))==================output:76``` * Variable-length arguments(가변인자) * 개수가 특정되지 않은 변수를 함수의 parameter로 사용하는 방법 * Asterist * 기호를 사용하여 argument를 나타낸다 * 입력된 값은 Tuple로 사용할 수 있다 * 함수에서 단 하나 존재하고, 뒤에 일반적인 argument가 존재할 수 없다```pythondef asterisk_test(a, b, *args): print(args) return a+b+sum(args)print(asterisk_test(1, 2, 3, 4, 5))===================================output:(3, 4, 5) 튜플의 형태로 존재한다15 Keyword Variable-length arguments(키워드 가변인자) Parameter의 이름을 따로 지정하지않고 입력하는 방법 Asterisk 두개 (**) 를 사용하여 함수의 parameter를 표시한다 입력된 값은 dict type으로 사용할수 있다 함수에서 단 하나 존재하고 뒤에 다른 argument가 존재할 수 없다 12345678def asterisk_test(a, b, **kargs): print(kargs) return a+b+sum(kargs.values())print(asterisk_test(1, 2, three=3, four=4, five=5))===================================================output:{'three': 3, 'four': 4, 'five': 5}15 10.7 Asterisk Asterisk는 위의 가변인자와 곱하기 연산자 이외의 기능이 존재한다 list, tuple 등의 자료형 변수 앞에 *를 붙여서 unpacking 할 수 있다 dict type의 경우 **를 붙여서 키워드 가변인자처럼 출력이 가능하다12345678910111213a = [1, 2, 3, 4]print(a)print(*a)b = {'one':1, 'two':2, 'three':3}print(*b)print(asterisk_test(1, 2, **b))===============================output:[1, 2, 3, 4]1 2 3 4one two three{'one': 1, 'two': 2, 'three': 3}9","link":"/2022/01/18/boostcamp/week/week1/python-6/"},{"title":"부스트 캠프 ai tech 1주 1일차 Python Basic for AI (1)","text":"1. Python의 특징 독립적인 플랫폼운영체제에 상관없이 작동하는 언어이다. 인터프리터 언어별도의 컴파일링 없이 컴퓨터가 바로 처리할 수 있는 언어이다. 속도는 컴파일러 언어에 비해서 느리지만 메모리가 적게 필요하다. 객체지향적실행 순서가 아닌 단위 모듈 중심으로 프로그램이 작성된다. Dynamic Typing 언어프로그램이 실행하는 시점에 프로그램이 사용해야하는 데이터 타입이 결정된다. 2. 변수 데이터를 저장하기 위한 메모리 공간 변수가 정의되면 변수는 메모리 주소를 할당 받고, 그 메모리 위치에 값을 저장한다. 그 외에 python에서 어떻게 변수를 할당받고 메모리를 관리하는지 알고싶으면 아래의 영상을 참고하는걸 추천한다. https://www.youtube.com/watch?v=arxWaw-E8QQ 기본 자료형들은 +, -, *, %의 사칙연산이 가능 하다 Dynamic Typing을 지원하기 때문에 정의할 때에 자료형을 특정하지 않아도 된다. 실행하는 시점에서 변수형을 확인하고 결정하기 때문에 타 언어보다 속도가 느리다. 아래와 같이 자료형간 형 변환또한 가능하다. 12345a = 1 # int형으로 정의int(a) # int() 로 형 변환 가능 str(a) # str로 재정의 이때의 값은 '5'float(a) # float형으로 재정의 이때의 값은 '5.0'bool(a) # boolean 형으로 재정이 이때의 값은 True 3. 리스트 여러 데이터들을 묶어서 표현할 수 있는 자료형 python 에서는 리스트 내부에 여러가지 자료형이 동시에 존재할 수 있다. 1. List Indexing &amp; Slicing Indexing : 리스트에 있는 값들은 주소를 사용해 호출이 가능하다 index를 넣는 곳에 음수값을 넣어서 뒤에서부터 호출 할 수 있다. len(object_name) : object의 길이를 반환한다123456color = ['red', 'blue', 'green']print(colors[0]) # redprint(colors[-1]) # greenprint(len(colors)) # 3color[0] = 'Yellow' # ['Yellow', 'blue', 'green'] Slicing : list의 값들을 잘라서 부분적으로 표현할 수 있다. index과 같이 음수값 통해 역순으로도 가능하다. 12345numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 0]print(numbers[0:6]) # [1, 2, 3, 4, 5, 6] index 0번부터 6개print(numbers[:]) # [1, 2, 3, ... , 7, 8, 9] 처음부터 끝까지print(numbers[::2]) # [1, 3, 5, 7, 9] 2칸단위로 슬라이싱print(numbers[-5::-1]) # [6, 5, 4, 3, 2, 1] 뒤에서 5번째부터 역순으로 슬라이싱 2. List 연산 + : 두 리스트를 합쳐준다 * : 리스트를 n회 반복해서 늘린다 1234num1 = [1, 2, 3]num2 = [3, 4, 5]num1 + num2 # [1, 2, 3, 3, 4, 5]num1 * 2 # [1, 2, 3, 1, 2, 3] list.append(element) : list에 element를 추가한다 list.extend(iterable) : list에 iterable의 원소들을 추가한다 list.insert(index, element) : list의 특정 index 위치에 element를 삽입한다 list.remove(element) : list의 특정 element를 삭제한다 12345num = [1, 2, 3]num.append([4, 5]) # [1, 2, 3, [4, 5]]num.extend([1, 2]) # [1, 2, 3, [4, 5], 1, 2]num.insert(0, 'a') # ['a', 1, 2, 3, [4, 5], 1, 2]num.remove(1) # ['a', 2, 3, [4, 5], 2] 3. 2-dim list 행렬 기존의 리스트와 비슷하지만, 복사할때 주의할점이 필요하다리스트를 복사할때 리스트 주소가 복사되기 때문에 내부의 리스트는 동일한 주소의 값을 가져 하나의 리스트를 변경하면 다른 리스트값도 변경됨 python 모듈중 copy의 deepcopy를 이용하여 복사1234mat = [[1, 2, 3], [4, 5, 6]]mat2 = matmat[1][0] = 2 # [[2, 2, 3], [4, 5, 6]]mat2 # [[2, 2, 3], [4, 5, 6]]","link":"/2022/01/17/boostcamp/week/week1/python_1/"},{"title":"부스트 캠프 ai tech 2주 1일차 Pytorch (1)","text":"0. pytorch란? Meta(구 Facebook) 에서 개발한 딥러닝 프레임워크 numpy + AutoGradient 동적 그래프 기반 1. pytorch 기본 pytorch 에서는 Tensor class를 사용한다 Tensor numpy의 ndarray와 사실상 동일하다 내장 함수도 대부분 비슷한 기능이 존재한다 tensor가 가질수 있는 type은 ndarray와 동일하나 GPU 사용이 가능한 차이가 존재한다 1.1 기본 Tensor 함수 list &gt; tensor1234567import torchdata = [[3, 5],[10, 5]]x_data = torch.tensor(data)##########################output:tensor([[ 3, 5], [10, 5]]) ndArray &gt; tensor123456nd_array_ex = np.array(data)tensor_array = torch.from_numpy(nd_array_ex)############################################output:tensor([[ 3, 5], [10, 5]]) tensor &gt; ndarray12345tensor_array.numpy()####################output:array([[ 3, 5], [10, 5]]) flatten123456data = [[3, 5, 20],[10, 5, 50], [1, 5, 10]]x_data = torch.tensor(data)x_data.flatten()################output:tensor([ 3, 5, 20, 10, 5, 50, 1, 5, 10]) one_like123456torch.ones_like(x_data)#######################output:tensor([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) shape, dtype12x_data.shape # torch.Size([3, 3])x_data.dtype # torch.int64 GPU load123device = torch.device('cpu')if torch.cuda.is_available(): device = torch.device('cuda') 1.2 Tensor handling view &amp; reshape tensor의 shape를 변경하는 함수 view는 input tensor와 return tensor가 데이터를 공유하여 항상 같은 주소값들을 가진다 reshape은 tensor의 복사본 혹은 view를 반환한다 원본과 동일한 tensor값이 필요할 경우에는 view를 사용하거나 clone()을 이용해야한다 squeeze &amp; unsqueeze 차원의 개수가 1인 차원을 축소, 확장하는 함수 unsqueeze(index) : index에 1인 차원을 삽입해서 차원을 확장한다12345678tensor_ex = torch.rand(size=(2, 1, 2))tensor_ex.squeeze().shape # torch.Size([2, 2])tensor_ex = torch.rand(size=(2, 2))tensor_ex.unsqueeze(0).shape # torch.Size([1, 2, 2])tensor_ex = torch.rand(size=(2, 2))tensor_ex.unsqueeze(1).shape # torch.Size([2, 1, 2])tensor_ex = torch.rand(size=(2, 2))tensor_ex.unsqueeze(2).shape # torch.Size([2, 2, 1]) 1.3 Tensor operation numpy와 동일하게 operation에 대해서 broadcasting을 지원한다 행렬곱셈 연산은 mm 및 matmul을 사용한다 dot은 1차원 벡터와 스칼라 연산에서만 사용가능 mm과 matmul은 2차원이상의 행렬연산에서만 사용가능 mm은 broadcasting을 지원하지 않지만 matmul은 지원한다 1.4 Tensor operation for ML/DL formula nn.functional을 이용한 다양한 연산가능 softmax, argmax, one_hot 등등 1.5 AutoGrad 자동 미분 tensor에 requires_grad=True로 설정해서 자동으로 gradient 추적이 가능하다 기본적으로 nn모듈의 선형연산들은 default로 True로 설정되어있어 잘 쓰지 않는다1tensor(data, requires_grad=True) backward() 함수를 통하여 Backpropagation 수행","link":"/2022/01/24/boostcamp/week/week2/pytorch-1/"},{"title":"부스트 캠프 ai tech 2주 4일차 Pytorch (8)","text":"Pytorch Troubleshooting OOM : Out Of Memory GPU의 메모리가 터질때 발생하는 현상… 왜 발생했는지 알기힘듬 메모리의 이전상황의 파악이 어려움 OOM의 해결방법 보통 이 아래방법으로 대부분 해결된다 Batchsize를 줄여서 메모리 부하를 줄인다 torch.cuda.empty_cache()를 이용하여 GPU의 메모리를 clear 한 뒤에 학습시킨다 그 외에 신경쓰면 좋을점 GPUtil Module 사용하기 tensor.no_grad() 사용하기 적절하게 del 명령어 사용하기 다양한 batchsize로 돌려서 가능한 batchsize 알아보기 tensor의 float 32를 float 16으로 줄여보기 reference Naver Connect Boostcamp - ai tech","link":"/2022/01/27/boostcamp/week/week2/pytorch-10/"},{"title":"부스트 캠프 ai tech 2주 1일차 Pytorch (2)","text":"2. 유용한 torch 함수들 torch의 내장함수들 중 자주 쓰일만한 녀석들의 정리글이다pytorch 공식문서 - 링크 Tensors Creation Ops indexing, Slicing, Joining, Mutating 2.1 Tensors is_* 데이터 형태가 tensor인지 판단, tensor의 내부 데이터 등의 여러가지 판단을 하는 함수123x = torch.tensor([0])is_tensor(x) # Trueis_nonzero(x) # False, input : single element tensor torch.numel(x) 전체 element가 몇개인지 출력하는 함수 12a = torch.randn(1, 2, 3, 4, 5)torch.numel(a) # 120 2.2 Creation Ops torch.from_numpy ndarray를 torch.Tensor로 바꾸는 함수 torch.zeros(size), empty(size), ones(size) 0, 빈, 1로 이루어진 tensor를 size 형태로 생성하는 함수 numpy와 같은 기능을 한다 torch.zeros_like(tensor), empty_like(tensor), ones_like(tensor) tensor의 size를 가진 0, 빈, 1로 이루어진 tensor를 생성하는 함수 numpy와 같은 기능을 한다 torch.arrange(start, end, step) numpy의 arrange와 같은 기능을 하는 함수 start 부터 end 까지 step마다의 수를 가진 1D-tensor를 생성한다 torch.linspace(start, end, steps) start에서 end의 구간의 길이를 steps개로 균등하게 나누는 1D-tensor를 생성한다 torch.full(size, fill_value), torch.full_like(tensor, fill_value) fill_value로 채워진 tensor를 생성한다 2.3 indexing, Slicing, Joining, Mutating 함수 torch.index_select(input, dim, index) 특정한 index에 위치한 데이터를 모아서 return 해주는 함수123456A = torch.Tensor([[1, 2], [3, 4]])torch.index_select(A, 1, torch.tensor([0]))===========================================output:tensor([[1.], [3.]]) torch.gather(input, dim, index) 특정한 index들에 위치한 데이터를 모아서 return 해주는 함수1234567891011t = torch.tensor([[1, 2], [3, 4]])torch.gather(t, 1, torch.tensor([[0, 0], [1, 0]]))==================================================output:tensor([[ 1, 1], [ 4, 3]])==================================================index calculate:out[i][j][k] = input[index[i][j][k]][j][k] # if dim == 0out[i][j][k] = input[i][index[i][j][k]][k] # if dim == 1out[i][j][k] = input[i][j][index[i][j][k]] # if dim == 2 torch.cat(tensors, dim) == torch.concat tensors들을 합치는 함수 기준이 되는 dim을 제외하고 같은 shape를 가지고 있어야한다123x = torch.rand(1, 3)y = torch.rand(2, 3)torch.cat((x,y), 0).size() # torch.Size([3, 3]) torch.chunk(input, chunks, dim) tensor를 chunk의 갯수만큼으로 분리해주는 함수 chunks의 갯수가 넘어가지 않는 선에서 같은 size의 tensor로 분리해준다 나누어 떨어지지 않는경우 마지막 tensor의 사이즈의 크기가 다를 수도 있다12345678torch.arange(13).chunk(6)=========================output:(tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([ 9, 10, 11]), tensor([12])) 12345678t = torch.tensor([[1, 2, 3], [4, 5, 6]])print(torch.chunk(t, 2, 1))===========================output:(tensor([[1, 2], [4, 5]]), tensor([[3], [6]])) torch.Tensor.scatter_(dim, index, src, reduce=None) Tensor에 index에 맞춰서 src를 삽입하는 함수이다 reduce에 add, multiple을 넣어서 더하거나 곱하기도로 바꿀 수 있다 torch.gather와 반대로 작동한다1234567891011121314src = torch.arange(1, 11).reshape((2, 5)) # tensor([[ 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10]])index = torch.tensor([[0, 1, 2, 0]])torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)==========================================================output:tensor([[1, 0, 0, 4, 0], [0, 2, 0, 0, 0], [0, 0, 3, 0, 0]])==========================================================index calculate:self[index[i][j][k]][j][k] = src[i][j][k] # if dim == 0self[i][index[i][j][k]][k] = src[i][j][k] # if dim == 1self[i][j][index[i][j][k]] = src[i][j][k] # if dim == 2 torch.stack(tensors, dim) 지정하는 차원으로 확장해서 tensor를 쌓아주는 함수이다 두 차원이 정확하게 일치해야 쌓기가 가능하다123x = torch.rand(3, 1, 3) # 3, 1, 3y = torch.rand(3, 1, 3) # 3, 1, 3torch.stack((x,y), dim=2).size() #torch.Size([3, 1, 2, 3]) 2.4 random Sampling 자주 쓰이지만 numpy와 비슷해서 문서를 참고하는편이 좋을듯 하다 Random sampling - PyTorch 공식 문서 torch.seed(), torch.manual_seed(int) Seed값을 고정해서 랜덤한 변수를 고정시킬 수 있다 manual_seed는 직접 시드값을 입력할 수 있다 2.5 Pointwise Ops 수학 연산과 관련된 기능을 포함하는 함수군 numpy와 비슷하다 torch.sqrt(tensor) 각 tensor의 element에 대한 제곱근을 구해주는 함수 torch.exp(tensor) 각 tensor의 element에 대한 $e^x$ torch.pow(tensor) 각 tensor의 element에 대한 $x^2$ 2.6 Reduction Ops 조건에 따라 특정한 tensor의 값을 가져오는 함수군 대부분 numpy와 동일하게 작동한다 Reduction Ops - PyTorch 공식 문서 2.7 Comparison Ops 비교와 관련된 기능을 포함하고 있는 함수군 Comparison Ops - PyTorch 공식 문서 torch.argsort(tensor) tensor를 sort하는 index를 return 해준다1234567891011a = torch.randint(1, 10, (3, 3))atorch.argsort(a)================output:tensor([[9, 5, 3], [6, 4, 2], [5, 8, 6]])tensor([[2, 1, 0], [2, 1, 0], [0, 2, 1]]) torch.eq, torch.gt, torch.ge tensor의 값들이 같은지, 더 큰지, 이상인지를 판단하는 함수들이다 torch.allclose(input, other, trol, atol) input tensor와 other의 원소들의 차가 특정 범위인지를 판단하는 함수$$|\\operatorname{input} - \\operatorname{other}| \\leq atol + rtol \\times|other|$$ 12torch.allclose(torch.tensor([10.1, 1e-9]), torch.tensor([10.0, 1e-08]))# False 2.8 Other Operations 그 외 다양한 기능들이 모여있는 함수들 Other Operations - PyTorch 공식 문서 torch.einsum Einstein Notation에 따라 연산을 진행하는 함수 Einstein Notation은 특정 index의 집합에 대한 합연산을 간결하게 표시하는 방법이다123456789101112131415161718192021222324x = torch.randn(5)y = torch.randn(4)torch.einsum('i,j-&gt;ij', x, y)============================output:tensor([[ 0.1156, -0.2897, -0.3918, 0.4963], [-0.3744, 0.9381, 1.2685, -1.6070], [ 0.7208, -1.8058, -2.4419, 3.0936], [ 0.1713, -0.4291, -0.5802, 0.7350], [ 0.5704, -1.4290, -1.9323, 2.4480]])==============================================As = torch.randn(3,2,5)Bs = torch.randn(3,5,4)torch.einsum('bij,bjk-&gt;bik', As, Bs)====================================output:tensor([[[-1.0564, -1.5904, 3.2023, 3.1271], [-1.6706, -0.8097, -0.8025, -2.1183]], [[ 4.2239, 0.3107, -0.5756, -0.2354], [-1.4558, -0.3460, 1.5087, -0.8530]], [[ 2.8153, 1.8787, -4.3839, -1.2112], [ 0.3728, -2.1131, 0.0921, 0.8305]]]) 2.9 BLAS &amp; LAPACK Ops “BLAS” - Basic Linear Algebra Subprograms “LAPACK” - Linear Algebra PACKage 선형대수에 관련된 함수군이다 BLAS &amp; LAPACK Ops - PyTorch 공식 문서","link":"/2022/01/24/boostcamp/week/week2/pytorch-2/"},{"title":"부스트 캠프 ai tech 2주 2일차 Pytorch (3)","text":"3. torch.nn Pytorch의 Nerual Network와 관련된 기능들이 있는 모듈이다 Neural Network와 관련된 Layer, Function들이 속해있다 Layer : 1층의 인공신경망을 이야기한다. input으로 들어온 값을 선형연산이나, 비선형연산을 통해 output을 return해 주는 class이다 Function : 활성화함수 등의 Neural Network의 연산을 하기위해 필요한 함수을 이야기한다 3.1 nn.Module Custom Network(모델)를 만들기 위해서 지원하는 module이다 nn.Module은 내부에 Module을 포함할 수 있다 여러층으로 쌓이는 모양으로 인해 Layer라고도 부른다 Layer가 모여서 Model을 이룬다 기본적으로 아래와 같은코드를 베이스로 만들 수 있다 super : nn.Module에서 Attribute를 상속받기위한 선언. 이것이 없으면 빈 깡통 클래스이다 forward : 순전파를 구현하는 함수 123456class TestNet(nn.Module): def __init__(self): super(TestNet, self).__init__() def forward(self, x): return x_out 3.2 Container Layer들을 묶어서 보관하기 위한 저장소 Containers - PyTorch 공식 문서 nn.Sequential() 여러 모듈을 하나로 묶어서 하나의 모듈처럼 사용할 수 있는 Container 순차적인 Layer들을 하나로 묶어서 깔끔하게 관리 할 수 있다 nn.ModuleList() 여러 모듈을 list처럼 한군데 모아두는 Container indexing을 통해 필요한 모듈을 꺼내 쓸 수 있다 일반적인 List와 다르게 Attribute여도 Class를 print할 때 외부에 출력된다 nn.ModuleDict() 여러 모듈을 dict처럼 한군데 모아두는 Container Key값을 통해 필요한 모듈을 불러올 수 있다 ModuleList()와 같이 Class를 print할 때 외부에 출력된다 3.3 Parameter &amp; Buffer Parameter 모듈안에 임시로 저장되는 특별한 Tensor 일반적인 Tensor attribute와는 다르게 기울기 계산이 가능하고, 모델저장시에 같이 저장된다 RNN 같이 parameter가 반복되고, 갱신이 필요한 경우 사용된다 또한 모듈속의 내부모듈들의 tensor는 전부 parameter로 지정된다 Parameter()로 선언 할 수 있다 Buffer 모듈안에 임시로 저장되는 Tensor 모델저장시에 같이 저장된다 config용의 정보등을 저장할 때 사용한다 nn.Module의 register_buffer로 등록할 수 있다 3.4 Module 내부 살펴보기 nn.module에는 내부의 여러 attribute를 볼 수 있는 기능이 존재한다 내부의 모듈, Parameter, buffer 등 여러 attribute가 ObjectDict형태로 저장되어 불러올 수 있다 submodule 모듈속 모듈인 submodule은 아래의 함수들로 살펴 볼 수 있다 named_children module에 바로 아래단계에 속한 submodule만 보여준다 named_modules submodule 뿐만아니라 module에 속해있는 모든 module을 보여준다 parameter named_parameters를 통해 parameter를 호출이 가능하다 buffer named_buffers를 통해 buffer 호출이 가능하다 3.5 hook package화 된 코드에서 custom 코드를 중간에 실행시킬 수 있도록 만들어 놓은 인터페이스 pytorch에는 등록하는 대상에 따른 2가지 종류의 hook Tensor에 등록하는 Tensor hook Module에 등록하는 Module hook 실행 시점에 따른 5가지 종류의 hook이 존재한다 forward pre hooks : forward 연산 전에 실행되는 hook forward hooks : forward 연산 후에 실행되는 hook backward_hooks : backward 연산이 수행될때 마다 실행되는 hook. 현재는 사용하는걸 권장하지 않는다 full backward hooks : backward 연산이 수행될때 마다 실행되는 hook state dict hooks : load_state_dict 함수가 모듈 내부에서 실행하는 hook, 직접적으로 user가 잘 사용하지는 않는다 Tensor hook Tensor에 대한 Backward Propagation 후에 작동하는 hook torch.Tensor.register_hook 을 통하여 hook을 등록 할 수 있다 torch.Tensor._backward_hooks 을 통하여 등록한 hook을 확인 할 수 있다1234def hook(grad): passtensor.register_hook(hook)tensor_backward_hooks() # OrderedDict([(0, &lt;function __main__.hook(grad)&gt;)]) Module hook Module hook은 3개의 종류의 hook으로 사용된다 forward pre hooks forward hooks backward_hooks full backward hooks forward pre hooks forward 연산이 일어나기 전 시점에서 실행되는 hook parameter로 module과 input으로 받고 input을 수정해서 return 할 수 있다 Module.register_forward_pre_hook(hook)으로 등록이 가능하다1forward_pre_hook(module, input) -&gt; None or modified input forward hooks forward 연산이 일어난 뒤 시점에서 실행되는 hook parameter로 module, input, output으로 받고, output을 수정해서 return 할 수 있다 input값또한 수정이 가능하지만 forward 연산에 변화는 없다 Module.register_forward_hook(hook)으로 등록이 가능하다1forward_hook(module, input, output) -&gt; None or modified output full backward hooks backward 연산이 수행될때 마다 실행되는 hook parameter로 module, grad_input, grad_output으로 받고, 새로운 grad_input return 할 수 있다 parameter인 grad_input 자체를 수정하면 Error가 발생할 수 있다 Module.register_full_backward_hook(hook)으로 등록이 가능하다 1full_backward_hooks(module, grad_input, grad_output) -&gt; None or modified grad_input 3.6 apply 특정 함수를 Module과 Module에 속한 submodule에 적용하는 함수 weight 초기화나, 내부 모듈에 특정한 method를 추가할 때 사용할 수 있다 weight_initialization1234def weight_initialization(module): module_name = module.__class__.__name__ if 'Function' in module_name: module.W.data.fill_(1) make_method1234567def function_repr(self): return f'name={self.name}'def add_repr(module): module_name = module.__class__.__name__ if 'Function' in module_name: module.extra_repr = partial(function_repr, module)","link":"/2022/01/24/boostcamp/week/week2/pytorch-3/"},{"title":"부스트 캠프 ai tech 2주 3일차 Pytorch (4)","text":"4. Dataset &amp; DataLoader pytorch에서 생성한 모델을 학습시키기 위해 데이터를 공급해주는 유틸리티 4.1 Dataset Data를 담고 있는 Class pytorch Dataset은 아래와 같이 3가지의 기본 Method로 구성되어있다 __init__: 초기화 함수. 필요한 변수들을 선언하고, data를 load하는 부분이다 __len__: 데이터의 개수를 반환하는 함수. Dataloader에서 길이등을 반환하는데 쓰인다 __get_item__(index): index번째의 data를 반환하는 함수. tensor로 return 해준다. 데이터에 따라 Map style과 iterable style로 나뉜다 Map style : 일반적인 data 구조 iterable style : random으로 읽기 어렵거나 data에 따라 batchsize가 달라지는 data. 시계열 데이터 등에 적합하다 Map style 코드는 아래와 같다 1234567891011class BasicDataset(Dataset): def __init__(self, path): self.data = pd.read_csv(path) self.X = self.data.drop(['label']) self.y = self.data['label'] def __get_item__(self, idx): return self.X.iloc[idx], self.y[idx] def __len__(self): return len(self.X) 4.2 DataLoader Dataset을 iterable 하게 사용할 수 있도록 도와주는 Utility data loading 순서 커스터마이징, 자동 batch 설정, Single-Multi process data loading등 여러가지 기능을 지원한다 12345DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None, *, prefetch_factor=2, persistent_workers=False) dataset torch.utils.data.Dataset parameter batch_size Data를 불러올 때 배치사이즈를 설정하는 항목 shuffle Data load 순서를 항상 랜덤하게 뽑을지를 결정하는 항목 torch.manual_seed 를 통해 랜덤값을 고정할 수도 있다 sampler Data의 index를 컨트롤 하는 방법 torch.utils.data.Sampler 객체를 사용한다 SequentialSampler : 항상 같은 순서로 elements들을 sampling한다 RandomSampler : 랜덤하게 sampling 한다. replacement 가능, random의 범위를 지정 가능하다 (default=len(dataset)) SubsetRandomSampler : 랜덤하게 sampling 한다 위의 두 기능은 없다 WeigthRandomSampler : 가중치에 따라 뽑히는 확률이 달라진다 BatchSampler : Batch단위로 sampling을 해준다 DistributedSampler : Multi GPU에서 분산처리를 할때 사용한다 batch_sampler sampler와 같지만 기본적으로 BatchSampler가 적용된 상태이다 num_workers GPU에 Data를 load 할때 사용할 process의 수를 결정한다 collate_fn sample list를 합쳐서 tensor의 minibatch로 바꿔주는 기능. map style의 dataset에서 사용한다 데이터마다의 길이가 다른 NLP에서 많이 사용한다 pin_memory pin memory를 사용하여 GPU에 더 빠르게 data를 load하는 방법. 추가적인 메모리 자원이 필요하다. 보통 parallel 모델에서 많이 사용한다 drop_last Data의 전체 개수가 batchsize로 나누어 떨어지지 않을때 마지막 batch를 drop를 결정하는 parameter reference Naver Connect Boostcamp - ai tech [Pytorch] DataLoader parameter별 용도 Pytorch DataLoader 공식문서","link":"/2022/01/26/boostcamp/week/week2/pytorch-5/"},{"title":"부스트 캠프 ai tech 2주 3일차 Pytorch (5)","text":"학습시킨 모델을 다른사람들에게 공유하거나, 보관하기 위에서는 메모리에 있는 Model들을 따로 파일로 만들어서 저장할 필요가 있는데 본 글에서는 저장을 어떻게 해야하는지, 그리고 이를 이용한 Tranfer Learning 에 대해서 다룰 예정이다 5. Pytorch Model Save &amp; Load torch.save() 학습의 결과를 저장하기 위한 함수이다 모델의 Layer들과 Parameter, Buffer를 저장한다 학습 중간중간 Model을 저장해서 최선의 성능을 가지는 결과모델을 선택하는 방식으로 사용 할 수 있다 (Checkpoint) model : 학습한 모델 PATH : 모델을 저장할 directory 1234# 모델의 weight 만 저장하는 방법torch.save(model.state_dict(), PATH)# 모델의 weight와 내부모듈 구조, Buffer까지 저장하는 방법torch.save(model, PATH) checkpoints 학습의 중간 결과를 저장해서 최선의 성능을 가지는 결과모델을 선택하는 방법 보통 early stopping 기법과 함께 사용한다 early stopping : Loss와 Metric값을 지속적으로 확인 하면서 일정 기간이상 줄지 않으면 학습을 멈추는 방법 일반적으로 epoch, loss, mertic을 함께 저장하여 확인한다 123456789101112torch.save({ 'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'loss': epoch_loss, }, f&quot;saved/checkpoint_model_{epoch}_{epoch_loss/len(dataloader)}_{epoch_acc/len(dataloader)}.pt&quot;)checkpoint = torch.load(PATH)model.load_state_dict(checkpoint['model_state_dict'])optimizer.load_state_dict(checkpoint['optimizer_state_dict'])epoch = checkpoint['epoch']loss = checkpoint['loss'] 6. Transfer Learning 다른 데이터셋으로 만든 모델을 현재 데이터셋에 맞춰서 다시 학습시키는 방법 일반적으로 큰 데이터셋으로 학습시킨 모델(ex Imagenet 10K로 학습시킨 resnet50 등등)의 성능이 다른 데이터셋에 적용시키는것이 처음부터 학습하는 모델보다 학습이 빠르고, 학습이 잘된다 현재 DeepLearning에서 가장 일반적인 학습 방법이다 기존의 pretrained 된 모델을 backbone 모델이라고 하며 여기서 일부 Layer만 변경시켜서 학습을 수행한다 CV : Pytorch 공식 비전 라이브러리 TorchVision 이나 torch image model(timm)을 많이 이용한다 NLP : transformer 전문 라이브러리인 HuggingFace를 많이 사용한다 6.1 Freezing pretrained model을 활용할때 모델의 일부분을 freeze 시켜 파라미터의 업데이트가 일어나는것을 막는 방법 DeepLearning의 특성상 학습이 계속 진행되면서 파라미터가 바뀌면 과거에 학습했던 정보가 희석되는 현상이 일어나는데 특히 pretrained 모델에게 안좋은 영향을 준다 pytorch의 requires_grad를 비활성화 시키거나 hook를 이용해서 backward의 input_grad를 0으로 고정시켜버리는 것으로도 가능하다 reference Naver Connect Boostcamp - ai tech","link":"/2022/01/26/boostcamp/week/week2/pytorch-6/"},{"title":"부스트 캠프 ai tech 2주 4일차 Pytorch (6)","text":"7. Multi GPU 학습 데이터의 양이 방대해짐에 따라서 모든 데이터들을 전부 메모리에 올리는것이 물리적으로 힘들고, 시간적으로도 소요가 많이 되어서 이를 해결하기 위해 여러대의 GPU를 병렬적으로 사용하는 방법이다 크게 2가지의 방법으로 나뉜다 Model 병렬화 : 모델을 나눠서 학습한다 Data 병렬화 : 데이터를 나눠서 학습한다 7.1 Model 병렬화 모델을 나눠서 여러대의 GPU에 올려서 연산하는 방법 모델의 크기가 너무 커서 GPU에 올라가지 않는 상황에서 사용한다 모델의 병목화, 파이프라인 구축 등의 문제로 인해 구현 난이도가 높다 pipeline을 제대로 구축하지 않으면 한 GPU가 연산하는동안 다른 GPU가 놀고있는 상황이 발생해 오히려 Single GPU보다 못한 상황이 발생 할 수 있다 Model Pipeline Paralle 예시 - Pytorch 공식 모델 병렬화 Tutorial 1234567891011121314151617181920212223class PipelineParallelResNet50(ModelParallelResNet50): def __init__(self, split_size=20, *args, **kwargs): super(PipelineParallelResNet50, self).__init__(*args, **kwargs) self.split_size = split_size def forward(self, x): splits = iter(x.split(self.split_size, dim=0)) s_next = next(splits) s_prev = self.seq1(s_next).to('cuda:1') ret = [] for s_next in splits: # A. s_prev는 두 번째 GPU에서 실행됩니다. s_prev = self.seq2(s_prev) ret.append(self.fc(s_prev.view(s_prev.size(0), -1))) # B. s_next는 A.와 동시에 진행되면서 첫 번째 GPU에서 실행됩니다. s_prev = self.seq1(s_next).to('cuda:1') s_prev = self.seq2(s_prev) ret.append(self.fc(s_prev.view(s_prev.size(0), -1))) return torch.cat(ret) 아래의 그림에서 2장의 레이어 사이에 교차하는 부분이 병렬 GPU간의 교차 통신이다 Model 병렬화는 꽤 예전 논문인 AlexNet에서도 사용되고 있었다 7.2 Data 병렬화 데이터를 나눠서 GPU에 할당한 후 결과의 평균을 취하는 방법 각 데이터에 대한 연산을 여러 GPU에서 동시에 수행해서 학습의 효율을 높인다 합칠때 pytorch에서는 두 가지 방식을 제공한다 DataParallel : 단순하게 데이터를 분배한 뒤 평균을 취하는 방식 Distributed DataParallel : GPU에서 모든 연산이 끝난뒤에 결과만을 공유하는 방식 DataParallel: 단순하게 GPU에 데이터를 분배한 뒤 평균을 취하는 방식 연산이 끝난뒤에 하나의 GPU에 loss값을 모아서 gradient를 만들고 이것들 다시 다른 GPU에 전달을 해준다 하나의 GPU가 특별하게 자원을 많이 사용하는 문제가 발생할 수 있다 합쳐진 loss연산을 GPU는 더 많은 메모리를 사용하기 때문에 Batch사이즈의 감소등의 방법으로 메모리 부하를 줄여야 할 수도 있다 매우 간단하게 pytorch에서 구현 할 수 있다1parallel_model = torch.nn.DataParallel(model) # 나머지는 일반 모델과 동일 Distributed DataParallel: GPU에서 모든 연산이 끝난뒤에 결과만을 공유하는 방식 Loss, Backward 계산 모두 각각의 GPU에서 이루어지며 연산이 완전히 끝나고 평균값이 결과로 출력된다 개별 GPU마다 CPU에서 프로세스를 생성해서 할당한다 (Multiprocessing) DataParallel과는 다르게 DataLoader에서 Shuffle 대신에 DistributeSampler를 사용하고, pin_memory를 활성화 시킨다 reference Naver Connect Boostcamp - ai tech Alexnet 논문 - ImageNet Classification with Deep Convolutional Neural Networks Pytorch 공식 모델 병렬화 Tutorial Pytorch Distributed Data Parallel Tutorial","link":"/2022/01/27/boostcamp/week/week2/pytorch-8/"},{"title":"부스트 캠프 ai tech 2주 4일차 Pytorch (7)","text":"8. Hyperparameter Tuning Hyperparameter 란? Learning Rate, Model의 inputsize, optimizer, loss function, batchsize 등의 모델이 스스로 학습하지 않는 값을 말한다 이 Hyperparameter를 조절하여 성능을 올리는 방법을 Hyperparameter Tuning이라고 부른다 생각보다 스펙타클하게 성능이 좋아지지는 않는다 8.1 Gradient Search parameter에 따른 기울기값을 계산한뒤 큰값을 내는(빠르게 학습이 가능한) parameter를 찾는 기법 보통 Learning rate를 찾는데 사용하는 기법이다 특정 간격마다의 값으로 검색하는 Grid Layout과 랜덤한 값으로 검색하는 Random Layout 등 여러가지 방법이 존재한다 최근에는 베이지안 기반의 기법들이 주도하고 있다 BOHB(Baysian Optimizer Hyperband) 8.2 Ray 라이브러리 ML과 DL의 병렬 처리를 위해 개발된 모듈이다 Hyperparameter Search를 위한 다양한 모듈을 제공한다 ML과 DL을 위해 개발되긴 했는데 분산처리(Multiprocessing)코드를 단순하고, 범용적으로 작성할 수 있게 도와준다 병렬처리 양식으로 학습을 시행해서 성능이 좋지않은 process들을 제외해 가면서 최적의 hyperparameter를 찾는다 아래쪽의 참고 문서를 보는것을 추천한다 reference Naver Connect Boostcamp - ai tech Baysian Optimizer Hyperband BOHB: Robust and Efficient Hyperparameter Optimization at Scale Ray - github Python Ray 사용법 - Python 병렬처리, 분산처리 HYPERPARAMETER TUNING WITH RAY TUNE","link":"/2022/01/27/boostcamp/week/week2/pytorch-9/"},{"title":"부스트 캠프 ai tech 3주 1일차 Data 시각화 (1)","text":"1. Data의 종류 Dataset은 아래와 같이 분류가 가능하다. 정형 데이터 시계열 데이터 지리 데이터 관계형 데이터 계층적 데이터 데이터는 아래와 같이 분류가 가능하다. 수치형 데이터(numerical) : 수치로 표현된 데이터 연속형(continuous) : 길이, 무게, 온도 등 이산형(discrete) : 사람 수, 주사위 눈금 등 범주형(categorical) : 문자로 표현되는 데이터 명목형(norminal) : 혈액형, 종교, 주소 등 순서형(ordinal) : 학년, 등급, 성적 등 1. 정형 데이터 가장 기본적인 데이터 형태 테이블 형태로 제공되는 데이터이다. 2. 시계열 데이터 시간에 흐름에 따른 데이터 기온 주가 등의 정형 데이터로 표현한 데이터와 음성, 비디오와 같이 비정형인 데이터가 존재한다. 3. 지리/지도 데이터 지형과 지명이 들어가 있는 데이터 위도와 경도를 이용해서 정형데이터로도 표현이 가능하다. 지도 정보와 보고자하는 정보간의 조화를 잘 맞추어 주는것이 중요하다 4. 관계형 데이터 객체와 객체간의 관계를 시각화 할 수 있는 데이터 객체는 Node로, 관계는 Link로 표현이 가능하다 크기와 색, 수 등으로 관계의 가중치를 표현 가능하다 보기쉽게 하기위해 휴리스틱하게 노드의 배치를 구성할 수 있다 5. 계층적 데이터 위의 관예형 데이터중에서 포함관계가 분명한 데이터 Tree, Treemap등의 형태의 데이터가 포함된다 2. 시각화 수치와 문제로 이루어진 데이터를 점,선,면을 이용해서 한눈에 보기 쉽게 만들어준다 아래의 속성들을 적절하게 사용해서 시각적으로 분리를 일으켜서 주의 깊게 보지 않아도 한눈에 알아볼수 있도록 하는것이 목표이다 너무 많이 사용하면 오히려 인지하기 힘든 부작용이 나타난다 reference Naver Connect Boostcamp - ai tech","link":"/2022/02/03/boostcamp/week/week3/Data-Viz-1/"},{"title":"부스트 캠프 ai tech 3주 1일차 Data 시각화 (2)","text":"3. matplot.pyplot 기초 이 글에서는 python 시각화 라이브러리 matplot에 대해서 다루어 본다 기본적으로 가장 많이 사용하는 matplot.pyplot을 이용하여 그래프를 그린다. 들어가기전에 보통 아래와 같이 많이 pyplot을 plt로 선언 한다 12import numpy as npimport matplotlib.pyplot as plt Figure &amp; Axes plt.figure로 그래프틀을 선언하고, plt.show()를 이용하여 화면에 나타낼 수 있다. num : figure의 id를 지정한다. 이미 지정한 id가 존재하고 그것이 다시 정의될 경우에 원래 존재하던 figure를 반환한다 figsize : 그래프틀의 크기를 지정한다 dpi : 해상도를 설정한다 facecolor : 배경화면의 색을 지정한다 edgecolor : 가장자리 라인의 색을 지정한다 12345fig = plt.figure(num=None, figsize=None, dpi=None, facecolor=None, edgecolor=None)plt.show()==========output&lt;Figure size 432x288 with 0 Axes&gt; 위의 코드에 Axes라는 subplot을 추가해야지만 제대로 그래프가 나온다 figure의 add_subplot()을 이용하여 Axes를 지정할 수 있다 123fig = plt.figure()ax = fig.add_subplot()plt.show() subplot Axes에 추가적인 Argument 입력을 통해서 위치를 지정해 줄 수 있다. suplots를 이용하여 fig와 Axes들을 동시에 정의 할 수도 있다. 1234fig = plt.figure()ax1 = fig.add_subplot(1, 2, 1)ax2 = fig.add_subplot(1, 2, 2)plt.show() plot plot을 통해서 그래프를 그릴 수 있다. x축과 y축의 수치가 1대1 대응으로 그래프가 그려진다. figure, subplot에 plot을 통해 입력이 가능하다 여러번 plot을 할 경우 여러개의 그래프가 그려진다 직접 색을 입력해서 그래프의 색상을 지정 할 수 있다 x : x축이 될 데이터들 y : y축이 될 데이터들 12345fig = plt.figure()ax1 = fig.add_subplot(1, 1, 1)ax1.plot([1, 2], [1, 3], color = 'forestgreen')ax1.plot([2, 3], [3, 1], color = 'r')plt.show() text label : 그래프에 label을 붙일 수 있다. 단 label을 표시하기 위해서는 legend()를 이용해야 한다. 123456fig = plt.figure()ax1 = fig.add_subplot(1, 1, 1)ax1.plot([1, 2], [1, 3], color = 'forestgreen', label = '1')ax1.plot([2, 3], [3, 1], color = 'r', label = '2')ax1.legend() # 이게 없으면 label 표시가 나오지 않음plt.show() 여러 메소드를 이용하여 그래프의 특정부분을 변경 시킬 수 있다. set_title : title을 지정할 수 있다. set_xticks : x축의 범주값을 지정할 수 있다. set_ticklabels : x축을 텍스트 값으로 지정할 수 있다. annotate : 그래프에 여러가지를 추가 할 수 있다. 여러 메소드의 자세한 내용들은 추후에 다룰 예정이다. reference Naver Connect Boostcamp - ai tech","link":"/2022/02/03/boostcamp/week/week3/Data-Viz-2/"},{"title":"부스트 캠프 ai tech 3주 1일차 Data 시각화 (4)","text":"Lineplot 연속적으로 변화하는 값을 점으로 나타내고 선으로 연결한 그래프 1. 기본적인 Lineplot .plot()으로 그래프를 그릴 수 있다 5개 이하의 선을 사용하는것이 가독성이 좋다 색상, 마커, 선의 종류 등으로 선을 구분해서 가독성을 더 끌어 올릴 수 있다. color : 색상 지정 marker : 점의 모양 지정 linestyle : 선의 종류 지정(solid, dashed, dashdot, dotted, None) 흐름의 파악을 원할하게 하기 위해 smoothing을 사용해서 Noise를 줄인다 2. Lineplot의 특징1. 흐름에 집중하는 그래프 데이터의 흐름을 보기위한 그래프이다 그렇기에 bar와 다르게 축을 0에 맞출 필요는 없다 너무 구체적인 정보는 오히려 흐름을 보는데 방해 될 수 있다 Grid, Annotate등을 최소한으로 사용한다 디테일한 정보는 따로 표로 제공하는것도 좋다 생략되지 않는 선에서 범위를 조절해서 표현한다 .set_ylim()을 이용하자 2. 간격 축의 간격이 다를경우 기울기 정보에서 오해를 일으킬 수 있다. 또한 점과 점 사이를 선으로 연결한 것이기 때문에 실제로 데이터가 없는부분에서 있다고 오해가 가능하다 수치형 데이터일 경우 matplot에서 알아서 맞추어준다 데이터의 위치에 mark를 해서 오해를 줄일 수 있다 3. 보간 점과 점사이를 실제 데이터가 없지만 이어서 선으로 만드는 방법 데이터의 error나 Noise가 포함되어 있을경우 보간을 사용해서 어느정도 보정해 이해를 도울 수 있다. scipy모듈을 이용하여 사용 데이터를 분석할 경우 미세한 차이를 놓치거나, 없는데이터를 있다고 생각하게 할수 있기때문에 EDA에서는 지양하는것이 좋다. 4. 이중 축 사용 한 plot에 대해서 2개의 축을 사용하는 방법 같은 시간축에서 서로다른 데이터를 표현하기 위해서 쓴다. .twinx()를 사용해서 구현한다 보통 한 데이터에 대한 다른단위 표현을 위해 사용한다 .secondary_xaxis(), .secondary_yaxis()를 사용한다 두 데이터에 대해서 이중 축을 사용하는것은 강제로 상관관계를 부여할 수 있으니 지양하고 2개의 plot을 사용하는쪽이 좀 더 가독성 면에서도 좋다 5.그 외 팁 라인 끝에 label을 추가하면 식별에 도움이 된다 주요 포인트에는 annotation을 추가하면 도움이 될 수도 있다 연한색으로 uncerainty 표현이 가능하다 reference Naver Connect Boostcamp - ai tech","link":"/2022/02/04/boostcamp/week/week3/data-viz-4/"},{"title":"부스트 캠프 ai tech 3주 1일차 Data 시각화 (3)","text":"Barplot 직사각형의 막대를 사용하여 데이터를 표현하는 그래프 category에 따른 수치값을 비교하기에 적합하다 1. 기본적인 Barplot barplot은 기본적으로 bar, barh가 존재한다. bar는 수직, barh는 수평으로 막대를 그린다 123456fig, ax = plt.subplots(1, 2, figsize=(12, 7))x = list('ABCDE')y = np.array([1, 2, 3, 4, 5])ax[0].bar(x, y)ax[1].barh(x, y)plt.show() 2. 다양한 Barplot 기법 다양한 barplot에 대해서 이야기를 할 예정이다 사용하는 데이터는 Boostcamp에서 제공한 데이터를 사용하였다 Multiple plot을 여러개 그리는 방법이다. subplots의 sharey를 이용하여 y축의 범위를 공유할 수 있다. 각 group의 분포를 알기 좋지만 group간 비교하기에는 쉽지 않다 1234fig, ax = plt.subplots(1, 2, figsize=(12, 6), sharey=True)ax[0].bar(group['male'].index, group['male'], color='royalblue')ax[1].bar(group['female'].index, group['female'], color='tomato')plt.show() Stack 2개 이상의 그룹을 쌓아서 표현하는 방식이다 맨 밑 group의 분포는 파악하기 쉽지만 그외는 파악하기 힘들다 bottom : bar의 시작 y좌표를 설정 할 수 있다. 12345678fig, axes = plt.subplots(1, 2, figsize=(15, 7))group_cnt = student['race/ethnicity'].value_counts().sort_index()axes[0].bar(group_cnt.index, group_cnt, color='darkgray')axes[1].bar(group['male'].index, group['male'], color='royalblue')axes[1].bar(group['female'].index, group['female'], bottom=group['male'], color='tomato') # 각 category의 y축 시작지점을 group['male']의 수치로 지정한다for ax in axes: ax.set_ylim(0, 350)plt.show() Percentage Stack Stack을 응용하여 만든 BarPlot bal_label을 이용하여 중간에 퍼센트를 찍어주었다 12345678910111213141516fig, ax = plt.subplots(1, 1, figsize=(12, 7))group = group.sort_index(ascending=False) # 역순 정렬total=group['male']+group['female'] # 각 그룹별 합for name, color in zip(['male', 'female'], ['royalblue', 'tomato']): rects = ax.barh(group[name].index, group[name]/total, left=group['male']/total if name == 'female' else 0, color=color) ax.bar_label(rects, fmt='%.2g', label_type='center')ax.set_xlim(0, 1)for s in ['top', 'bottom', 'left', 'right']: ax.spines[s].set_visible(False)plt.show() Overlap 2개의 그룹만 비교할때 사용하기 좋은 방식 3개 이상은 파악이 어렵다 같은 축을 사용하기 때문에 비교하기 쉽다 Bar보다는 Area에서 더 효과적이다 1234567891011group = group.sort_index()fig, axes = plt.subplots(1, 1, figsize=(8, 6))axes.bar(group['male'].index, group['male'], color='royalblue', alpha=0.7)axes.bar(group['female'].index, group['female'], color='tomato', alpha=0.7)ax.set_ylim(0, 200)plt.show() Group 그룹별 범주에 따른 막대를 이웃되게 배치하는 방법 Matplotlib로는 구현이 까다롭다 그룹이 5~7개 이하일때 효과적이다 많으면 오히려 역효과가 난다 시각화시 주의해야할점 실제값과 그래픽으로 표현되는 부분은 비례해야한다 반드시 x축의 시작은 0부터 한다 차이를 나타내고 싶다면 세로의 비율을 늘리자 정확한 정보를 전달하기 위해서 정렬을 하자 데이터의 종류에따라 여러 기준으로 정렬을 한다. 시계열 : 시간 수치형 : 크기 순서형 : 범주의 순서대로 명목형 : 범주의 값에 따라서 interactive로 제공하는 것이 유용하다 여백을 잘 조절하자 너무 꽉차있거나 비어있으면 가독성이 떨어진다. 적절한 조절로 가독성을 높이자 .set_xlim(), .set_ylim()으로 표시할 영역을 지정한다 .spines[pos].set_visible()을 이용해서 외곽선을 안보이게 조절한다 Gap, Margins을 이용해서 적절히 간격을 띄운다 복잡함을 줄이자 3D는 왠만해서는 쓰지말자… 축과 디테일을 조절하여 가독성과 깔끔함을 동시에 챙기자 text, annotate등을 이용하자 reference Naver Connect Boostcamp - ai tech","link":"/2022/02/03/boostcamp/week/week3/Data-Viz-3/"},{"title":"data-viz-5","text":"scatterplot 점을 통해서 그리는 그래프 상관관계를 확인하기위해 그리는 그래프 color, marker(모양), size으로 다양한 바리에이션을 주는것이 가능하다 scatterplot에서 확인해할 것 군집을 판단한다 값의 차이를 확인한다 빈공간을 데이터를 보고 어떻게 채울지 이상치를 파악하자 scatterplot을 통해서 이상치를 파악하고 처리할 수단을 생각한다 Overplotting 점이 많아져서 분포를 파악하기 힘들 상황 투명도 조절 jittering 점의 위치를 겹치지않게 변형 2차원 히스토그램 : 히트맵으로 변화시켜서 시각화 Countor plot : 등고선으로 표현 점의 요소와 인지 색 연속적인것은 gradient, 이산은 category color로 marker 구별하기가 힘들다 크기가 고르지 않다 색과 병행해서 사용하자 크기 버블차트 관계보다는 점간 비율에 초점을 두고 사용하자 오용하기 쉽기때문에 조심할것! 인과관계와 상관관계 인과관계와 상관관계를 구별해서 사용하자 상관관계가 보인다고해서 인과관계가 있는것이 아니다 항상 text를 추가해서 설명해주는것이 더 좋다 추세선 상관관계가 존재할 경우에는 추세선을 추가해서 정보를 더 제공할 수 있다. 대신 2개이상 사용하는것은 지양할것 그 외 Grid는 지양하는게 좀 더 깔끔한 시각화를 제공한다 Category data는 버블차트나 히트맵을 사용하는편이 좋다 reference Naver Connect Boostcamp - ai tech","link":"/2022/02/04/boostcamp/week/week3/data-viz-5/"},{"title":"부스트 캠프 ai tech 3주 2일차 Data 시각화 (6)","text":"Text 시각화에 적절한 Text는 시각적인것으로만 전달하기 힘든 설명을 추가하거나 잘못된 전달에서 생기는 오해를 방지 할 수 있다 하지만 과한 Text는 오히려 방해가 될 수 있으니 주의할 필요가 있다 1. Anatomy of a Figure Title : 그래프의 주제 Label : 축에 해당되는 데이터 정보 Tick Lable : 축의 grid의 스케일 정보 Legend : 한 그래프에서 여러개의 데이터 분류를 위한 보조 정보 Annotation : 그 외의 시각화를 위한 보조정보 1코드 추가 필요 2. Text Properties font Components family : 글씨체 size or fontsize : 사이즈 style or fontstyle : 스타일(기울임체 등등) weight or fontweight : 두께 matplot Docs Fonts Demo Detail color : 글씨의 색 linespacing : 줄간격 backgroundcolor : 배경색 alpha : 투명도 zorder : z축 순서 visible : 랜더 유무 정렬 ha : horizontal alignment va : vertical alignment rotation : 가로로 적을지 세로로 적을지 설정 multialignment : 추가적인 정렬 그 외 추가적인 항목 bbox설정을 통해 text에 box를 만들수 있다. Drawing fancy boxes reference Naver Connect Boostcamp - ai tech","link":"/2022/02/04/boostcamp/week/week3/data-viz-6/"},{"title":"부스트 캠프 ai tech 3주 2일차 Data 시각화 (7)","text":"color 시각화에서 색을 통해서 효과적으로 채널을 구분할 수 있다 심미적인 요소 또한 시각화의 일부 요소이다 전달하고 싶은 내용을 깔끔하게 색을 통해서 전달하는것이 주 목표이다 꼭 화려한것이 답은 아니다 Color Palette1. categorical color Discrete, Qualitative등의 다양한 이름으로 불린다 독립된 색상으로 구성되어 범주형 변수에 주로 사용된다 이산적인 개별값을 나타낼때 적합하다 2. Sequential color 정렬된 값을 가지는 연속형 변수에 적합나다 연속적인 색상을 사용하여 표현한다 어두운곳에서는 밝은색, 밝은 곳에서는 어두운색을 이용한다. 색상은 단일 색조로 표현하는것이 좋다. 대표적으로 github commit log의 색이 있다. 3. Divergence color 연속형과 유사하지만 중앙을 기준으로 서로 다른색으로 나타난다 상반된 값을 표현하는데 좋다(기온, 지지율 등) 그 외에 고려할 점 다름을 보이기 위한 Highlighting을 색으로 표현 할 수 있다. 보통 먼 색일수록 차이가 더 크게보이는 색상 대비를 사용한다. 색약이나 색맹을 가지는 읽는 사람을 위해 색 선택을 고려할 필요가 있다. reference Naver Connect Boostcamp - ai tech Sequential color","link":"/2022/02/04/boostcamp/week/week3/data-viz-7/"},{"title":"부스트 캠프 ai tech 3주 2일차 Data 시각화 (8)","text":"Facet 분할을 의미한다 화면상에 view를 분할하여 큰틀에서는 볼 수 없는 부분집합을 세세하게 보여줄 수 있다. 1. Figure &amp; Axes Figure는 그래프가 들어가는 큰 틀, Axes는 각 plot이 들어가는 공간을 말한다. Figure는 항상 1개, Axes는 여러개가 존재할 수 있다. 아래의 함수들로 N by M 의 Axes(subplot)들을 만들 수 있다. plt.subplot() plt.figure() + fig.add_subplot() plt.subplots() sharex, sharey를 통해 subplot끼리의 x축, y축의 범위를 통일 할 수 있다 squeeze를 False로 지정해서 subplot의 index를 n by m Matrix로 바꿀 수 있다. 기본으로 True이기 때문에 1차원 배열로 나오게 된다 aspect을 통해서 눈금간의 간격의 길이를 설정 할 수 있다 1234fig = plt.figure(figsize=(12, 5))ax1 = fig.add_subplot(121, aspect=1)ax2 = fig.add_subplot(122, aspect=0.5)plt.show() 2. Grid spec css의 그리드 처럼 동일 크기 분할이 아닌 다양한 크기의 그래프를 그리고 싶을때 사용하는 방식이다 add_subplot numpy의 slicing과 비슷하게 사용이 가능하다 1234567891011121314151617181920fig = plt.figure(figsize=(8, 5))gs = fig.add_gridspec(3, 3)ax = [None for _ in range(3)]ax[0] = fig.add_subplot(gs[0, :2]) ax[0].set_title('gs[0, :]')ax[1] = fig.add_subplot(gs[0:, -1])ax[1].set_title('gs[0, -1]')ax[2] = fig.add_subplot(gs[1:3, 0:2])ax[2].set_title('gs[-1, 0]')for ix in range(3): ax[ix].set_xticks([]) ax[ix].set_yticks([])plt.tight_layout()plt.show() subplot2grid((shape), (y, x), colspan = dx, rowspan = dy) shape를 통해 그리고자하는 grid를 설정 y, x : 시작하고자하는 좌표값 colspan, rawspan : 할당하고자 하는 가로 세로 길이 12345678910111213141516fig = plt.figure(figsize=(8, 5))ax = [None for _ in range(6)]ax[0] = plt.subplot2grid((3,4), (0,0), colspan=4)ax[1] = plt.subplot2grid((3,4), (1,0), colspan=2)ax[2] = plt.subplot2grid((3,4), (1,2), colspan=1)ax[3] = plt.subplot2grid((3,4), (1,3), colspan=1,rowspan=2)ax[4] = plt.subplot2grid((3,4), (2,0), colspan=3)for ix in range(5): ax[ix].set_title('ax[{}]'.format(ix)) # make ax title for distinguish:) ax[ix].set_xticks([]) # to remove x ticks ax[ix].set_yticks([]) # to remove y ticks fig.tight_layout()plt.show() 3. insert subplot 내부에 subplot을 생성하는 방법이다. ax.inset_axes() Ax 내부에 subplot을 추가하는 방법 메인 시각화를 해치지 않는 선에서 사용하자 123456789101112fig, ax = plt.subplots()color=['royalblue', 'tomato']ax.bar(['A', 'B'], [1, 2], color=color )ax.margins(0.2)axin = ax.inset_axes([0.8, 0.8, 0.2, 0.2])axin.pie([1, 2], colors=color, autopct='%1.0f%%')plt.show() make_axes_locatable(ax) Ax 사이드에 부가적인 정보를 주는 방법 보통 colorbar로 많이 사용한다 1234567891011fig, ax = plt.subplots(1, 1)# 이미지를 보여주는 시각화# 2D 배열을 색으로 보여줌im = ax.imshow(np.arange(100).reshape((10, 10)))divider = make_axes_locatable(ax)cax = divider.append_axes(&quot;right&quot;, size=&quot;5%&quot;, pad=0.05)fig.colorbar(im, cax=cax)plt.show() reference Naver Connect Boostcamp - ai tech","link":"/2022/02/04/boostcamp/week/week3/data-viz-8/"},{"title":"부스트 캠프 ai tech 3주 2일차 Data 시각화 (9)","text":"Grid 축과 평행한 선을 사용하여 거리 및 값 등을 보조적으로 알려준다 색은 최대한 방해하지 않도록 무채색을 사용한다 Layer상 항상 맨 아래 오도록 zorder를 0으로 조정 axis를 이용해서 x, y축 또는 동시에 격자를 보이게 할 수 있다 which 를 이용하여 큰격자, 세부격자 등을 보이게 할 수 있다 추가적인 보조 처리 보조선 긋기 axvline(), axhline()으로 수평선을 그을 수 있다 axvline(start, color, linestyle, zorder, alpha) start : 선을 그어질 point color : 색 linestyle : 선 스타일 zorder : z축 순서 alpha : 투명도 조절 1234567891011121314151617181920def drow_graph(x, y, d, function_name, y_lim, x_lim, minmax): fig, ax = plt.subplots(1, 2, figsize=(16, 4)) ax[0].plot(x, y) ax[0].set_title(f&quot;{function_name}&quot;) ax[1].plot(x, d) ax[1].set_title(f&quot;{function_name} (Derivative)&quot;) if minmax: ax[0].axhline(max(y), color=&quot;red&quot;, linestyle=&quot;--&quot;, zorder=1) ax[0].axhline(min(y), color=&quot;blue&quot;, linestyle=&quot;--&quot;, zorder=1) ax[1].axhline(max(d), color=&quot;red&quot;, linestyle=&quot;--&quot;, zorder=1, xmax=0.5) for i in range(2): ax[i].axvline(0, color=&quot;gray&quot;, linestyle=&quot;-&quot;, zorder=0) ax[i].axhline(0, color=&quot;gray&quot;, linestyle=&quot;-&quot;, zorder=0) ax[i].set_xlim(x_lim) ax[i].set_ylim(y_lim) ax[i].spines['top'].set_visible(False) ax[i].spines['right'].set_visible(False) 보조 면 추가하기 axvspan(), axhspan()으로 영역에 색을 칠할 수 있다 axvspan(start, color, linestyle, zorder, alpha) start : 시작 point end : 끝 지점 color : 색 linestyle : 경계 스타일 zorder : z축 순서 alpha : 투명도 조절 12345678910fig, ax = plt.subplots()ax.set_aspect(1)ax.axvspan(0,0.5, color='red')ax.axhspan(0,0.5, color='green')ax.set_xlim(-1, 1)ax.set_ylim(-1, 1)plt.show() reference Naver Connect Boostcamp - ai tech","link":"/2022/02/05/boostcamp/week/week3/data-viz-9/"},{"title":"부스트 캠프 ai tech 4주 1일차 DL Basic (1)","text":"Linear Neural Networks Data $(x_{i}, y_{i})^{N}_{i=1}$ 가 존재 할 때 $x$에 대해서 $\\hat{y}$ 연산하는 선형연산함수 $\\hat{y}=Wx + b$ $x$ : 데이터, $y$ : 라벨 경사하강법으로 y에 가까운 값을 계산하는 $W$와 $b$를 찾는다 Multi Layer Perceptron(MLP) 위의 Neural Network가 여러층에 걸쳐서 쌓여있는 형태 Layer 사이에 Non Linear transform을 한다 선형연산을 2번연속으로 하는것은 연산을 한번 하는 것과 똑같다 $W_{1}W_{2}x = W_{1,2}x$ NonLinear transform의 역활을 해주는것이 Activation Functions이다 최근에는 대부분 ReLU 계열의 Activation Function이 쓰인다 자주 쓰이는 Activation functions Target $y$와 출력물 $\\hat{y}$의 차이를 계산하는 loss function을 문제에 따라 잘 선택하여 사용하는 테크닉 또한 필요하다 그 외 내용 이론적으로 1개의 hidden layer로 대부분의 원하는 target값의 근사할 수 있다 라고 하지만 이것은 매우 어렵다 그만큼 Neural Network의 표현력이 좋다라는 뜻으로 받아드리는게 더 좋다. reference Naver Connect Boostcamp - ai tech","link":"/2022/02/07/boostcamp/week/week4/DL-basic-1/"},{"title":"부스트 캠프 ai tech 4주 1일차 DL Basic (2)","text":"들어가기 전에Generalization 이 모델이 얼마나 일반적인지를 나타내는 지표 보통 train loss와 test loss간의 차이를 말한다 Generalization Gap이 작을수록 일반적인 모델이라고 한다 Overfitting &amp; Underfitting Overfitting 과적합. 학습데이터에 대해서는 잘 예측하지만, test데이터에 대해서는 잘 예측하지 못하는 형태. Underfitting 학습데이터와 test데이터 둘 다 제대로 예측하지 못하는 형태. Cross Vaildation Cross vaildation train Data를 균등하게 나눠서 학습을 시켜 최적의 hyperparameter를 찾는 방법 Bias &amp; Variance Bias 편향 Variance 분산 Boostrapping 기법 Bootstrapping 통계학적으로 resampling을 통해 표본들의 추정치를 예측하는 기법 train dataset을 다시 sampling을 해서 만든 여러가지 data로 모델들을 학습시키는것을 Bootstrapping이라고 한다 Bagging Bootstrapping aggregating 여러 모델들을 bootstrapping을 통하여 학습시키고, 그 나온 결과값의 평균을 내는 방법 일반적으로 Ensemble 이라고 부른다 Boosting 여러개의 모델들을 학습시켜서 Sequential하게 이어 예측하는 방법 Gradient Descent Methods (Stochastic) gradient descent 하나의 데이터 샘플로 Gradient를 업데이트 하는 방식 Minibatch Gradient Descent 일부의 데이터 샘플로 Gradient를 업데이트 하는 방식 Batch Gradient Descent 전체의 데이터로 Gradient를 업데이트 하는 방식 데이터의 전체 크기가 커진 현재로써 Batch Gradient는 하드웨어 한계와 연산속도가 Minibatch에 비해 느려서 현재는 대부분 Minibatch 형식으로 학습을 진행한다 Batch Size large batch -&gt; sharp Minimum small batch -&gt; Flat minimun Optimization (Stochastic) Gradient descent 일반적인(확률적) 경사하강법 $\\gamma$ : learning rate $W$ : weight $g$ : gradient$$W_{t+1} \\leftarrow W_{t} - \\gamma g_{t}$$ Momentum 경사하강법에 관성을 부여한 방법 전에 이동한 정보를 조금 더해서 Gradient를 업데이트 하는 방법$$\\begin{aligned}a_{t+1} &amp;\\leftarrow \\beta a_{t} + g_{t}\\\\W_{t+1} &amp;\\leftarrow W_{t} - \\gamma a_{t+1}\\end{aligned}$$ Nesterov Accelerate Gradient Momentum과 비슷하지만 순서가 다르다 $a$ 방향으로 이동 한 뒤 위치에서 gradient를 계산 후 업데이트한다 Momentum 보다 minimum에 수렴하는 속도가 빠르다$$\\begin{aligned}a_{t+1} &amp;\\leftarrow \\beta a_{t} + \\nabla\\mathcal{L} (W_{t} - \\gamma g_{t})\\\\W_{t+1} &amp;\\leftarrow W_{t} - \\gamma a_{t+1}\\end{aligned}$$ Adagrad parameter의 변한 값에 대해서 영향을 받는다 $G_{t}$ : gradient 제곱합 적게 변한 parameter는 크게, 크게변한 parameter는 작게 변환한다 $G_{t}$ 가 계속 커지기 때문에 학습이 길어지면 잘 학습되지 않는다 $G_{t}$ 또한 계속 저장해야하기 때문에 학습이 길어지면 resource 소모가 크다$$W_{t+1} \\leftarrow W_{t} - \\frac{\\gamma}{\\sqrt{G_{t}+\\epsilon}} g_{t}$$ Adadelta Adagrad에서 $G_{t}$ 가 무한하게 커지는것을 방지한 학습법 Weight에 관여하는 Learning rate가 존재하지 않는다 hyperparameter가 적어서 잘 사용되지 않았다 $G_{t}$ : EMA of gradient squares $H_{t}$ : EMA of difference squares EMA : Exponential Moving Average 지수이동평균 $\\alpha$ : ema 가중치 $$\\begin{aligned}G_{t+1} &amp;\\leftarrow \\alpha G_{t} + (1-\\alpha) g^{2}_{t}\\\\W_{t+1} &amp;\\leftarrow W_{t} - \\frac{\\sqrt{H_{t-1}+\\epsilon}}{\\sqrt{G_{t}+\\epsilon}} g_{t}\\\\H_{t+1} &amp;\\leftarrow \\alpha H_{t} + (1-\\alpha)(\\Delta W_{t})^2\\end{aligned}$$ RMSprop EMA of gradient squares + Learning rate 해봤는데 잘되었다 $$\\begin{aligned}G_{t+1} &amp;\\leftarrow \\alpha G_{t} + (1-\\alpha) g^{2}_{t}\\\\W_{t+1} &amp;\\leftarrow W_{t} - \\frac{\\gamma}{\\sqrt{G_{t}+\\epsilon}} g_{t}\\end{aligned}$$ Adam RMSprop + Momentum 현재 가장 많이 쓰이고있는 계열의 optimizer AdamW, RAdam, AdamL등 여러가지 variation이 존재한다 $$\\begin{aligned}m_{t+1} &amp;\\leftarrow \\beta_{1} m_{t} + (1-\\beta_{1}) g_{t}\\\\v_{t+1} &amp;\\leftarrow \\beta_{2} m_{t} + (1-\\beta_{2}) v_{t}\\\\W_{t+1} &amp;\\leftarrow W_{t} - \\frac{\\gamma}{\\sqrt{v_{t}+\\epsilon}}\\frac{\\sqrt{1-\\beta^{t}_{2}}}{1-\\beta_{1}^{t}} g_{t}\\end{aligned}$$ Regularzation 일반화가 잘 되도록 데이터나 parameter에 규제를 하는 방법 Earlystopping overfitting을 방지하기 위해서 중간에 학습을 멈추는것 모델을 평가하기 위한 vaildation Dataset이 필요하다 Parameter norm penalty 파라미터가 일정이상 커지는것을 방지하는 기법 Data augmentation 데이터 수를 늘리기 위해 하는 기법 데이터에 종류에 따라 augmentation을 잘 선택해서 반영해야한다 Noise robustness 입력 데이터나, weight에 noise를 추가하는 기법 Label smoothing 데이터의 경계를 흐리게 하여 강건성을 높이는 방법 Mix-up 두 사진을 섞어서 섞은 비율만큼 다시 라벨링 하는 방법 Cutout 일부분을 잘라서 제거하는 방법 CutMix 일부분을 자른뒤 다른 label을 추가하는 방법 Dropout 랜덤하게 일부 Neural을 비활성화 하는 방법 Batch normalization 따로 포스팅 예정 reference Naver Connect Boostcamp - ai tech Bootstrapping Image Overfitting &amp; Underfitting Image On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima","link":"/2022/02/07/boostcamp/week/week4/DL-basic-2/"},{"title":"부스트 캠프 ai tech 4주 2일차 DL Basic (3)","text":"Convolution Neural Network (CNN) 시각적 데이터르 분석하는데 사용되는 인공신경망 CNN은 크게 Convolution Layer, Pooling Layer, (Fully Cunnect Layer)로 구성된다 Convolution layer 합성곱 연산이 진행되는 레이어 parameter의 수는 $kernel_size \\times Channel_in \\times Channel_out$으로 계산된다 이미지 처리를 할 시에 Fully Connected Layer보다 parameter 수가 월등하게 적다 실제 연산 이미지 input과 output의 크기는 아래와 같이 계산된다 input : $(N, C_{in}, H_{in}, W_{in})$ output : $(N, C_{out}, H_{out}, W_{out})$ stride : 연산이 이루어지는 간격 padding : 차원을 확장시켜 convolution 연산후에도 크기가 일정하게 유지되도록 한다 kernel : convolution 연산을 하는 주체, filter이기도 하다 N : batch size C : Channel 수 W : 연산될 Matrix의 가로 길이 H : 연산될 Matrix의 세로 길이 Pooling Layer 일정 범위안의 값들을 대표하는 하나의 값으로 압축하는 down sampling 기법 W와 H을 줄여서 차원을 축소하고, 연산에 필요한 parameter 수를 줄인다. 1x1 Convolution kernel size가 1,1인 convolution 연산을 하는것 input, output의 W, H는 일정하지만 channel수가 감소한다. WHY? channel 수를 줄여서 차원축소를 시키고, 추후에 연산에 필요한 parameter 수를 줄인다 $$H_{out} = \\left[ \\frac{H_{in} + 2 \\times \\operatorname{padding[0]} - \\operatorname{kernel_size[0]}}{\\operatorname{stride}[0]} +1 \\right]$$ $$W_{out} = \\left[ \\frac{W_{in} + 2 \\times \\operatorname{padding[1]} - \\operatorname{kernel_size[1]}}{\\operatorname{stride}[1]} +1 \\right]$$ reference Naver Connect Boostcamp - ai tech [By Aphex34 - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=45679374]","link":"/2022/02/08/boostcamp/week/week4/DL-basic-3/"},{"title":"부스트 캠프 ai tech 4주 1일차 DL Basic (4)","text":"AlexNet CNN으로 구성된 Network 시작부분에 11 x 11의 큰 convolution Layer를 사용했다 VGGNet 여러장의 3 x 3의 convolution Layer와 2 x 2 MaxPooling을 사용하였다 여러장의 3 x 3의 convolution Layer를 사용하면서 다음과 같은 advantage를 얻었다 큰 convolution Layer와 동일한 연산을 더 작은 Parameter로 수행할 수 있다 receptive field를 크게 유지할 수 있다 더 깊게 비선형적으로 Layer 추가가 가능해 진다 GoogLeNet 1 x 1, 3 x 3, 5 x 5, maxpooling을 이용하여 inception module을 구성하였다 1 x 1 convolution Layer를 이용해서 Channel 수를 줄여주었다 Layer가 깊어지면서 Gradient Vanashing이 일어나는것을 막기위해 Auxiliary classifier를 두어서 추가적으로 Gradient를 더해주었다 inference시에는 사용되지 않는다 ResNet Skip Conncetion을 두어 Gradient Vanashing을 해결하여 더 많게 레이어를 쌓은 모델이다 VGGnet의 3x3을 차용하여 파라미터 수를 크게 늘리지 않으면서 레이어를 더 쌓았다 channel이 변하는 구간에서는 DownSampling을 통하여 channel과 Height, weight를 맞춰주었다 reference Naver Connect Boostcamp - ai tech","link":"/2022/02/08/boostcamp/week/week4/DL-basic-4/"},{"title":"부스트 캠프 ai tech 4주 3일차 DL Basic (5)","text":"Fully Convolutional Network CNN에서 마지막을 담당하던 Dense Layer를 Dense Layer Feature와 동일한 Channel수를 가진 Convolution Layer로 대체한 Network Dense Layer는 reshape을 통해서 input을 집어넣기 때문에 정해진 input size가 필요 했지만, convolution Layer의 경우 channel 이외에는 가변적이기 때문에 이미지의 크기와 상관없이 연산이 가능해졌다 연산을 할 때 마다 차원이 축소되는 문제가 있다 -&gt; upsampling기법을 사용 conv transpose -&gt; checker board unpooling Object DetectionR-CNN 계열 R-CNN Selective Search 로 BBox 2000개정도를 추출 한 뒤 각각 CNN을 돌린다 CNN 연산이 2000번 반복되기 때문에 매우 느린 속도이다 fast R-CNN SPP Net을 이용하여 기존 2000번 반복된 연산을 1번으로 줄임 Faster R-CNN Selective Search를 Region Proposal Network로 바꾼 R-CNN Region Proposal Network : BBox도 네트워크 학습으로 뽑아내자 기존에 존재하는 anchor Box(샘플한 여러 크기의 Bbox)와 이미지를 비교하여 물체가 있을법한 장소를 탐색하고, 대략적인 Bbox위치를 특정한다 Yolo BBox와 Classfication이 동시에 이루어지는 1 stage 모델 R-CNN 계열에 비해서 속도가 매우 빠르지만, 정확도는 조금 떨어진다 실시간 물체검출이나 추적에 용이한 모델이다 reference Naver Connect Boostcamp - ai tech","link":"/2022/02/08/boostcamp/week/week4/DL-basic-5/"},{"title":"부스트 캠프 ai tech 4주 3일차 DL Basic (6)","text":"Sequential ModelNaive sequeance model 과거 모든시점의 데이터를 고려해야한다 시퀸스가 진행될 수록 고려해야할 데이터 양이 늘어남 Autoregressive model 특정 과거 시점 이후의 데이터만 고려한다Markov model Markov Chain role에 의하여 바로 전 state가 이전시점의 모든 데이터를 가지고 있다고 가정한다 위의 이유로 바로 전 시점의 데이터만 고려함 강화학습에서 많이 사용하는데 현실에 직접 적용하기에는 버려지는 정보량이 너무 많다 Latent autoregressive model 과거의 모든 정보들을 요약한 hidden state를 사용한다 hidden state가 어떻게 정의되느냐에 따라서 모델간 많은 차이가 존재한다 RNN도 Latent autoregressive model라고 볼 수 있다 Recurrent Neural Network (RNN) 자기참조로 학습하는 네트워크 short-term dependencies 먼 과거의 정보(Long-term)는 고려하기 힘들다 자기참조로 인한 연산이 계속되면서 gradient vanishing(sigmoid, tanh)이나 exploring(ReLU 계열)이 발생한다 Long Short Term Memory 먼 과거의 정보를 고려하기위해 고안된 RNN 기존에 존재하는 Hidden state에 내부에서만 연산되는 Cell State를 추가하여 먼 과거의 정보 또한 잘 기억할 수 있다 $x$ : data $C$ : Cell state $h$ : hidden state $\\sigma$ : sigmoid function $tanh$ : hyperbolic tan function Cell state 먼 과거의 정보까지 요약해서 가지고 있다가 Hidden state에 넘겨주는 역할 과거의 정보가 희석되는것을 막는 Resnet의 Skip Connection과 비슷한 역할을 한다 Cell state는 다음과 같은 과정으로 업데이트 된다 $t-1$시점의 Hidden state가 Forget Gate를 통과 Forget Gate : 중요하지 않은 정보들을 없애는 Gate$$f_{t} = \\sigma(W_{f}\\cdot[h_{t-1}, x_{t}] + b_f)$$ $t-1$시점의 Hidden state가 Input Gate를 통과 Input Gate : Cell state에 저장해야하는 정보들을 결정하는 Gate$$\\begin{aligned}i_{t} &amp;= \\sigma(W_{i}\\centerdot [h_{t-1}, x_{t}] + b_{f})\\\\\\tilde{C_{t}} &amp;= tanh(W_{C}\\cdot [h_{t-1}, x_{t} ]+b_{C})\\end{aligned}$$ $t-1$시점의 Cell state와 Gate를 통해서 나온 값들의 연산으로 Cell state를 업데이트 한다$$C_{t} = f_{t} * C_{t-1} + i_{t}*\\tilde{C_{t}}$$ Hidden state 기존의 RNN에 Hidden state와 동일한 역할 아래의 Output Gate에 Cell state와 Hidden state의 연산으로 업데이트 된다 Output Gate$$o_t = \\sigma(W_o [h_{t-1}, x_t] + b_i)\\\\h_t = o_t * tanh(C_t)$$ Gated Recurrent Unit (GRU) LSTM과 비슷한 형태 2개의 Gate(reset Gate, update Gate)가 존재하고 Cell state가 없다 LSTM보다 더 적은 parameter를 가진다 reference Naver Connect Boostcamp - ai tech colah.github.io - RNN image","link":"/2022/02/08/boostcamp/week/week4/DL-basic-6/"},{"title":"부스트 캠프 ai tech 4주 4일차 DL Basic (8)","text":"Generative Model 생성모델은 아래와 같은 특징을 가진다 Generatation 기존의 데이터 확률분포 $p(x)$ 에 속하는 $x_new$를 만들어 낸다 Density estimation data $x$가 기존의 데이터와 비슷하면 확률분포 $p(x)$상에 존재할 가능성이 높다. anomaly detection 이상치 탐지 설명 가능한 모델 등이 있다 Variaty Autoencoder Latent Space로 부터 데이터를 생성해내는 모델을 말한다 Encoder와 Decoder 2부분으로 이루어져 있다 Encoder에서는 기존의 Dataset으로 부터 Latent Space를 생성한다 $x \\rightarrow p(x)$ Decoder는 Latent Space로부터 역으로 Data를 생성한다 $p(x) \\rightarrow x$ 그래서 Encoder에서는 Dataset으로 Latent Space의 확률분포를 근사하고 $q_\\phi$(z|x) Decoder에서는 Latent Space에서 기존 Dataset의 확률분포로 이동을 시켜준다 $p_\\theta(x)$ 하지만 위의 확률분포는 우리가 알 방법이 없다 그래서 이것을 근사하기 위해 VAE에서 사용된 2가지 기법에 대해서 간략하게 설명한다 Variaty Inference $q_\\phi(z|x)$와 $p_\\theta(z|x)$의 차이($D_{KL}$)를 줄이는것이 궁극적인 목표이다 하지만 $p_\\theta(z|x)$은 우리가 알 수가 없다 그래서 Maximum Likehood를 변형시켜서 학습에 이용한다 $\\mathcal{L}(\\theta, \\phi ; x)$ : Evidence Lower Bound (ELBO)$$\\begin{aligned}log(p_\\theta (x)) &amp;= \\int_z q_\\phi(z|x)log(p_\\theta(x))\\\\&amp;= \\mathcal{L}(\\theta, \\phi ; x) + D_{KL}(q_\\phi(z|x)||p_\\theta(z|x))\\end{aligned}$$ $D_{KL}$는 항상 1보다 크기때문에 위의 식은 다음과 같이 나타낼 수 있다. $$log(p_\\theta (x)) \\geq \\mathcal{L}(\\theta, \\phi ; x)$$ 여기서 ELBO를 크게 하는 쪽으로 학습을 하게되면 $D_{KL}$은 줄어들게 된다. Reparametrization Trick 학습과정 중간에 Sampling이 들어가서 미분이 되지 않는것을 해결하기 위한 Trick sampling 한 값 $z$가 $\\mu_q + \\sigma_q \\cdot \\epsilon$ 과 같다고 생각하고 기존에 없던 $z$에 대해서 미분이 가능하게 바꾸었다. reference Naver Connect Boostcamp - ai tech PR-[010] : Auto-Encoding variational Bayes ICLR 2014 VARIATIONAL-AUTOENCODER와 ELBO(EVIDENCE LOWER BOUND)","link":"/2022/02/09/boostcamp/week/week4/DL-basic-8/"},{"title":"부스트 캠프 ai tech 4주 5일차 DL Basic (9)","text":"GAN 적대적 생성모델 노이즈로부터 데이터를 생성하는 Generator와 데이터가 진짜 데이터인지 생성된 데이터인지를 판단하는 Discriminator 2개의 구조로 이루어져 있다 Generator와 Discriminator는 서로의 Loss값을 최대로 하는 방향으로 학습을 하려 한다 Generator는 Discriminator의 판단한 결과로 실제 데이터와 유사하게 학습하는 방향으로 학습한다 Discriminator는 이진분류기로 실제데이터와 생성데이터를 분류한다 GAN을 아래와 같이 표현이 가능하다.$$min_G, max_D, V(D,G) = \\mathbf{E}{x\\sim p{data}(x)}[\\operatorname{log}D(x)] + \\mathbf{E}{z \\sim p{z}(z)}[\\operatorname{log}(1 - D(G(z)))]$$ GAN &amp; VAE VAE 학습이 안정적이다 결과물이 흐릿하게 나올 확률이 높다 학습 데이터에 있는 데이터와 비슷하게 나온다 새로운것을 만들어내지는 못함 GAN 학습이 불안전하다 출력물이 뚜렷한 편이다 새로운 분포를 만들 수 있다 최근에는 VAE또한 많이 발전해서 output이 GAN 이상의 것들을 보여준다reference Naver Connect Boostcamp - ai tech","link":"/2022/02/09/boostcamp/week/week4/DL-basic-9/"},{"title":"부스트 캠프 ai tech 4주차 Data 시각화 (13)","text":"Missingno 결측치를 시각화 해주는 라이브러리 빠르게 결측치의 분포를 확인할 때 사용가능하다 missingno library를 사용한다 plotly interactive한 시각화를 할때 사용하는 시각화 라이브러리 추가적으로 다룰 예정이다 Treemap같은 계층을 interactive 하게 보여줄때 사용한다 Waffle Chart pywaffle 와플형태로 discrete하게 값을 나타내는 차트 github commit형태 icon을 이용해서 표현을 할 수 있다 info graphic 에 유용하게 사용가능하다 Venn 집합으로 표현하는 시각화 pyvenn을 사용 EDA보다는 출판용으로 사용하는것이 좋다 가독성이 좋지 않다 reference Naver Connect Boostcamp - ai tech","link":"/2022/02/13/boostcamp/week/week4/data-viz-13/"},{"title":"AI 프로젝트 설계","text":"문제를 해결하기 위한 흐름 현상파악 목적 및 문제 정의 프로젝트 설계 Action 추가적인 원인 분석 1. 현상 파악 및 문제 정의 문제의 정의 특정 현상을 파악하고, 그 현상의 있는 문제를 정의하는 과정이 필요하다 풀고자 하는 문제를 명확하게 하는것이 중요하다 어느정도 현상파악이 끝나면 내렸던 문제의 정의를 좀더 구체적으로 만들어본다 문제 해결을 위한 대상을 정하기 목표에 대한 구체적인 정의 등 왜 그러한 일이 발생하는지 가설세우기 이 문제대해 어떠한 데이터가 존재하는가? 2. 프로젝트 설계 처음부터 최대한 자세하게 설계하자 머신러닝 문제 타당성 확인 항상 ML이 만능은 아니다 ML을 사용하면 좋은경우 학습가능한 패턴이 존재하는 문제 사람이 반복적으로 실행하는 task인 경우 -&gt; ML로 대체될 가능성이 높다 그리고 그 패턴이 복잡할 경우 간단한 문제면 Huristic한 알고리즘이 이것보다 몇배는 더 빠르다 간단하면 계산 코스트가 너무 커질 가능성이 높다 목적함수를 만들 수 없으면 ML의 의미가 없다 데이터 수집이 가능할 경우 : 데이터가 없으면 답이 없다 없으면 데이터 수집부터 진행해야한다…. Labeling 인종, 성향 등등의 윤리적인 제한에 자유로울 경우 프로젝트의 목표 및 지표 설정 목표 : 일반적인 목적, 큰 목적, 메인 Task 지표 : 목적을 달성하기 위한 세부 단계의 목표 제약조건 이 문제를 해결하기 위해 무한한 자금과 시간이 있는것이 아니다. 시간적인 문제 금전적인 문제 데이터가 민감한 정보들을 포함하고 있을 가능성도 존재한다 데이터 윤리적인 문제 Baseline, Prototype 제작 Metric Evaluation 3. Action 모델 개발 후 배포, 모니터링 과정 앞서 설계한 지표의 변화 파악하는 과정을 진행한다 4. 추가 원인분석 새롭게 발견한 상황들의 원인 분석 및 해결방안 설계 비즈니스 모델 BM 회사가 어떤 서비스 가치를 제공하고있는가? 비즈니스 모델 : 회사가 서비스를 제공하여 가치를 창출하는 방식 서비스의 핵심을 파악하자 어떠한 데이터를 가지고있는가 데이터로 무엇을 할수 있을까 reference Naver Connect Boostcamp - ai tech","link":"/2022/02/14/boostcamp/week/week5/ai-serving/"},{"title":"부스트 캠프 ai tech 4주차 Data 시각화 (14)","text":"Interactive Visualization정형 데이터의 단점 각각의 데이터마다 plot해주어야 하기때문에 Feature가 많으면 그만큼 plot수도 많아진다 상관관계가 존재할 경우에는 10 * 9 개의 plot이 필요하다 공간적인 낭비가 크다 이러한 단점을 Interactive한 시각화로 보안할 수 있다 Matplotlib 인터랙티브를 제공하지만 local에서만 가능 외부 라이브러리를 통해서 웹에도 서비스가 가능은 하다 기능또한 많지 않아서 의미가 크지 않다 Plotly 가장 많이 사용하는 Interactive 시각화 라이브러리 R이나 JavaScript같은 다른 언어도 지원한다 문서화가 잘되어있다 커스텀이 아쉽다 Bokeh Matplotlib와 비슷한 라이브러리 문서화가 부족하다 Altair 문법이 pythonic하지 않다 데이터 크기에 5000개의 제한이 있다 기본차트에 특화되어 있음 reference Naver Connect Boostcamp - ai tech","link":"/2022/02/16/boostcamp/week/week5/data-viz-14/"},{"title":"윈도우, Linux 그리고 Docker","text":"부스트 캠프를 진행하던 도중 질문게시판에 mlflow를 윈도우에서 돌렸는데 에러가 발생했다고 올라와서 궁금해서 조사하던 도중 알게된 사실과 추가적으로 궁금해서 찾아본 것들에 대해 정리해 보고자 한다 발생한 문제점 docker: Error response from daemon: invaild mode: 경로와 같은 에러가 발생하였다. 조사과정 평소 python에서 코딩을 할 경우에도 /와 \\를 혼용해서 사용하면 매우 쉽게 에러가 발생하는 모습을 보았기 때문에 Linux기반인 docker에서 windows 명령어를 사용해서 에러가 나는것이 아닐까 생각하였다 알게된 점 원인은 : symbol에 존재했다. 윈도우에서는 : symbol을 C:\\directory식으로 드라이브를 표기할 때 사용하지만, mount할때에는 : 를 연동할 대상의 구분자로 사용을 하기 때문이다 docker 에서 volumn mount를 시행할 시 입력되는 경로는 무조건 절대경로로 적어야한다. pwd로 입력해야한다고 doc에 나와있었다 해결 방법 C: 형태를 //C/directory 형태로 바꿔서 입력을 한다 기존 윈도우에서 사용하는 형태를 리눅스 커맨드 형태로 바꿔서 입력한다 어차피 docker 내부에서 작동할 커맨드이기 때문에 윈도우 커널에서도 잘 돌아간다 “”로 한번 감싸준다 “”로 싸주어서 전체 C:\\가 링크인것을 알려준다 결론 기본적으로 docker는 Linux 기반이기 때문에 windows로 사용할 경우 많은 제약이 당연하게도 뒤따른다 windows에서 Docker를 쓸 때는 WSL을 이용하자 reference Naver Connect Boostcamp - ai tech docker toolbox Docker Volume, Error response from daemon: invalid mode","link":"/2022/02/18/boostcamp/week/week5/docker-symbols/"},{"title":"Docker","text":"Docker 리눅스의 응용 프로그램들을 프로세스 격리 기술을 사용하여 컨테이너로 실행하고 관리하는 오픈 소스 프로젝트이다 도커는 아래와 같은 주요 구성 요소들이 존재한다 이미지 컨테이너 데몬Docker image 서비스 운영에서 필요한 프로그램, 소스코드, 각종 모듈, 컴파일된 실행파일을 묶는 형태를 말한다 간단히 말해서 프로세스를 실행하기 위해 필요한 모든 파일과 설정값을 저장하고 있어서 추가적으로 의존성 파일을 설치할 필요없는 상태이다 Image는 Layer로 이루어져 있다 image를 build할때 효율적으로 동작하기 위해 구현된 층을 Layer라고 한다 image는 여러개의 읽기전용 Layer로 구성되어 있다 다른 image를 받아와서 그위에 Layer를 쌓아 새로운 Image를 만드는것도 가능하다 아래의 명령어 한줄한줄이 Layer라고 생각해도 무방하다1234567FROM pytorch/pytorch:1.7.0-cuda11.0-cudnn8-runtimeRUN apt-get update -y...WORKDIR /appCOPY ./src /app/srcCOPY ./test /app/testENTRYPOINT python3 /app/src/run.py 이를 통해 컨테이너를 생성할 수 있다 Docker Container Image를 실행, 응용프로그램 자체를 격리된 공간에서 동작시키는 기술이다 Image를 통하여 여러대의 Container를 생성 할 수 있고, 이 Container들은 모두 동일한 개발환경을 가지게 된다 Docker의 장점 1 여러대의 분리된 서버를 모두 같은 환경으로 만들 수 있다 Image를 실행시키기만 하면 Image에 저장되어있던 모든 파일들과 환경변수등이 셋팅되기 때문에 설치가 매우 간편하다 장점 2 Docker Daemon Docker Container나 Image를 관리하는 Kernel user가 client를 통해서 보낸 명령을 받아서 Docker 객체들을 관리한다 하나의 커널로 여러 Container를 관리하기 때문에 가상환경에 비해 도커가 용량을 덜 차지하고, 더 빠른 속도를 가질 수 있다 reference Naver Connect Boostcamp - ai tech","link":"/2022/02/15/boostcamp/week/week5/docker/"},{"title":"Linux 커맨드","text":"Linux Command기본 커멘드 man [command] 쉘 커맨드의 매뉴얼 문서를 출력해준다 mkdir [name] name의 이름을 가진 directory를 생성한다 ls 현재 접근한 폴더의 폴더, 파일 확인 a: 현재 접근한 폴더의 전체 파일 출력(.으로 감춰진 폴더까지 전부) l: 권한, 소유자, 만든날짜, 용량까지 출력 h: 용량을 보기쉽게 GB, MB등으로 표현 pwd 현재 폴더의 경로를 절대경로로 표시 echo ‘text’: 터미널에 텍스트를 출력 “command”: 터미널에 커멘드의 출력한 결과를 출력해준다 sudo [command]: 슈퍼유저로 프로그램을 실행 clear 커멘트 창을 깨끗하게 해준다 history 최근에 입력한 쉘 커맨드 History 출력 !number 를 통해 커맨드 재활용 가능하다 export 환경변수를 지정할 수 있다. 커널을 종료하면 날아가니까 .bashrc 등에 적으면 영구적으로 사용가능하다 alias 기존 커맨드의 별칭을 지정할 수 있다 ex) alias ll2=’ls -l’ 파일 관리 관련 커맨드 cp [filename] [newfilename] Copy -r : directory 내부의 모든 파일도 같이 복사 -f : 강제로 복사 mv [filename] [newfilename] 파일 옮기기(혹은 이름바꾸기) cat [files] (&gt; or &gt;&gt; [filename]) 특정 파일 내용 출력 여러파일을 인자로 주면 합쳐서 출력 &gt; : 파일을 저장하고 overwrite &gt;&gt; : 파일에 추가하는 경우 head, tail [number] 파일 앞/뒤의 n행 출력 sort 말 그대로 sort uniq 중복되는 라인을 제거하는 명령어 c : 제거된 라인을 count한다 서버 관련 커맨드 ps 현재 실행되고 있는 프로세스 출력 curl 웹서버 작성 후 Request 테스트 하는 명령어 df 디스트 용량확인 -h로 가독성을 높임 scp chmod 파일의 권한을 변경하는 경우 사용한다 r 읽기권한 4 w 쓰기권한 2 x 실행권한 1 수를 합쳐서 표기하면 여러개의 권한을 나타낼 수 있다 reference Naver Connect Boostcamp - ai tech","link":"/2022/02/14/boostcamp/week/week5/linux-command/"},{"title":"부스트 캠프 ai tech 8주 1일차 CNN architectures","text":"Image Classifier 이미지를 분류하는 기본적인 모델을 말한다 충분한 데이터가 존재한다면 모든 분류문제는 K-Nearest Neighobors로 해결이 가능하다. 영상 분류 문제를 검색 문제로 바꿔서 해결이 가능하다 하지만 데이터는 너무 많고, 우리의 머신 리소스는 한정적이기 때문에 모든 문제를 해결하기에는 적합하지 않다 데이터 수에 비례해서 시간복잡도가 증가한다 초창기에는 single Fully Connected Layer를 이용해서 분류 문제를 해결하려 했다 레이어층이 적다보니 평균적인 이미지에서 벗어나면 잘 작동하지 않았다(test 성능이 좋지 않았다) 이미지를 전체적으로 보는것이 아닌 부분적으로 파라미터 연산을 하는 Locally Connected Layer가 등장하였고 Convolution Layer의 전신이 되었다 Data Augmentation 우리가 모델을 학습시킬때 사용하는 Data는 실제 전체 데이터에서 샘플링한 극히 일부의 데이터이다. 또한 데이터를 제작한 사람의 주관또한 들어가 있을 가능성이 존재하기 때문에 Train Data의 분포가 실제 데이터와 일치한다고 보기 힘들다. 이를 보안하기 위해서 Data의 분포를 다양하게 만드는 방법을 Data Augmentation이라고 한다. 기본적인 Augmentation 밝기, 채도, 명암 조절 Random Crop, Filp, Rotate Affine Transform : 기하학적 변환 warp로 시작하는 함수 특수한 Augmentation CutMix : 두개의 사진을 잘라서 합치는 Augmentation. 라벨값 또한 비율에 맞게 조절한다 MixUp : 두개의 사진을 Alpha값의 조절을 통한 픽셀을 합치는 Augmentation. 라벨값 또한 비율에 맞게 조절한다 Transfer Learning 기존에 학습시킨 네트워크를 이용하여 새로운 Task를 해결하는 모델에 재학습 시키는 방법 학습시키는 Dataset이 비슷한 분포를 가지고 있어야 더욱 잘 학습 된다. Layer Freeze 특정한 Layer의 Parameter를 Freeze시켜서 고정시키고 나머지 Layer로만 학습시키는 방법 데이터의 양이 적을때 효과가 좋다 Fine Tuning 새로 추가된 Layer의 Learning Rate와 기존 CNN 부분의 Learning Rate를 다르게(기존 부분을 더 작게) 설정하여 Tuning하는 방법 어느정도 데이터가 존재할때 효과가 좋다 Knowledge distillation Teacher Student Learning 큰 모델에서 학습한 weight를 작은 모델에도 비슷하게 작동하게 전달하는 기법 최적화방면에서도 많이 이용된다. reference Naver Connect Boostcamp - ai tech Mixup: BEYOND EMPIRICAL RISK","link":"/2022/03/07/boostcamp/week/week8/CNN-1/"},{"title":"부스트 캠프 ai tech 8주 3일차 Object Detection","text":"Object Detection 특정 오브젝트가 어디에 위치해있고, 그 오브젝트가 무엇인지를 탐지하는 Task를 말한다 Classification과 Box Localization을 같이 하는 Task 자율주행이나 OCR등에서 사용된다 Classification과 Box Localization을 따로 연산하는 Two Stage 방식과 동시에 연산하는 One Stage 방식이 존재한다 Two Stage Object Detection 이미지의 BBox를 추출하고 이 BBox로 Classification을 진행하는 모델을 말한다 R-CNN 계열의 모델이 여기에 속한다 2단계로 연산을 하기 때문에 연산속도는 느린편에 속하지만 정확도가 높다 Selective Search 이미지로부터 BBox를 만들어 내는 알고리즘 이미지의 색상단위로 Over Segmentation을 진행하고 규칙에 따라 점점 합쳐나가는 알고리즘 Color Similarity Texture Similarity Size Similarity Shape Similarity A final meta-similarity measure R-CNNClassification이 바로 Object Detection에 응용된 모델이다.모델은 아래와 같이 간단한 단계로 BBox를 구하고, Classification을 진행한다 Selective Search를 사용하여 물체가 있을 법한 후보를 선택한다(~2k) 선택된 후보군 전체에 대해서 이미지의 크기를 재가공하여 Classification 모델에 집어넣는다 (2000개의 후보들에 대해서 모두 CNN, SVM 연산) RCNN은 초기 모델인 만큼 다양한 문제점 또한 존재한다 BBox를 뽑아내는 알고리즘은 Seletive Search 같은 Huristic 알고리즘이기 때문에 학습이 불가능해서 성능향상이 크지 않다 Selective Search는 Cpu에서 연산이 이루어지기 때문에 시간도 많이 소요된다 후보 전체에 대하여 Classfication을 한번씩 진행하다보니 연산량이 많아져서 시간소모가 크다 Fast R-CNN기존의 R-CNN의 연산이 매우 오래걸린것을 해결한 모델이다.Roi Pooling을 이용하여 모든 후보에 대해서 Convolution Network 에 입력하던것을 단 1번으로 줄였다. Keyword RoI Pooling SPPNet RoI Pooling을 이용한 Fast R-CNN 전체 이미지를 CNN에 통과시켜서 Feature Map을 추출한다 Seletive Search등의 Region Proposal Method를 이용하여 RoI를 찾는다 찾은 RoI를 미리 뽑아둔 Feature Map에 투영하여 RoI에 해당하는 부분에 대해서 Pooling을 진행해서(SPPNet 이용) Classification을 위한 FC Layer의 input Size에 맞춘다 softmax연산을 통하여 Classification을 진행한다 Bounding Box Regression을 통하여 BBox의 위치를 재조정한다 R-CNN에서 RoI Pooling을 도입하여 연산속도면에서 획기적인 발전을 이룩한 모델이지만 여러 한계점이 존재했다 아직도 Seletive Search를 사용하기 때문에 BBox 검출에 대해서 큰 학습이 이루어지지 않았기 때문에 성능면에서는 큰 차이가 없다 모델 뒷부분의 성능은 개선되었지만 BBox 검출 속도는 그대로기 때문에 Bottleneck 현상이 발생한다 Faster R-CNNFast R-CNN의 단점이었던 Seletive Search를 Nueral Network(RPN)로 대체함으로써 End to End로 학습이 가능해진 모델이다 Keyword RPN NMS IoU (Intersection over Union) 두 BBox가 얼마나 잘 겹쳐있는지를 판단하는 Metric RPN Region Proposal Network R-CNN 계열에서 RoI를 생성하던 Region Proposal Method를 대체하는 Network이다.RPN에서는 다양한 모양의 BBox를 출력 해 내기 위해서 미리 특정 크기의 Anchor Box들을 구현해 놓고 이 Anchor Box들과 대조하여 IoU를 계산한다. Faster RCNN 에서는 3개의 Scale과 3개의 비율을 조합하여 9개의 Anchor Box를 미리 정해 두었다. RPN에서는 Slide Window 방식으로 Anchor Box를 이용하여 물체가 존재하는지에 대한 유무와 BBox의 delta 값을 Feature Map으로 부터 추출한다 Delta : 고정된 크기의 Anchor Box를 실제 BBox에 일치시키는 이동 정보를 담고있는 벡터를 말한다 결론적으로 RPN을 학습시키면 물체가 존재할 가능성이 높은 BBox를 도출하는 쪽으로 학습이 진행된다 RPN으로 부터 추출된 BBox 좌표를 기준으로 기존에 뽑아두었던 Feature Map에 RoI Pooling을 적용하고 Classification과 Box Regression을 진행한다 Non Maximum Suppression RPN으로 생성된 수많은 BBox중 중복되는 Box들을 지우는 알고리즘 동일한 클래스에 대해서 Sorting을 통해 Comfidence 순서로 정렬 시킨다 가장 Confidence가 높은 BBox와 IoU가 일정 이상인 BBox는 중복되었다고 판단하고 삭제한다 추가적인 사항 실제로 Faster RCNN을 학습시킬때는 RPN과 RCNN 모델을 따로 각각 학습을 시킨뒤에 붙였다고 한다 One Stage Object Detection 이미지의 BBox를 추출하면서 Classification까지 동시에 진행하는 모델을 말한다 1단계로 연산을 하기 때문에 실시간 처리속도가 높지만 정확도가 2 Stage Detector 보다 조금 떨어진다 YOLO One Stage Object Detection Model의 대표적인 모델 Faster RCNN과 유사하게 Anchor Box와 Box Regression을 통해서 BBox를 예측한다 Anchor Box의 위치를 찾는것과 동시에 Class Probability map을 생성한다 Class Probability map과 BBox를 합쳐서 detection을 마친다 초당 처리 프레임 수는 Faster RCNN을 앞섰지만, 성능면에서는 조금 떨어지는 경향을 보였다 Single Shot MultiBox Detector(SSD) YOLO의 정확도 문제가 개선된 One Stage 모델이다 아래의 그림과 같이 여러개의 Feature Map에서 Anchor를 이용하여 Feature를 추출한다 각 레이어마다 Anchor Box에 대한 정보들을 종합하여 최종적으로 NMS를 통해 겹치는 BBox를 제거하여 결과를 낸다 이를 통하여 Yolo와 비슷한 수준의 처리속도와 Faster RCNN을 넘는 성능을 보여주었다 RetinaNet Focal Loss와 FPN구조를 도입함으로써 One Stage Detector의 성능을 더욱 끌어올린 모델 구조 Keyword Focal Loss Feature Pyramid Network(FPN) Focal Loss One Stage Detector의 고질적인 문제인 적은 Positive Sample 문제를 해결하기 위해 고안된 Loss 함수이다 Positive Sample은 단 하나지만 Negative Sample은 엄청나게 많이 발생하기 때문에 Class imbalance 문제가 발생한다 Cross Entropy loss로 부터 고안된 Loss 함수 맞추기 쉬운 Sample에 대해서 발생하는 weight를 낮추고 맞추기 힘든 Sample에 대해서는 높은 weight를 주게 된다 loss값은 Focal loss가 작지만 같은 지점의 Gradient를 보면 Focal Loss가 훨씬 크다 Feature Pyramid Networks 서로다른 해상도의 Feature Map을 쌓아올린 형태를 가지는 CNN 모델이다 입력층에 가까울수록 Low Level의 Feature를 가지고, 출력층에 가까울수록 High Level(Global Level)의 Feature를 보유하는 CNN의 특성을 이용하였다 (a)는 다양한 Scale의 Feature 맵을 사용해서 다양한 크기의 Object를 탐색하는 것이 가능하고 성능도 좋다. 하지만 여러장의 이미지에서 모두 Feature Map을 추출해야하기 때문에 느린 처리속도를 가진다 기존의 Yolo는 단일 Scale의 Feature 맵을 사용하는 (b) 방식을 사용했다. 모델구조가 단순하여 빠른 처리가 가능하지만, 성능이 떨어지는 단점이 존재한다 SSD에서 사용한 방식인 (c)는 다양항 크기의 Feature Map을 사용하여 좋은 성능과 빠른 처리속도를 보여주었지만, Backbone을 지나서 충분하게 High Level 수준의 Feature들을 합쳐서 결과를 내기 때문에, 더 높은 해상도의 Low Level Feature Map(High Resolution map)을 사용 하지 않아 Small Object 검출에 한계가 있다고 논문에서 서술했다 FPN에서는 (d)의 구조를 통하여 Low Level 부터 High Level 까지의 Feature Map을 전부 사용하여 검출이 힘든 작은 물체 까지 잘 검출하는 모습을 보여주었다 reference Naver Connect Boostcamp - ai tech","link":"/2022/03/09/boostcamp/week/week8/CNN-3/"},{"title":"부스트 캠프 ai tech 8주 2일차 Sementic Segmantation","text":"Semantic segmentation 이미지의 픽셀단위로 Classification을 수행하는 Task 의료분야에서나 자율주행, 영상편집 등의 분야에서 다양하게 사용된다. Fully Convolutional Networks (FCN) KeyPoint : 기존 fully connected Layer(fc Layer)를 Convolutional Layer로 대체하면서 fc Layer의 문제점을 해결하고 Semantic Segmentation까지 end to end로 구현한 모델 기존의 Classification 모델들은 마지막 Layer를 fc Layer로 구성하기 때문에 고정된 input 이미지 사이즈를 가져야 했지만 1 x 1 Convolution Layer를 사용하면서 가변적인 input 이미지를 사용할 수 있게 되었다 맨 마지막 단에 Upsampling을 시행하여 해상도를 맞춰주어 Segmentation을 한다 Transposed Convolution 아래와 같은 특징을 골고루 가지기 위해 중간단계의 map을 Upsampling을 해서 가져와 더한다. 단계별 Map들이 합쳐지면서 더 좋은 Segmantaion 이 가능했다. Layer를 적게 거칠수록 이미지의 지역적이고 세부적인 부분에 집중한다 Layer를 많이 지나가면 이미지의 전체적인 부분에 집중한다 U Net FCN을 유사한 구조를 가진 Segmentation 모델 Feature를 추출하는 Contracting 과정과 Upsampling을 단계적으로 진행하는 Expanding 과정으로 나뉜다 Contracting Path 한번의 과정이 끝날 때 마다 Channel 수를 2배로 늘린다 기존의 FCN의 추출과정과 비슷하다 Expanding Path 해상도를 2배씩 늘리면서 점진적으로 Upsampling을 진행한다 반대로 Channel수는 절반으로 줄이면서 진행한다 Contracting 과정에서 대칭으로 대응되는 Layer에서 나온 Map과 Concatenating을 진행해서 Fusion 시킨다 주의할점 MaxPooling을 통해서 크기를 반으로 점진적으로 줄이고 다시 Upsampling을 통해 2배씩 늘려나가기 때문에 이미지 사이즈가 홀수일 경우 차원이 맞지않아 계산이 불가능하다 DeepLab 구글에서 2018년에 작성된 논문으로 그 당시 좋은 성능을 보여주었다 모델의 특징으로는 Dilated convolution와 Depthwise separable convolution를 이용하여 파라미터 수를 줄이면서 성능을 유지시켰다 본 글에서는 논문의 주된 특징인 Dilated convolution와 Depthwise separable convolution Layer에 대해서 다룬다 Dilated convolution Atrous Convolution 이라고도 한다 필터 내부에 빈 공간이 존재하는 Convolution Layer를 말한다 parameter r을 조절하여 내부의 빈 공간의 크기를 조절 할 수 있다 1일 경우 기본적인 Convolution Layer와 동일 동일한 양의 파라미터와 계산량을 유지하면서 한 픽셀이 볼 수 있는 영역을 크게 할 수 있다. 기존에 한 픽셀이 볼 수 있는 영역을 크게 하기위해서는 Kernel Size를 키워야 했는데 이는 필연적으로 파라미터와 계산량의 증가가 따라온다 이미지 데이터의 경우에는 한 픽셀 주위의 픽셀이 어느정도 연관이 되어있다고 가정할 수 있기 때문에 가능한 방식으로 생각된다 Depthwise separable convolution 기존 Convolution Layer의 연산을 2단계로 분리시켜서 사용되는 파라미터 수를 획기적으로 줄인 방법이다 Convolution Layer에서는 Channel축을 필터가 한번에 연산하지만, Depthwise separable convolution Layer에서는 Channel을 분리해서 1의 길이를 가지는 여러개의 Feature로 만들고 여기에 1 x 1 x 채널길의 크기의 필터를 다시한번 적용하여 연산을 하는 방식을 취한다 이를 통해서 기존 연산에서는 $H \\times W \\times C \\times n$ 개의 파라미터가 필요 했지만 Depthwise separable convolution 연산에서는 $H \\times W \\times C + C \\times n$ 개의 파라미터가 필요하게 되어 수를 더욱 줄일 수 있었다. reference Naver Connect Boostcamp - ai tech Fully Convolutional Networks for Semantic Segmentation https://github.com/vdumoulin/conv_arithmetic","link":"/2022/03/07/boostcamp/week/week8/CNN-2/"},{"title":"부스트 캠프 ai tech 8주 4일차 CNN visualization","text":"CNN visualization 의 필요성 기존 DeepLearning 모델은 내부를 볼 수 없는 시스템(Black Box)라고 여겨졌다 실제로는 내부 Parameter 값을 볼 수 있지만 weight들로 이루어진 Metrix만 존재하기 때문에 해석하기 힘들다 CNN visualization에서는 weight들을 시각화 해서 설명가능하게 만들어 준다 filter들을 시각화 함으로써 어떤방식으로 동작하는지 설명이 가능해진다 weight의 GradCAM을 통하여 어떤부분에 모델이 집중하는지 보여주면서 왜 잘 동작했는지, 동작하지 않았는지를 더 쉽게 설명이 가능하다 시각화된 결과를 기반으로 추가적인 성능 향상을 위한 가설을 세울 수 있다 CNN Visualization CNN Visualization에는 다양한 방법들이 존재한다 이 글에서는 Model behavior analysis와 Model Decision analysis부분에 대해서 다룬다 Model behavior analysis 모델 자체의 행동에 집중하여 분석하는 기법 Embedding feature analysisHigh Level의 Layer에서 얻어지는 Feature를 분석하는 기법이다 Nearest Neighbors in Feature Space Nearest Neighbors를 이용한 모델 시각화이다 Neural Networks를 이용하여 High Level의 Feature를 뽑고 이를 이용하여 DB를 생성한다 test Data를 Model에 넣어서 kNN으로 모델이 생성한 High dimensional Feature Space를 확인한다 예제를 보고 판단하기 때문에 전체적인 부분을 확인하기는 힘들다 t-SNE 위의 모델이 생성한 High demensional Feature Space를 Low dimensional Space로 변화시켜서 시각화하는 방법 Feature의 전체적인 그림을 그려주어서 Feature Space를 어느정도 이해할 수 있도록 도와주는 역할을 한다 Activation investigationMid ~ High Level Layer에서 이루어지는 Feature 분석 기법이다 Layer Activation mid to high level hidden unit의 행동을 파악해보는 기법 특정 Layer의 특정 Node를 가공하여 어느부분을 집중적으로 보는 node인지를 masking한다 Maximally activating patches Hidden Node 별로 가중치가 가장 높은 부분을 뜯는 기법 국부적인 부분에 적합하여 Mid Level Feature에서 사용한다 Class visualization 예제 데이터를 사용하지 않고 네트워크의 parameter로 이미지를 시각화 하는 방법 특정 class에 대한 네트워크의 예상치를 확인하는 방법이다 이것을 보고 주변객체와의 연관성 등도 파악이 가능하며 데이터의 편향성이 존재하는지도 파악 할 수 있다 특정 이미지를 넣어서 확인하는 것이 아닌 dummy 이미지를 넣어서 확인한다 Model Decision analysis 모델의 특정 입력에 대해서 경향에 집중하여 분석하는 기법 Occulsion map 특정 부분에 Occusion patch를 이용하여 가린 이미지들로 뽑은 Score바탕으로 heapmap을 구성하는 방법 특정 이미지의 스코어 영향을 미치는 영역을 파악할 수 있다. via Backpropatation 특정 이미지에 대해서 classification하는데에 영향을 미친 부분을 heapmap으로 표시하는 기법 특정 이미지에 대한 class의 스코어를 얻는다 Backpropagation을 통해서 입력 이미지의 Gradient를 구한다 얻어진 Graident의 magnitude를 구한다 얼마나 큰 영향을 끼쳤는지가 중요하기 때문에 부호를 제거한다 해당 map을 시각화 Class Activation Mapping 특정이미지에 대해서 어떤 결과가 나왔고 어떤부분을 참조하였는지를 보여주는 기법 Global Average Pooling + FC Layer가 있는 모델에서만 사용이 가능하다 Grad CAM CAM과 같이 특정이미지에 대해서 어떤 결과가 나왔고 어떤부분을 참조하였는지를 보여주는 기법 CNN Backbone이기만 하면 어떤 모델이든지 사용이 가능하다 reference Naver Connect Boostcamp - ai tech","link":"/2022/03/10/boostcamp/week/week8/CNN-4/"},{"title":"부스트 캠프 ai tech 9주 1일차 Instance &amp; Panoptic Segmantation","text":"Instance Segmantation Pixel 단위의 Classification 뿐만 아니라 객체간의 구분도 판단하는 Task Mask R-CNN Faster R-CNN를 기반으로 Instance Segmentation Task를 해결하기 위해 디자인된 모델 Keyword RoI-Align Mask Branch(head) RoI Align기존 RoI Pooling은 반올림을 해서 Pooling을 연산해서 조금 부정확 하더라도 BBox를 찾는것이기 때문에 괜찮았지만, Segmentation Task에서는 Mask가 이질적으로 변할 가능성이 있기 때문에 소수점 자리까지 연산이 가능하도록 한 RoI 기법 Mask BranchFaster RCNN의 Neck에서 BBox 별로 추출한 Feature에 따로 Mask Branch를 두어 Binary Classfication을 수행한다 YOLOACTYoloActEDGEPanoptic SegmentationInstance + Semantic Segmentation Task UPSNetBackbone Network를 통해서 뽑은 Feature를 이용하여 Semantic, Instance Feature로 가공한 뒤 Panoptic head로 합치는 과정을 거치는 모델 Keypoint 3개의 head Semantic head Instance head Panoptic head Heads Design Instance Head Semantic Head Semantic head와 Instance head에서 Feature를 추출 Instance head에서는 각 Object에 대해서 mask Feature를 얻음 Semantic Head에서는 Instance의 클래스가 겹치는 $X_{thing}$ 과 배경 $X_{stuff}$ Feature를 받아옴 Instance Feature를 적절히 Resize하여 가공하고 Semantic Head의 $X_{thing}$ 과의 합연산을 통하여 각 물체에 대한 Instace Mask를 얻는다 Segmentation Feature에서 Max값만 추출한 Feature Map에서 Instance Feature와 합연산 처리가 된 부분을 제거한다 이는 Unknown Class에 해당하는 새로운 채널로 추가된다 Semantic Feature와 Instance Feature간의 충돌을 해결해 주는 역할을 한다 2와 3에서 만들어진 Feature들과 배경을 나타내는 $X_{stuff}$를 Concat시켜서 최종적인 Panoptic Segmentation mask를 예측 VPSNet UPSNet을 Video에서도 동작하도록 디자인된 모델 기존 UPSNet과 동일한 구조를 가지고 추가적으로 Track Head가 추가되어 동일 객체에 대해서 Instance Segmentation이 잘 진행되도록 한다 Landmark Localization얼굴이나 사람의 포즈를 추정하고 Tracking 하는데 사용되는 기술이다 Coordinate regression Landmark 별 Regression을 진행하는 방법 기존에 많이 사용하던 방식이지만 부정확 했다 Heatmap Classification Segmentation과 비슷하게 모든 픽셀에 대해서 Landmark 인지를 연산하는 방법 Coordinate regression보다 좋은 성능을 보여주었지만, 모든 픽셀에 대하여 연산을 진행하다보니 더 많은 연산이 필요하다 Hourglass Network Stacked hourglass modules Skip Connection Hourglass Module Unet과 비슷한 구조 서로 대칭되는 Layer가 존재한다 Feature를 대칭되는 Layer로 넘겨줄 때 CNN을 통해서 걸러지고 + 연산이 이루어진다 DensePose이미지를 3D Surface(UV map)로 표현해주는 모델 Fast R-CNN + 3D surface regression branch RetinaFace 얼굴에 대해서 여러가지 task를 동시에 처리하는 모델 Gender Classification Face Detection 5 Landmark Regression 3D Mashup FPN + Multi-task branches Backbone + target Branch 우리가 원하는 모델 디자인 가능 Detecting objects as keypointsCornerNetTop-left, Bottom-right 2 point만 예측하면 BBox를 만들수 있다는 것에서 시작한 모델 속도는 매우 빠른편 성능은 좋지 않다 CenterNetCornerNet에서 Center까지 같이 예측하는 모델추가적으로 Center를 예측하면서 성능의 상승이 이루어졌다 CenterNet(1) Top-left, Bottom-right, Center CenterNet(2) Center, height, width reference Naver Connect Boostcamp - ai tech USPNet Review","link":"/2022/03/14/boostcamp/week/week9/CNN-5/"},{"title":"부스트 캠프 ai tech 9주 2일차 Conditional Generative Model","text":"Conditional Generative Model 사용자가 컨트롤이 가능한 Generative Model 서로 다른 두 도메인을 변화시켜주는 Task 통역모델, 음성의 고품질 전환, 요약모델 등 다양한 분야에서 응용가능하다 Conditional GAN랜덤으로 생성되는 Latent Noise z 만 받는 GAN과는 다르게 latent Noise z + Conditional Input이나, domain Data의 형식으로 받는다 CV 응용분야 Style Transfer Super resolution Colorization Super Resolution 해상도가 낮은 이미지를 높은 이미지로 변환시키는 Task Super Resolution을 위한 기존의 Naive Regression model에서는 MAELoss나 MSELoss를 사용 MAE와 MSELoss는 이미지를 전체 이미지의 평균값으로 생성하는 경향이 존재해서 이미지가 뿌옇게 생성됨 Super Resolution GANLoss를 이용하여 좀더 선명한 품실의 image를 얻어냈다 GAN Loss는 전체 이미지의 분포로 접근해서 생성하는 경향이 있었기에 MAE, MSE에 비해서 덜 뿌연 이미지를 생성 Image Translation ModelPix2Pix Image Translations Task를 위한 GAN model Generator는 Segmentation Masking Data를 사용하여 이미지를 생성한다 Discriminator는 Segmentation Masking Data + image를 가지고 진짜인지 가짜인지 판별한다 Total Loss GAN Loss + L1 Loss 논문에서는 GAN Loss로 Cross Entropy를 사용 L1 Loss : 형태는 Ground Truth와 비슷하지만 Blurry한 이미지가 생성 GAN Loss : Sharp한 이미지가 형성되지만 형태가 불안전한 이미지가 생성 $$G^{*} = arg, \\underset{G}{min}, \\underset{D}{max}, \\mathcal{L}_{cGAN}(G,D) + \\lambda \\mathcal{L}_{L1}(G)$$ CycleGAN Pix2Pix와 같은 Image Translation Model 이지만 Unpair Data를 변환시켜줄 수 있다 Pix2Pix의 Pair Image라는 제약상황에서 벗어날 수 있다 Generator Input으로 변환시킬 Image를 받는다 Unet의 Decoder처럼 단계적으로 Size를 확장시키면서 생성하는구조의 Generator를 가진다 Discriminator Input으로 Image를 받고 Real, Fake를 판단 PatchGAN의 형태를 가짐 CycleGAN에서는 2개의 Discriminator와 2개의 Generator가 존재해서 서로 Cycle을 이룬다 Total Loss GAN Loss + Cycle Consistency Loss GAN Loss : adversarial losses를 적용 Cycle Consistency Loss : mode collapse 문제를 막기위해 도입한 함수 변환된 이미지를 재변환(reconstruct)시켰을 때 Real Image사이의 L1 Distance Loss $$\\mathcal{L} = \\mathcal{L}_{GAN}(X \\rightarrow Y) + \\mathcal{L}_{GAN}(Y \\rightarrow X) + \\mathcal{L}_{cycle}(G, F)$$ Perceptiaul Loss GAN은 학습시키기 힘들다 High quality output을 위한 Loss Adversarial Loss 학습과 구현의 난이도가 높다 Data 만 존재하면 Pretrained 모델이 없어도 좋은 성능을 낼 수 있다 Perceptiaul Loss 학습 및 구현의 용이성 Pretrained 모델을 통해서 만 구현이 가능 Perceptiaul Loss 구조Perceptiaul Loss는 다음과 같이 Image Translation model과 pretrained 모델 2개로 구현 할 수 있다. reference Naver Connect Boostcamp - ai tech","link":"/2022/03/14/boostcamp/week/week9/CNN-6/"},{"title":"부스트 캠프 ai tech 9주 3일차 Multi-modal Learning","text":"Multi-modal Overview Unimodal : 하나의 특징 Data로 학습시키는 기법 Multi-modal : 여러가지의 Data로 학습시키는 기법 Difficultiy of Multi-modal 데이터마다 표현방법이 모두 다르다 Audio : wave Image : pixel text : sequence? query? 데이터간의 Unbalance한 Feature map 데이터 자체의 종류가 다르기 때문에 생성하는 분포의 차이가 클 가능성이 높다 학습시키기 용이하지 않음 항상 Multi-modal이 좋은방법은 아니다 전체 모델에서 한 데이터에 집중하여 학습하면서 다른 데이터를 소홀히 하는 편향적인 학습이 이루어 질 가능성이 존재한다 Multimodal Learning Matching : 두 데이터에 대해서 같은 공간으로 매칭시키도록 학습 Translating : 한 데이터를 다른 데이터로 변형 시키도록 학습 Referencing : 참조를 통한 상호보안적으로 더 좋은 결과를 내게 학습 Image &amp; TextNLP PreviewText Embedding Text Map to vector Text를 1차원 Vector로 변환해서 공간상에 표현하는 방법 Word2vec* Joint embedding Matching 기법을 사용해서 만들어진 Multi-modal Pretrained unimodal Model을 합쳐서 사용하는 기법 두 가지의 Data로 부터 같은 차원의 Feature를 추출하고, 이것을 Joint Embedding 시켜서 Matching 이 이루어지는 같은 데이터는 높은 Metric, Matching 되지않는 데이터는 낮은 Metric을 부여하도록 학습시키는 방법이다. 같은 차원의 Feature로 추출하는 이유 하나의 Feature Dimension상에서 Metric을 계산해야한다 Image Tagging 주어진 이미지에 대해서 Tag를 붙여주거나, 여러가지 Tag에 맞는 이미지를 검색해 주는 모델 Distance를 Metric으로 사용한 모델 Tag를 추가하거나 빼면 기존의 이미지와 유사하면서 바뀐 Tag만 적용될만한 이미지를 우선적으로 뽑아주는 결과를 얻었다 Recipe text vs food image 주어진 요리 사진에 레시피를 출력해주거나 레시피를 입력했을때 매칭된 이미지를 뽑아주는 모델 cosine similarity와 semantic regularization loss를 이용하였다 cosine similarity : text data와 image로 뽑은 Feature가 얼마나 유사한지를 계산 semantic regularization loss : 공통된 요리 카테고리에 속해있는지를 계산해서 반영한다 (성능을 높이기 위해 보정) Cross modal translation Translating 기법을 사용한 모델 모델에서 뽑은 Feature를 input으로 다른 모델에 넣고 변환시킨다. Data를 Feature로 바꿔주는 첫 모델을 Encoder, Feature로 Output를 뽑아내는 모델을 Decoder라고 지칭한다 Show attend and tell CNN을 통해서 Feature를 추출 추출한 Feature를 바탕으로 RNN에 입력 RNN 에서는 단어를 예측하면서 다음에 참조할 Feature map을 선택한다 위의 과정이 반복되면서 문장을 생성한다 Text2Image Text에서 image를 생성하는 모델 Conditional GAN을 통해서 구현 하였다 Encoder를 통해서 Text로 부터 Feature를 얻는다 Feature를 Conditional Input으로 Conditional GAN을 학습시킨다 Cross modal reasoning Referencing 기법을 통해 학습시킨 모델 두 모델에서 나온 Feature로 Joint embedding을 진행하고 추가적으로 Layer를 배치하여 하나의 Task를 푸는 형태로 디자인 되어있다 위의 Show attend and tell은 Translating와 Referencing이 둘다 사용된 모델이다 실제로 학습할 때는 word token을 같이 받음 reference Naver Connect Boostcamp - ai tech","link":"/2022/03/16/boostcamp/week/week9/CNN-7/"},{"title":"Week9 - Day 3~4 Review","text":"3~4일간 한 일 심화 과제 2, 3 완료 9강 Multi Modal 완료 mmdetection 시험 기동 mlflow fp16 - 실패 2. 피어세션에서 한 것 Controllable GAN &amp; Conditional GAN Controllable GAN Noise 컨트롤을 해서 원하는 Generate Image를 생성 Entangle한 latent noise의 vector공간을 펴서 원하는 이미지를 유도 따로 GAN의 구조를 바꾸지 않아도 기능의 장착이 가능하다 Conditional GAN Conditional Input을 집어넣어서 원하는 Category의 Data를 생성 Category 자체가 바뀌기 때문에 Controllable 보다 큰 변화를 줄 수 있다 학습을 시킬때 Conditional Input과 함께 학습을 시켜야 한다 피어세션에서 한 질문 3. 하루 느낀점 심화 과제한다고 시간이 너무 많이 지나갔다 과제코드가 이상하게 많이 꼬여있었다….. 할게 진짜 많은데 시간이 너무 부족하다 4. 미세 꿀팁 torch.sort는 output으로 2개를 지정하면 value값과 indice 값을 같이 준다","link":"/2022/03/18/boostcamp/Dairy/Week9-Day-3-Review/"},{"title":"부스트 캠프 ai tech 9주 4일차 3D perspective","text":"3D 사람은 Projection된 2D 이미지로 부터 3D를 인식한다 3D의 표현방법 Multiview images 여러 방향에서 찍은 사진데이터로 표현 Volumetric (voxel) x, y, z의 3차원 pixel로 3D를 표현 Part assembly 단순한 여러개의 Polygon 덩어리로 3D를 표현 Point cloud 물체의 surface을 dot의 좌표로 표현 Mesh point와 edge로 이루어진 map 3각형으로 이루어진 Polygon Data implicit shape 고차원의 함수형태로 surface를 표현 3D DatasetShapeNet 51300개, 55개의 Category를 가진 3D Dataset 전부 디자이너들이 제작함 PartNet 26671개의 3D 데이터가 573585개의 Part로 분리되어있는 3D Dataset SceneNet 5 Million개의 RGB-Depth Pair Dataset Simulationed indoor image(생성 이미지) ScanNet 2.5 Million 실제 Indoor Scan Image Outdoor 3D Scene Dataset KITTI LiDAR Data, 3D Bboxes Semantic KITTI LiDAR Data, point Waymo open Dataset LiDAR Data, 3D Bboxes 3D Task 3D object recognition 3D object detection 3D semantic segmentation Conditional 3D generation 2D Image에서 3D Mesh를 구하는 Task Mesh RCNN 기존 Mask RCNN 에서 Mesh Branch를 추가한 형태 Learning to Reconstruct Shapes from Unseen Classes CNN구조로 부터 Feature 추출 3개의 Branch로 Feature 재생성 normal map depth silhuette 재구성을 통한 3D shape 출력 reference Naver Connect Boostcamp - ai tech","link":"/2022/03/18/boostcamp/week/week9/CNN-8/"},{"title":"Week9 - Day 5 Review","text":"제목은 항상 상단에 나옴 H1 쓸필요 없음reference Naver Connect Boostcamp - ai tech","link":"/2022/03/18/Week9-Day-5-Review/"}],"tags":[{"name":"Ai Math","slug":"Ai-Math","link":"/tags/Ai-Math/"},{"name":"DeepLearning","slug":"DeepLearning","link":"/tags/DeepLearning/"},{"name":"week4","slug":"week4","link":"/tags/week4/"},{"name":"CV","slug":"CV","link":"/tags/CV/"},{"name":"Data visualization","slug":"Data-visualization","link":"/tags/Data-visualization/"},{"name":"week5","slug":"week5","link":"/tags/week5/"},{"name":"Ai serving","slug":"Ai-serving","link":"/tags/Ai-serving/"},{"name":"week6","slug":"week6","link":"/tags/week6/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"backend","slug":"backend","link":"/tags/backend/"},{"name":"message","slug":"message","link":"/tags/message/"},{"name":"할일","slug":"할일","link":"/tags/%ED%95%A0%EC%9D%BC/"},{"name":"일상","slug":"일상","link":"/tags/%EC%9D%BC%EC%83%81/"},{"name":"week3","slug":"week3","link":"/tags/week3/"},{"name":"week2","slug":"week2","link":"/tags/week2/"},{"name":"week8","slug":"week8","link":"/tags/week8/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"Function","slug":"Function","link":"/tags/Function/"},{"name":"Pytorch Lightning","slug":"Pytorch-Lightning","link":"/tags/Pytorch-Lightning/"},{"name":"cs","slug":"cs","link":"/tags/cs/"},{"name":"database","slug":"database","link":"/tags/database/"},{"name":"자료구조","slug":"자료구조","link":"/tags/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0/"},{"name":"network","slug":"network","link":"/tags/network/"},{"name":"os","slug":"os","link":"/tags/os/"},{"name":"week1","slug":"week1","link":"/tags/week1/"},{"name":"week9","slug":"week9","link":"/tags/week9/"},{"name":"pytorch","slug":"pytorch","link":"/tags/pytorch/"},{"name":"CNN","slug":"CNN","link":"/tags/CNN/"},{"name":"Sequencial Model","slug":"Sequencial-Model","link":"/tags/Sequencial-Model/"},{"name":"VAE","slug":"VAE","link":"/tags/VAE/"},{"name":"Generative Model","slug":"Generative-Model","link":"/tags/Generative-Model/"},{"name":"GAN","slug":"GAN","link":"/tags/GAN/"},{"name":"Project product","slug":"Project-product","link":"/tags/Project-product/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Object Detection","slug":"Object-Detection","link":"/tags/Object-Detection/"},{"name":"Semantic Segmentation","slug":"Semantic-Segmentation","link":"/tags/Semantic-Segmentation/"},{"name":"CNN Viz","slug":"CNN-Viz","link":"/tags/CNN-Viz/"},{"name":"Instance Segmentation","slug":"Instance-Segmentation","link":"/tags/Instance-Segmentation/"},{"name":"LandMark Detection","slug":"LandMark-Detection","link":"/tags/LandMark-Detection/"},{"name":"Multi-modal","slug":"Multi-modal","link":"/tags/Multi-modal/"},{"name":"3D","slug":"3D","link":"/tags/3D/"}],"categories":[{"name":"boostcamp","slug":"boostcamp","link":"/categories/boostcamp/"},{"name":"week","slug":"boostcamp/week","link":"/categories/boostcamp/week/"},{"name":"백엔드","slug":"백엔드","link":"/categories/%EB%B0%B1%EC%97%94%EB%93%9C/"},{"name":"일상","slug":"일상","link":"/categories/%EC%9D%BC%EC%83%81/"},{"name":"Programming","slug":"Programming","link":"/categories/Programming/"},{"name":"메세지큐","slug":"백엔드/메세지큐","link":"/categories/%EB%B0%B1%EC%97%94%EB%93%9C/%EB%A9%94%EC%84%B8%EC%A7%80%ED%81%90/"},{"name":"DeepLearning","slug":"DeepLearning","link":"/categories/DeepLearning/"},{"name":"계획","slug":"일상/계획","link":"/categories/%EC%9D%BC%EC%83%81/%EA%B3%84%ED%9A%8D/"},{"name":"Computer Science","slug":"Computer-Science","link":"/categories/Computer-Science/"},{"name":"TIL","slug":"일상/TIL","link":"/categories/%EC%9D%BC%EC%83%81/TIL/"},{"name":"Dairy","slug":"boostcamp/Dairy","link":"/categories/boostcamp/Dairy/"},{"name":"Python","slug":"Programming/Python","link":"/categories/Programming/Python/"},{"name":"Peer Session","slug":"boostcamp/Peer-Session","link":"/categories/boostcamp/Peer-Session/"},{"name":"Problems","slug":"boostcamp/Problems","link":"/categories/boostcamp/Problems/"},{"name":"Basic","slug":"DeepLearning/Basic","link":"/categories/DeepLearning/Basic/"},{"name":"Pytorch Lightning","slug":"DeepLearning/Pytorch-Lightning","link":"/categories/DeepLearning/Pytorch-Lightning/"},{"name":"Database","slug":"Computer-Science/Database","link":"/categories/Computer-Science/Database/"},{"name":"자료구조","slug":"Computer-Science/자료구조","link":"/categories/Computer-Science/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0/"},{"name":"Network","slug":"Computer-Science/Network","link":"/categories/Computer-Science/Network/"},{"name":"OS","slug":"Computer-Science/OS","link":"/categories/Computer-Science/OS/"},{"name":"Docker","slug":"Programming/Docker","link":"/categories/Programming/Docker/"},{"name":"tip","slug":"Programming/Python/tip","link":"/categories/Programming/Python/tip/"}]}